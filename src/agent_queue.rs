//! Agent Evaluation Queue System
//!
//! A complete queue system for evaluating agents with:
//! - Automatic scaling from 4 to 16 concurrent tasks
//! - Docker resource management (IP pool, containers)
//! - Proper cleanup on shutdown
//! - Priority queue based on stake

use crate::bench::{
    registry::RegistryClient,
    results::TaskResult as BenchTaskResult,
    runner::{TrialConfig, TrialRunner},
    task::Task,
};
use anyhow::{Context, Result};
use bollard::Docker;
use parking_lot::RwLock;
use serde::{Deserialize, Serialize};
use std::collections::{BinaryHeap, HashMap, HashSet};
use std::sync::atomic::{AtomicBool, AtomicU32, AtomicUsize, Ordering};
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::{mpsc, Mutex, Semaphore};
use tracing::{debug, error, info, warn};
use uuid::Uuid;

/// Maximum concurrent tasks across all agents (Docker resource limit)
const MAX_GLOBAL_CONCURRENT_TASKS: usize = 16;

/// Minimum concurrent tasks per agent
const MIN_TASKS_PER_AGENT: usize = 4;

/// Maximum concurrent tasks per agent  
const MAX_TASKS_PER_AGENT: usize = 16;

/// Maximum queued agents
const MAX_QUEUE_SIZE: usize = 100;

/// Container name prefix for cleanup
const CONTAINER_PREFIX: &str = "term-eval-";

/// Network name for evaluation containers
const EVAL_NETWORK: &str = "term-eval-network";

/// Agent information for queue
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QueueAgentInfo {
    /// Agent hash (unique identifier)
    pub hash: String,
    /// Agent Docker image
    pub image: String,
    /// Agent API endpoint (if applicable)
    pub endpoint: Option<String>,
    /// Source code
    pub source_code: Option<String>,
}

/// Agent evaluation request
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EvalRequest {
    pub id: String,
    pub agent: QueueAgentInfo,
    pub miner_hotkey: String,
    pub miner_uid: u16,
    pub miner_stake: u64,
    pub epoch: u64,
    pub submitted_at: u64,
    pub dataset: String,
    pub max_tasks: Option<usize>,
}

impl EvalRequest {
    pub fn new(
        agent: QueueAgentInfo,
        miner_hotkey: String,
        miner_uid: u16,
        miner_stake: u64,
        epoch: u64,
    ) -> Self {
        Self {
            id: Uuid::new_v4().to_string(),
            agent,
            miner_hotkey,
            miner_uid,
            miner_stake,
            epoch,
            submitted_at: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_secs(),
            dataset: "terminal-bench@2.0".to_string(),
            max_tasks: None,
        }
    }
}

/// Priority wrapper for heap ordering (higher stake = higher priority)
#[derive(Debug)]
struct PriorityRequest {
    request: EvalRequest,
}

impl PartialEq for PriorityRequest {
    fn eq(&self, other: &Self) -> bool {
        self.request.miner_stake == other.request.miner_stake
    }
}

impl Eq for PriorityRequest {}

impl PartialOrd for PriorityRequest {
    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {
        Some(self.cmp(other))
    }
}

impl Ord for PriorityRequest {
    fn cmp(&self, other: &Self) -> std::cmp::Ordering {
        // Higher stake = higher priority
        self.request.miner_stake.cmp(&other.request.miner_stake)
    }
}

/// Evaluation result
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EvalResult {
    pub request_id: String,
    pub agent_hash: String,
    pub miner_hotkey: String,
    pub miner_uid: u16,
    pub epoch: u64,
    pub score: f64,
    pub tasks_passed: u32,
    pub tasks_total: u32,
    pub task_results: Vec<TaskEvalResult>,
    pub execution_time_ms: u64,
    pub error: Option<String>,
}

/// Individual task result
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TaskEvalResult {
    pub task_name: String,
    pub passed: bool,
    pub score: f64,
    pub duration_ms: u64,
    pub steps: u32,
    pub error: Option<String>,
}

/// Queue statistics
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QueueStats {
    pub queued: usize,
    pub running: usize,
    pub completed: usize,
    pub failed: usize,
    pub active_containers: usize,
    pub active_tasks: usize,
    pub max_concurrent_tasks: usize,
}

/// Resource manager for Docker containers and IPs
struct ResourceManager {
    docker: Docker,
    active_containers: RwLock<HashSet<String>>,
    task_semaphore: Arc<Semaphore>,
    shutdown: AtomicBool,
}

impl ResourceManager {
    async fn new() -> Result<Self> {
        let docker =
            Docker::connect_with_local_defaults().context("Failed to connect to Docker")?;

        // Ensure network exists
        Self::ensure_network(&docker).await?;

        Ok(Self {
            docker,
            active_containers: RwLock::new(HashSet::new()),
            task_semaphore: Arc::new(Semaphore::new(MAX_GLOBAL_CONCURRENT_TASKS)),
            shutdown: AtomicBool::new(false),
        })
    }

    async fn ensure_network(docker: &Docker) -> Result<()> {
        use bollard::network::{CreateNetworkOptions, ListNetworksOptions};

        // Check if network exists
        let mut filters = HashMap::new();
        filters.insert("name", vec![EVAL_NETWORK]);

        let networks = docker
            .list_networks(Some(ListNetworksOptions { filters }))
            .await?;

        if networks.is_empty() {
            info!("Creating evaluation network: {}", EVAL_NETWORK);
            let options = CreateNetworkOptions {
                name: EVAL_NETWORK,
                driver: "bridge",
                ..Default::default()
            };
            docker.create_network(options).await?;
        }

        Ok(())
    }

    fn register_container(&self, container_id: &str) {
        self.active_containers
            .write()
            .insert(container_id.to_string());
    }

    fn unregister_container(&self, container_id: &str) {
        self.active_containers.write().remove(container_id);
    }

    fn active_container_count(&self) -> usize {
        self.active_containers.read().len()
    }

    async fn cleanup_all(&self) {
        use bollard::container::{
            ListContainersOptions, RemoveContainerOptions, StopContainerOptions,
        };

        info!("Cleaning up all evaluation containers...");

        // List all containers with our prefix
        let mut filters = HashMap::new();
        filters.insert("name", vec![CONTAINER_PREFIX]);

        let options = ListContainersOptions {
            all: true,
            filters,
            ..Default::default()
        };

        match self.docker.list_containers(Some(options)).await {
            Ok(containers) => {
                for container in containers {
                    if let Some(id) = container.id {
                        let id_short: String = id.chars().take(12).collect();
                        let name = container
                            .names
                            .as_ref()
                            .and_then(|n| n.first())
                            .map(|s| s.trim_start_matches('/').to_string())
                            .unwrap_or(id_short);

                        // Stop with timeout
                        let _ = self
                            .docker
                            .stop_container(&id, Some(StopContainerOptions { t: 3 }))
                            .await;

                        // Force remove
                        let rm_options = RemoveContainerOptions {
                            force: true,
                            ..Default::default()
                        };
                        if self
                            .docker
                            .remove_container(&id, Some(rm_options))
                            .await
                            .is_ok()
                        {
                            info!("Cleaned up container: {}", name);
                        }
                    }
                }
            }
            Err(e) => {
                error!("Failed to list containers for cleanup: {}", e);
            }
        }

        self.active_containers.write().clear();
    }

    fn shutdown(&self) {
        self.shutdown.store(true, Ordering::SeqCst);
    }

    fn is_shutdown(&self) -> bool {
        self.shutdown.load(Ordering::SeqCst)
    }
}

/// Agent Evaluation Queue
pub struct AgentQueue {
    /// Priority queue of pending requests
    pending: Mutex<BinaryHeap<PriorityRequest>>,
    /// Currently running evaluations
    running: RwLock<HashMap<String, RunningEval>>,
    /// Completed results
    results: RwLock<HashMap<String, EvalResult>>,
    /// Resource manager
    resources: Arc<ResourceManager>,
    /// Result sender for completed evaluations
    result_tx: mpsc::UnboundedSender<EvalResult>,
    /// Statistics
    stats: QueueStatsInner,
    /// Shutdown flag
    shutdown: AtomicBool,
}

/// Running evaluation tracking
#[derive(Debug)]
struct RunningEval {
    request: EvalRequest,
    started_at: Instant,
    tasks_completed: AtomicU32,
    tasks_total: u32,
}

/// Internal stats
struct QueueStatsInner {
    completed: AtomicUsize,
    failed: AtomicUsize,
}

impl AgentQueue {
    /// Create a new agent queue
    pub async fn new() -> Result<(Self, mpsc::UnboundedReceiver<EvalResult>)> {
        let resources = Arc::new(ResourceManager::new().await?);
        let (result_tx, result_rx) = mpsc::unbounded_channel();

        let queue = Self {
            pending: Mutex::new(BinaryHeap::new()),
            running: RwLock::new(HashMap::new()),
            results: RwLock::new(HashMap::new()),
            resources,
            result_tx,
            stats: QueueStatsInner {
                completed: AtomicUsize::new(0),
                failed: AtomicUsize::new(0),
            },
            shutdown: AtomicBool::new(false),
        };

        Ok((queue, result_rx))
    }

    /// Submit an agent for evaluation
    pub async fn submit(&self, request: EvalRequest) -> Result<String> {
        if self.shutdown.load(Ordering::SeqCst) {
            anyhow::bail!("Queue is shutting down");
        }

        let mut pending = self.pending.lock().await;

        if pending.len() >= MAX_QUEUE_SIZE {
            anyhow::bail!("Queue is full ({} pending)", MAX_QUEUE_SIZE);
        }

        let request_id = request.id.clone();
        info!(
            "Queued agent {} from miner {} (stake: {}, position: {})",
            request.agent.hash,
            request.miner_hotkey,
            request.miner_stake,
            pending.len() + 1
        );

        pending.push(PriorityRequest { request });

        Ok(request_id)
    }

    /// Get queue statistics
    pub fn stats(&self) -> QueueStats {
        let pending = self.pending.try_lock().map(|p| p.len()).unwrap_or(0);
        let running = self.running.read().len();

        QueueStats {
            queued: pending,
            running,
            completed: self.stats.completed.load(Ordering::Relaxed),
            failed: self.stats.failed.load(Ordering::Relaxed),
            active_containers: self.resources.active_container_count(),
            active_tasks: MAX_GLOBAL_CONCURRENT_TASKS
                - self.resources.task_semaphore.available_permits(),
            max_concurrent_tasks: MAX_GLOBAL_CONCURRENT_TASKS,
        }
    }

    /// Get result for a request
    pub fn get_result(&self, request_id: &str) -> Option<EvalResult> {
        self.results.read().get(request_id).cloned()
    }

    /// Calculate optimal concurrent tasks based on current load
    fn calculate_concurrent_tasks(&self) -> usize {
        let available = self.resources.task_semaphore.available_permits();
        let running_agents = self.running.read().len();

        if running_agents == 0 {
            return MAX_TASKS_PER_AGENT.min(available);
        }

        // Distribute available permits among running agents + 1 (new agent)
        let per_agent = available / (running_agents + 1);

        // Clamp to min/max
        per_agent.clamp(MIN_TASKS_PER_AGENT, MAX_TASKS_PER_AGENT)
    }

    /// Start the queue processor
    pub async fn run(self: Arc<Self>) {
        info!(
            "Starting agent queue processor (max {} concurrent tasks)",
            MAX_GLOBAL_CONCURRENT_TASKS
        );

        // Cleanup old containers on start
        self.resources.cleanup_all().await;

        loop {
            if self.shutdown.load(Ordering::SeqCst) {
                info!("Queue processor shutting down");
                break;
            }

            // Check if we can start a new evaluation
            let available_permits = self.resources.task_semaphore.available_permits();
            if available_permits < MIN_TASKS_PER_AGENT {
                // Not enough capacity, wait
                tokio::time::sleep(Duration::from_millis(500)).await;
                continue;
            }

            // Get next request from queue
            let request = {
                let mut pending = self.pending.lock().await;
                pending.pop().map(|p| p.request)
            };

            let request = match request {
                Some(r) => r,
                None => {
                    // Queue empty, wait
                    tokio::time::sleep(Duration::from_millis(100)).await;
                    continue;
                }
            };

            // Calculate concurrent tasks for this agent
            let concurrent_tasks = self.calculate_concurrent_tasks();

            info!(
                "Starting evaluation for agent {} (concurrent tasks: {})",
                request.agent.hash, concurrent_tasks
            );

            // Start evaluation in background
            let queue = self.clone();
            let resources = self.resources.clone();

            tokio::spawn(async move {
                queue
                    .run_evaluation(request, concurrent_tasks, resources)
                    .await;
            });

            // Small delay to prevent tight loop
            tokio::time::sleep(Duration::from_millis(50)).await;
        }

        // Final cleanup
        self.resources.cleanup_all().await;
    }

    /// Run evaluation for a single agent
    async fn run_evaluation(
        &self,
        request: EvalRequest,
        concurrent_tasks: usize,
        resources: Arc<ResourceManager>,
    ) {
        let request_id = request.id.clone();
        let agent_hash = request.agent.hash.clone();
        let start = Instant::now();

        // Download dataset
        let task_paths = match self.download_dataset(&request.dataset).await {
            Ok(paths) => paths,
            Err(e) => {
                error!("Failed to download dataset: {}", e);
                self.complete_with_error(&request, &format!("Dataset error: {}", e));
                return;
            }
        };

        // Limit tasks if requested
        let task_paths: Vec<_> = if let Some(max) = request.max_tasks {
            task_paths.into_iter().take(max).collect()
        } else {
            task_paths
        };

        let total_tasks = task_paths.len() as u32;

        // Register as running
        {
            let mut running = self.running.write();
            running.insert(
                request_id.clone(),
                RunningEval {
                    request: request.clone(),
                    started_at: start,
                    tasks_completed: AtomicU32::new(0),
                    tasks_total: total_tasks,
                },
            );
        }

        // Acquire semaphore permits for concurrent tasks
        let semaphore = Arc::new(Semaphore::new(concurrent_tasks));
        let task_results = Arc::new(Mutex::new(Vec::new()));
        let tasks_completed = Arc::new(AtomicU32::new(0));

        // Run tasks concurrently
        let mut handles = Vec::new();

        for task_path in task_paths {
            let semaphore = semaphore.clone();
            let resources = resources.clone();
            let agent = request.agent.clone();
            let task_results = task_results.clone();
            let tasks_completed = tasks_completed.clone();
            let request_id = request_id.clone();

            let handle = tokio::spawn(async move {
                // Acquire permit
                let _permit = semaphore.acquire().await.unwrap();

                // Also acquire global permit
                let _global_permit = resources.task_semaphore.acquire().await.unwrap();

                if resources.is_shutdown() {
                    return;
                }

                // Load task
                let task = match Task::from_path(&task_path) {
                    Ok(t) => t,
                    Err(e) => {
                        error!("Failed to load task {:?}: {}", task_path, e);
                        return;
                    }
                };

                let task_name = task.name.clone();
                let task_start = Instant::now();

                // Create unique container name
                let request_id_short: String = request_id.chars().take(8).collect();
                let task_name_short: String = task_name.chars().take(20).collect();
                let container_name = format!(
                    "{}{}-{}",
                    CONTAINER_PREFIX, request_id_short, task_name_short
                );

                // Run task evaluation
                let result = Self::evaluate_task(&task, &agent, &container_name).await;

                let completed = tasks_completed.fetch_add(1, Ordering::SeqCst) + 1;
                debug!(
                    "Task {}/{} completed: {} - {}",
                    completed,
                    task_results.lock().await.len() + 1,
                    task_name,
                    if result.passed { "PASS" } else { "FAIL" }
                );

                task_results.lock().await.push(result);
            });

            handles.push(handle);
        }

        // Wait for all tasks
        for handle in handles {
            let _ = handle.await;
        }

        // Collect results
        let task_results = task_results.lock().await.clone();

        let tasks_passed = task_results.iter().filter(|r| r.passed).count() as u32;
        let score = if total_tasks > 0 {
            tasks_passed as f64 / total_tasks as f64
        } else {
            0.0
        };

        // Create result
        let result = EvalResult {
            request_id: request_id.clone(),
            agent_hash,
            miner_hotkey: request.miner_hotkey.clone(),
            miner_uid: request.miner_uid,
            epoch: request.epoch,
            score,
            tasks_passed,
            tasks_total: total_tasks,
            task_results,
            execution_time_ms: start.elapsed().as_millis() as u64,
            error: None,
        };

        // Store and send result
        self.complete_evaluation(result).await;
    }

    /// Evaluate a single task
    async fn evaluate_task(
        task: &Task,
        agent: &QueueAgentInfo,
        container_name: &str,
    ) -> TaskEvalResult {
        let start = Instant::now();

        // Create trial config
        let output_dir = std::env::temp_dir().join("term-eval").join(&task.name);
        let _ = std::fs::create_dir_all(&output_dir);

        let config = TrialConfig {
            trial_name: container_name.to_string(),
            output_dir,
            max_steps: 50,
            timeout_multiplier: 1.0,
            force_build: false,
            delete_container: true,
            agent_provider: None,
            model_name: None,
        };

        // We need to create a custom agent that uses the source code
        // For now, return a placeholder - this needs integration with the actual runner
        TaskEvalResult {
            task_name: task.name.clone(),
            passed: false,
            score: 0.0,
            duration_ms: start.elapsed().as_millis() as u64,
            steps: 0,
            error: Some("Task evaluation not yet integrated".to_string()),
        }
    }

    /// Download dataset and get task paths
    async fn download_dataset(&self, spec: &str) -> Result<Vec<std::path::PathBuf>> {
        let mut client = RegistryClient::new();
        let (name, version) = RegistryClient::parse_dataset_spec(spec);
        client.get_task_paths(&name, &version).await
    }

    /// Complete evaluation with error
    fn complete_with_error(&self, request: &EvalRequest, error: &str) {
        let result = EvalResult {
            request_id: request.id.clone(),
            agent_hash: request.agent.hash.clone(),
            miner_hotkey: request.miner_hotkey.clone(),
            miner_uid: request.miner_uid,
            epoch: request.epoch,
            score: 0.0,
            tasks_passed: 0,
            tasks_total: 0,
            task_results: vec![],
            execution_time_ms: 0,
            error: Some(error.to_string()),
        };

        // Store result
        self.results
            .write()
            .insert(request.id.clone(), result.clone());

        // Remove from running
        self.running.write().remove(&request.id);

        // Update stats
        self.stats.failed.fetch_add(1, Ordering::Relaxed);

        // Send result
        let _ = self.result_tx.send(result);
    }

    /// Complete evaluation successfully
    async fn complete_evaluation(&self, result: EvalResult) {
        let request_id = result.request_id.clone();

        info!(
            "Evaluation complete: agent={} score={:.2}% ({}/{} tasks) time={}s",
            result.agent_hash,
            result.score * 100.0,
            result.tasks_passed,
            result.tasks_total,
            result.execution_time_ms / 1000
        );

        // Store result
        self.results
            .write()
            .insert(request_id.clone(), result.clone());

        // Remove from running
        self.running.write().remove(&request_id);

        // Update stats
        if result.error.is_some() {
            self.stats.failed.fetch_add(1, Ordering::Relaxed);
        } else {
            self.stats.completed.fetch_add(1, Ordering::Relaxed);
        }

        // Send result
        let _ = self.result_tx.send(result);
    }

    /// Graceful shutdown
    pub async fn shutdown(&self) {
        info!("Initiating queue shutdown...");
        self.shutdown.store(true, Ordering::SeqCst);
        self.resources.shutdown();

        // Wait for running evaluations to complete (with timeout)
        let timeout = Duration::from_secs(30);
        let start = Instant::now();

        while !self.running.read().is_empty() && start.elapsed() < timeout {
            tokio::time::sleep(Duration::from_millis(500)).await;
        }

        // Force cleanup
        self.resources.cleanup_all().await;

        info!("Queue shutdown complete");
    }
}

/// Queue configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QueueConfig {
    pub max_global_concurrent: usize,
    pub min_per_agent: usize,
    pub max_per_agent: usize,
    pub max_queue_size: usize,
    pub default_dataset: String,
}

impl Default for QueueConfig {
    fn default() -> Self {
        Self {
            max_global_concurrent: MAX_GLOBAL_CONCURRENT_TASKS,
            min_per_agent: MIN_TASKS_PER_AGENT,
            max_per_agent: MAX_TASKS_PER_AGENT,
            max_queue_size: MAX_QUEUE_SIZE,
            default_dataset: "terminal-bench@2.0".to_string(),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_queue_creation() {
        // Skip if Docker not available or no permissions
        if Docker::connect_with_local_defaults().is_err() {
            return;
        }

        // Queue creation may fail on CI without Docker network permissions
        // This is acceptable - the test verifies it doesn't panic
        let _result = AgentQueue::new().await;
    }

    #[test]
    fn test_priority_ordering() {
        let low_stake = PriorityRequest {
            request: EvalRequest {
                id: "1".to_string(),
                agent: QueueAgentInfo {
                    hash: "a".to_string(),
                    image: "".to_string(),
                    endpoint: None,
                    source_code: None,
                },
                miner_hotkey: "".to_string(),
                miner_uid: 0,
                miner_stake: 100,
                epoch: 0,
                submitted_at: 0,
                dataset: "".to_string(),
                max_tasks: None,
            },
        };

        let high_stake = PriorityRequest {
            request: EvalRequest {
                id: "2".to_string(),
                agent: QueueAgentInfo {
                    hash: "b".to_string(),
                    image: "".to_string(),
                    endpoint: None,
                    source_code: None,
                },
                miner_hotkey: "".to_string(),
                miner_uid: 0,
                miner_stake: 1000,
                epoch: 0,
                submitted_at: 0,
                dataset: "".to_string(),
                max_tasks: None,
            },
        };

        // Higher stake should be "greater" for max heap
        assert!(high_stake > low_stake);
    }
}
