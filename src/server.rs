//! Always-On Challenge Server - Production Ready
//!
//! This module implements the challenge container server for Terminal-Bench evaluations.
//!
//! Architecture:
//! ```text
//! Challenge Container (always-on)
//!  ├── Service Mode (continuous)
//!  │   └── POST /evaluate → Run agent on real tasks → Return results
//!  └── Weights Mode (epoch-triggered)
//!      └── GET /get_weights → Read-only, deterministic
//! ```
//!
//! Datasets:
//! - Production: terminal-bench 2.0 (89 tasks)
//! - Testing: hello-world (1 task)

use crate::api::{self, ApiState};
use crate::auth::AuthManager;
use crate::bench::external_agent::ExternalAgent;
use crate::bench::registry::{Dataset, RegistryClient, TaskSource};
use crate::bench::runner::{TrialConfig, TrialRunner};
use crate::bench::task::Task;
use crate::block_sync::{BlockSync, BlockSyncConfig};
use crate::central_client::PlatformClient;
use crate::config::ChallengeConfig;
use crate::epoch::{create_epoch_calculator, SharedEpochCalculator};
use crate::llm_review::{LlmConfig, LlmProvider, LlmReviewManager};
use crate::pg_storage::PgStorage;
use crate::python_whitelist::{PythonWhitelist, WhitelistConfig};
use axum::{
    extract::{Path, Query, State},
    http::StatusCode,
    routing::{get, post},
    Json, Router,
};
use rand::seq::SliceRandom;
use serde::{Deserialize, Serialize};
use sp_core::crypto::Ss58Codec;
use std::collections::HashMap;
use std::path::PathBuf;
use std::sync::Arc;
use tokio::sync::RwLock;
use tower_http::cors::{Any, CorsLayer};
use tower_http::limit::RequestBodyLimitLayer;
use tower_http::trace::TraceLayer;
use tracing::{debug, error, info, warn};
use uuid::Uuid;

/// Validate that a string is a valid SS58 hotkey address
fn is_valid_ss58_hotkey(hotkey: &str) -> bool {
    sp_core::crypto::AccountId32::from_ss58check(hotkey).is_ok()
}

// ============================================================================
// CONSTANTS
// ============================================================================

/// Default dataset for production evaluations
pub const DEFAULT_DATASET: &str = "terminal-bench";
pub const DEFAULT_DATASET_VERSION: &str = "2.0";

/// Test dataset for quick validation
pub const TEST_DATASET: &str = "hello-world";
pub const TEST_DATASET_VERSION: &str = "head";

/// Registry URL
pub const REGISTRY_URL: &str = "https://raw.githubusercontent.com/laude-institute/harbor/83745559edb7b1e6f21483a90604f83e201c4a10/registry.json";

// ============================================================================
// SERVER STATE
// ============================================================================

pub struct ChallengeServerState {
    pub config: RwLock<ChallengeConfig>,
    pub platform_client: PlatformClient,
    pub challenge_id: String,
    pub whitelist: PythonWhitelist,
    pub llm_manager: RwLock<Option<LlmReviewManager>>,
    pub registry_client: RwLock<RegistryClient>,
    pub cached_tasks: RwLock<HashMap<String, Vec<PathBuf>>>,
    pub test_mode: bool,
    /// PostgreSQL storage for server mode (subnet owner)
    /// None = validator mode (uses platform API), Some = server mode (local PostgreSQL)
    pub pg_storage: Option<PgStorage>,
    /// Authentication manager for validator whitelist
    pub auth_manager: AuthManager,
    /// Epoch calculator for block-based epoch tracking
    pub epoch_calculator: SharedEpochCalculator,
}

impl ChallengeServerState {
    pub fn new(config: ChallengeConfig, platform_url: &str, challenge_id: &str) -> Self {
        Self::with_options(config, platform_url, challenge_id, false, None, vec![])
    }

    pub fn with_mode(
        config: ChallengeConfig,
        platform_url: &str,
        challenge_id: &str,
        test_mode: bool,
    ) -> Self {
        Self::with_options(config, platform_url, challenge_id, test_mode, None, vec![])
    }

    pub fn with_options(
        config: ChallengeConfig,
        platform_url: &str,
        challenge_id: &str,
        test_mode: bool,
        pg_storage: Option<PgStorage>,
        validator_whitelist: Vec<String>,
    ) -> Self {
        let whitelist_config = WhitelistConfig {
            allowed_stdlib: config.module_whitelist.allowed_stdlib.clone(),
            allowed_third_party: config.module_whitelist.allowed_third_party.clone(),
            ..Default::default()
        };
        let whitelist = PythonWhitelist::new(whitelist_config);

        Self {
            config: RwLock::new(config),
            platform_client: PlatformClient::new(platform_url),
            challenge_id: challenge_id.to_string(),
            whitelist,
            llm_manager: RwLock::new(None),
            registry_client: RwLock::new(RegistryClient::with_url(REGISTRY_URL)),
            cached_tasks: RwLock::new(HashMap::new()),
            test_mode,
            pg_storage,
            auth_manager: AuthManager::with_whitelist(validator_whitelist),
            epoch_calculator: create_epoch_calculator(),
        }
    }

    /// Get the current epoch from the epoch calculator
    pub fn current_epoch(&self) -> u64 {
        self.epoch_calculator.current_epoch()
    }

    /// Get the current block from the epoch calculator
    pub fn current_block(&self) -> u64 {
        self.epoch_calculator.last_block()
    }

    /// Check if running in server mode (with PostgreSQL storage)
    pub fn is_server_mode(&self) -> bool {
        self.pg_storage.is_some()
    }

    /// Create LLM review manager with miner's API key
    pub fn create_llm_manager(&self, api_key: &str, provider: &str) -> LlmReviewManager {
        let llm_provider = LlmProvider::parse(provider);
        let llm_config = LlmConfig::for_provider(llm_provider, api_key.to_string());
        LlmReviewManager::new(llm_config, self.challenge_id.clone())
    }

    /// Get dataset name based on mode
    pub fn dataset_name(&self) -> &str {
        if self.test_mode {
            TEST_DATASET
        } else {
            DEFAULT_DATASET
        }
    }

    /// Get dataset version based on mode
    pub fn dataset_version(&self) -> &str {
        if self.test_mode {
            TEST_DATASET_VERSION
        } else {
            DEFAULT_DATASET_VERSION
        }
    }

    /// Download and cache tasks for the current dataset
    pub async fn ensure_tasks_cached(&self) -> anyhow::Result<Vec<PathBuf>> {
        let dataset_key = format!("{}@{}", self.dataset_name(), self.dataset_version());

        // Check cache first
        {
            let cache = self.cached_tasks.read().await;
            if let Some(tasks) = cache.get(&dataset_key) {
                return Ok(tasks.clone());
            }
        }

        // Download tasks
        info!("Downloading tasks for dataset: {}", dataset_key);
        let mut registry = self.registry_client.write().await;

        let task_paths = registry
            .download_dataset(self.dataset_name(), self.dataset_version(), false)
            .await?;
        info!("Downloaded {} tasks", task_paths.len());

        // Cache tasks
        {
            let mut cache = self.cached_tasks.write().await;
            cache.insert(dataset_key, task_paths.clone());
        }

        Ok(task_paths)
    }
}

// ============================================================================
// /get_weights ENDPOINT
// ============================================================================

#[derive(Debug, Deserialize)]
pub struct GetWeightsQuery {
    pub epoch: Option<u64>,
}

#[derive(Debug, Serialize)]
pub struct GetWeightsResponse {
    pub epoch: u64,
    pub weights: Vec<WeightEntry>,
}

#[derive(Debug, Serialize)]
pub struct WeightEntry {
    pub hotkey: String,
    pub weight: f64,
}

/// GET /get_weights - Deterministic weight calculation
/// Winner-takes-all: The best eligible agent gets weight based on time decay
/// Eligibility requirements:
/// - manually_validated = true
/// - At least 2 validators have evaluated
/// - At least 8 tasks passed per validator
///
/// Time decay:
/// - Grace period: 40 epochs (~48 hours) - no decay
/// - After grace: 50% decay per 20 epochs (~1 day)
pub async fn get_weights(
    State(state): State<Arc<ChallengeServerState>>,
    Query(query): Query<GetWeightsQuery>,
) -> Result<Json<GetWeightsResponse>, (StatusCode, String)> {
    let epoch = query.epoch.unwrap_or(0);

    // Get PostgreSQL storage (required for server mode)
    let pg = state.pg_storage.as_ref().ok_or_else(|| {
        (
            StatusCode::SERVICE_UNAVAILABLE,
            "PostgreSQL storage not available".to_string(),
        )
    })?;

    // Load time decay config from environment
    let decay_config = crate::time_decay::TimeDecayConfig::from_env();

    // Get the eligible winner directly from our database
    let winner = pg
        .get_eligible_winner()
        .await
        .map_err(|e| (StatusCode::INTERNAL_SERVER_ERROR, e.to_string()))?;

    let weights = if let Some(winner) = winner {
        // Calculate time-based decay multiplier based on last task evaluation time
        // Use last_evaluation_at (last task completed) instead of created_at (submission time)
        let decay_info =
            crate::time_decay::calculate_decay_info(winner.last_evaluation_at, &decay_config);

        // Apply decay only if disable_decay is false
        let final_weight = if winner.disable_decay {
            1.0 // No decay for this agent
        } else {
            decay_info.multiplier
        };

        info!(
            "Weight winner for epoch {}: {} (hotkey: {}, tasks_passed: {}, validators: {}, weight: {:.2}%, disable_decay: {})",
            epoch,
            winner.name.as_deref().unwrap_or(&winner.agent_hash[..16]),
            &winner.miner_hotkey[..16],
            winner.total_tasks_passed,
            winner.num_validators,
            final_weight * 100.0,
            winner.disable_decay
        );

        if !winner.disable_decay && decay_info.decay_active {
            info!(
                "Time decay active: {:.1}h since last task, grace expired, {:.1} days decaying, multiplier={:.4}",
                decay_info.age_hours, decay_info.days_decaying, decay_info.multiplier
            );
        } else if winner.disable_decay {
            info!("Time decay DISABLED for this agent");
        }

        vec![WeightEntry {
            hotkey: winner.miner_hotkey,
            weight: final_weight,
        }]
    } else {
        info!("No eligible winner for epoch {} - no agents meet criteria (validated, >=2 validators, >=8 tasks/validator)", epoch);
        vec![]
    };

    let total_weight: f64 = weights.iter().map(|w| w.weight).sum();
    info!(
        "Computed weights for epoch {}: {} miners, total weight: {:.4}",
        epoch,
        weights.len(),
        total_weight
    );

    Ok(Json(GetWeightsResponse { epoch, weights }))
}

// ============================================================================
// /evaluate ENDPOINT - Production Ready
// ============================================================================

#[derive(Debug, Deserialize)]
pub struct EvaluateRequest {
    pub submission_id: String,
    pub agent_hash: String,
    pub miner_hotkey: String,
    pub validator_hotkey: String,
    pub name: Option<String>,
    pub source_code: String,
    /// Deprecated: API key is now looked up from platform-server
    #[serde(default)]
    pub api_key: Option<String>,
    /// Deprecated: Provider is now looked up from platform-server
    #[serde(default)]
    pub api_provider: Option<String>,
    pub epoch: u64,
}

#[derive(Debug, Serialize)]
pub struct EvaluateResponse {
    pub success: bool,
    pub error: Option<String>,
    pub score: f64,
    pub tasks_passed: u32,
    pub tasks_total: u32,
    pub tasks_failed: u32,
    pub total_cost_usd: f64,
    pub execution_time_ms: i64,
    pub task_results: Option<Vec<TaskResultResponse>>,
    pub execution_log: Option<String>,
}

#[derive(Debug, Clone, Serialize)]
pub struct TaskResultResponse {
    pub task_id: String,
    pub task_name: String,
    pub passed: bool,
    pub score: f64,
    pub execution_time_ms: i64,
    pub steps: u32,
    pub error: Option<String>,
}

/// POST /evaluate - Evaluate agent on real Terminal-Bench tasks
pub async fn evaluate_agent(
    State(state): State<Arc<ChallengeServerState>>,
    Json(req): Json<EvaluateRequest>,
) -> Result<Json<EvaluateResponse>, (StatusCode, String)> {
    let start = std::time::Instant::now();

    // Validate miner_hotkey is a valid SS58 address
    if !is_valid_ss58_hotkey(&req.miner_hotkey) {
        warn!(
            "Invalid miner_hotkey format: {} (expected SS58 address)",
            &req.miner_hotkey[..32.min(req.miner_hotkey.len())]
        );
        return Ok(Json(EvaluateResponse {
            success: false,
            error: Some(format!(
                "Invalid miner_hotkey: must be a valid SS58 address (e.g., '5GrwvaEF...'). Received: {}",
                &req.miner_hotkey[..32.min(req.miner_hotkey.len())]
            )),
            score: 0.0,
            tasks_passed: 0,
            tasks_total: 0,
            tasks_failed: 0,
            total_cost_usd: 0.0,
            execution_time_ms: start.elapsed().as_millis() as i64,
            task_results: None,
            execution_log: None,
        }));
    }

    let config = state.config.read().await;

    let agent_name = req.name.as_deref().unwrap_or("unnamed");
    let agent_hash_short = &req.agent_hash[..16.min(req.agent_hash.len())];

    info!(
        "Evaluating agent: {} (hash: {}) from {} [dataset: {}]",
        agent_name,
        agent_hash_short,
        &req.miner_hotkey[..16.min(req.miner_hotkey.len())],
        state.dataset_name()
    );

    // Step 1: Whitelist validation (warning only, LLM decides)
    let verification = state.whitelist.verify(&req.source_code);
    if !verification.valid {
        // Log warning but don't block - LLM review will make final decision
        info!(
            "Agent {} has potential issues (LLM will review): {:?}",
            agent_hash_short, verification.errors
        );
    }

    // Step 2: LLM Code Review via centralized platform-server
    let mut total_cost_usd = 0.0;
    let platform_llm = crate::platform_llm::PlatformLlmClient::for_agent(
        state.platform_client.base_url(),
        &req.agent_hash,
        &req.validator_hotkey,
    );

    if let Ok(llm_client) = platform_llm {
        // Create review prompt
        let review_prompt = format!(
            "Review this Python agent code for security and compliance. \
             Check for: dangerous imports, network access, file system access, \
             code injection, infinite loops, resource abuse. \
             Respond with JSON: {{\"approved\": true/false, \"reason\": \"...\", \"violations\": []}}\n\n\
             Code:\n```python\n{}\n```",
            &req.source_code
        );

        let messages = vec![
            crate::platform_llm::ChatMessage::system(
                "You are a security reviewer for AI agent code. Be strict about security.",
            ),
            crate::platform_llm::ChatMessage::user(&review_prompt),
        ];

        let mut flagged = false;
        let mut flag_reason: Option<String> = None;

        match llm_client.chat_with_usage(messages).await {
            Ok(response) => {
                total_cost_usd += response.cost_usd.unwrap_or(0.0);

                if let Some(content) = &response.content {
                    // Parse review result
                    if let Ok(review) = serde_json::from_str::<serde_json::Value>(content) {
                        let approved = review["approved"].as_bool().unwrap_or(true);
                        let reason = review["reason"].as_str().unwrap_or("Unknown").to_string();

                        if !approved {
                            // Flag for manual review by subnet owner, but continue evaluation
                            warn!(
                                "Agent {} flagged for manual review: {}",
                                agent_hash_short, reason
                            );
                            flagged = true;
                            flag_reason = Some(reason);
                        } else {
                            info!("Agent {} passed LLM review", agent_hash_short);
                        }
                    }
                }
            }
            Err(e) => {
                warn!("LLM review failed (continuing): {}", e);
                // Continue without review on error (graceful degradation)
            }
        }

        // TODO: Store flagged status in DB for subnet owner review
        if flagged {
            info!(
                "Agent {} will be evaluated but flagged for manual approval. Reason: {:?}",
                agent_hash_short, flag_reason
            );
        }
    } else {
        warn!("Could not create platform LLM client, skipping review");
    }

    // Step 3: Download/cache tasks
    let task_paths = match state.ensure_tasks_cached().await {
        Ok(paths) => paths,
        Err(e) => {
            error!("Failed to download tasks: {}", e);
            return Ok(Json(EvaluateResponse {
                success: false,
                error: Some(format!("Failed to download tasks: {}", e)),
                score: 0.0,
                tasks_passed: 0,
                tasks_total: 0,
                tasks_failed: 0,
                total_cost_usd,
                execution_time_ms: start.elapsed().as_millis() as i64,
                task_results: None,
                execution_log: None,
            }));
        }
    };

    // Step 4: Select tasks for evaluation
    let tasks_per_eval = config.evaluation.tasks_per_evaluation.min(task_paths.len());
    let selected_tasks: Vec<_> = if task_paths.len() <= tasks_per_eval {
        task_paths.clone()
    } else {
        let mut rng = rand::thread_rng();
        let mut shuffled = task_paths.clone();
        shuffled.shuffle(&mut rng);
        shuffled.into_iter().take(tasks_per_eval).collect()
    };

    info!(
        "Running {} tasks for agent {}",
        selected_tasks.len(),
        agent_hash_short
    );

    // Step 5: Execute agent on each task
    let mut task_results = Vec::new();
    let mut tasks_passed = 0u32;
    let mut tasks_failed = 0u32;
    let mut execution_log = String::new();

    // Create output directory for this evaluation
    let output_dir = PathBuf::from("/tmp/term-challenge-evals")
        .join(&req.submission_id)
        .join(&req.agent_hash[..16.min(req.agent_hash.len())]);

    for task_path in &selected_tasks {
        let task_start = std::time::Instant::now();
        let task_name = task_path
            .file_name()
            .and_then(|n| n.to_str())
            .unwrap_or("unknown")
            .to_string();

        info!("Running task: {}", task_name);

        // Load task
        let task = match Task::from_path(task_path) {
            Ok(t) => t,
            Err(e) => {
                error!("Failed to load task {}: {}", task_name, e);
                task_results.push(TaskResultResponse {
                    task_id: Uuid::new_v4().to_string(),
                    task_name: task_name.clone(),
                    passed: false,
                    score: 0.0,
                    execution_time_ms: task_start.elapsed().as_millis() as i64,
                    steps: 0,
                    error: Some(format!("Failed to load task: {}", e)),
                });
                tasks_failed += 1;
                continue;
            }
        };

        // Create external agent from source code
        let agent = match ExternalAgent::from_source(
            &req.source_code,
            agent_name.to_string(),
            req.api_key.clone(),
            req.api_provider.clone(),
        )
        .await
        {
            Ok(a) => a,
            Err(e) => {
                error!("Failed to create agent for task {}: {}", task_name, e);
                task_results.push(TaskResultResponse {
                    task_id: Uuid::new_v4().to_string(),
                    task_name: task_name.clone(),
                    passed: false,
                    score: 0.0,
                    execution_time_ms: task_start.elapsed().as_millis() as i64,
                    steps: 0,
                    error: Some(format!("Failed to create agent: {}", e)),
                });
                tasks_failed += 1;
                continue;
            }
        };

        // Configure trial
        let trial_config = TrialConfig {
            trial_name: format!(
                "{}-{}",
                &req.agent_hash[..8.min(req.agent_hash.len())],
                task_name
            ),
            output_dir: output_dir.clone(),
            max_steps: config.evaluation.max_steps_per_task.unwrap_or(100),
            timeout_multiplier: 1.0,
            force_build: false,
            delete_container: true,
            agent_provider: req.api_provider.clone(),
            model_name: None,
        };

        // Run trial
        let runner = TrialRunner::new(trial_config);
        match runner.run(&task, &agent).await {
            Ok(result) => {
                let passed = result.success();
                let score = result.reward();
                let task_time = task_start.elapsed().as_millis() as i64;

                execution_log.push_str(&format!(
                    "Task {}: {} (score: {:.2}, steps: {}, time: {}ms)\n",
                    task_name,
                    if passed { "PASS" } else { "FAIL" },
                    score,
                    result.steps,
                    task_time
                ));

                if passed {
                    tasks_passed += 1;
                } else {
                    tasks_failed += 1;
                }

                task_results.push(TaskResultResponse {
                    task_id: Uuid::new_v4().to_string(),
                    task_name,
                    passed,
                    score,
                    execution_time_ms: task_time,
                    steps: result.steps,
                    error: result.error,
                });

                // Add LLM cost if agent used API
                if req.api_key.is_some() {
                    total_cost_usd += estimate_task_cost(result.steps);
                }
            }
            Err(e) => {
                error!("Task {} failed: {}", task_name, e);
                execution_log.push_str(&format!("Task {}: ERROR - {}\n", task_name, e));
                tasks_failed += 1;
                task_results.push(TaskResultResponse {
                    task_id: Uuid::new_v4().to_string(),
                    task_name,
                    passed: false,
                    score: 0.0,
                    execution_time_ms: task_start.elapsed().as_millis() as i64,
                    steps: 0,
                    error: Some(e.to_string()),
                });
            }
        }

        // Cleanup agent container
        if let Err(e) = agent.cleanup().await {
            warn!("Failed to cleanup agent container: {}", e);
        }
    }

    // Calculate final score
    let tasks_total = selected_tasks.len() as u32;
    let score = if tasks_total > 0 {
        tasks_passed as f64 / tasks_total as f64
    } else {
        0.0
    };

    let execution_time_ms = start.elapsed().as_millis() as i64;

    info!(
        "Evaluation complete for {}: score={:.2}, passed={}/{}, cost=${:.4}, time={}ms",
        agent_hash_short, score, tasks_passed, tasks_total, total_cost_usd, execution_time_ms
    );

    // Store evaluation in PostgreSQL if in server mode
    if let Some(pg) = &state.pg_storage {
        let eval_record = crate::pg_storage::EvaluationRecord {
            id: Uuid::new_v4().to_string(),
            submission_id: req.submission_id.clone(),
            agent_hash: req.agent_hash.clone(),
            miner_hotkey: req.miner_hotkey.clone(),
            score,
            tasks_passed: tasks_passed as i32,
            tasks_total: tasks_total as i32,
            tasks_failed: tasks_failed as i32,
            total_cost_usd,
            execution_time_ms: Some(execution_time_ms),
            task_results: Some(serde_json::to_value(&task_results).unwrap_or_default()),
            created_at: chrono::Utc::now().timestamp(),
        };

        if let Err(e) = pg.store_evaluation(&eval_record).await {
            error!("Failed to store evaluation in PostgreSQL: {}", e);
        } else {
            debug!("Stored evaluation {} in PostgreSQL", eval_record.id);
        }
    }

    Ok(Json(EvaluateResponse {
        success: true,
        error: None,
        score,
        tasks_passed,
        tasks_total,
        tasks_failed,
        total_cost_usd,
        execution_time_ms,
        task_results: Some(task_results),
        execution_log: Some(execution_log),
    }))
}

/// Estimate cost for LLM code review based on provider
fn estimate_review_cost(provider: &str) -> f64 {
    match provider.to_lowercase().as_str() {
        "openrouter" | "anthropic" | "claude" => 0.003,
        "openai" => 0.002,
        "chutes" | "deepseek" => 0.0005,
        "grok" => 0.002,
        _ => 0.002,
    }
}

/// Estimate cost per task step (LLM calls)
fn estimate_task_cost(steps: u32) -> f64 {
    // Average ~$0.002 per step for LLM calls
    (steps as f64) * 0.002
}

// ============================================================================
// /validate ENDPOINT
// ============================================================================

#[derive(Debug, Deserialize)]
pub struct ValidateRequest {
    pub source_code: String,
}

#[derive(Debug, Serialize)]
pub struct ValidateResponse {
    pub valid: bool,
    pub errors: Vec<String>,
}

pub async fn validate_source(
    State(state): State<Arc<ChallengeServerState>>,
    Json(req): Json<ValidateRequest>,
) -> Json<ValidateResponse> {
    let verification = state.whitelist.verify(&req.source_code);
    Json(ValidateResponse {
        valid: verification.valid,
        errors: verification.errors,
    })
}

// ============================================================================
// /config ENDPOINT
// ============================================================================

pub async fn get_config(State(state): State<Arc<ChallengeServerState>>) -> Json<serde_json::Value> {
    let config = state.config.read().await;
    Json(serde_json::json!({
        "challenge_id": state.challenge_id,
        "dataset": state.dataset_name(),
        "dataset_version": state.dataset_version(),
        "test_mode": state.test_mode,
        "tasks_per_evaluation": config.evaluation.tasks_per_evaluation,
        "max_steps_per_task": config.evaluation.max_steps_per_task,
        "max_concurrent_tasks": config.evaluation.max_concurrent_tasks_per_agent,
        "max_cost_per_task_usd": config.pricing.max_cost_per_task_usd,
        "max_total_cost_usd": config.pricing.max_total_cost_usd,
        "min_stake_tao": config.min_stake_tao,
    }))
}

// ============================================================================
// /leaderboard ENDPOINT
// ============================================================================

#[derive(Debug, Deserialize)]
pub struct LeaderboardQuery {
    pub limit: Option<usize>,
}

#[derive(Debug, Serialize)]
pub struct LeaderboardResponse {
    pub challenge_id: String,
    pub entries: Vec<LeaderboardEntryResponse>,
    pub total_count: usize,
}

#[derive(Debug, Serialize)]
pub struct LeaderboardEntryResponse {
    pub rank: u32,
    pub agent_hash: String,
    pub miner_hotkey: String,
    pub name: Option<String>,
    pub status: String,
    pub tasks_passed: i32,
    pub tasks_total: i32,
    pub success_rate: f64,
    pub evaluation_count: u32,
    pub manually_validated: bool,
    pub total_cost_usd: f64,
    pub weight: f64,
    pub submitted_at: String,
}

pub async fn get_leaderboard(
    State(state): State<Arc<ChallengeServerState>>,
    Query(query): Query<LeaderboardQuery>,
) -> Result<Json<LeaderboardResponse>, (StatusCode, String)> {
    let limit = query.limit.unwrap_or(100);

    // Get PostgreSQL storage (required for server mode)
    let pg = state.pg_storage.as_ref().ok_or_else(|| {
        (
            StatusCode::SERVICE_UNAVAILABLE,
            "PostgreSQL storage not available".to_string(),
        )
    })?;

    // Get leaderboard from PostgreSQL storage
    let lb = pg
        .get_agent_leaderboard(limit as i64)
        .await
        .map_err(|e| (StatusCode::INTERNAL_SERVER_ERROR, e.to_string()))?;

    // Find the winner (first manually_validated entry with >= 2 validators and >= 8 tasks passed per validator)
    let winner_hash: Option<String> = lb
        .iter()
        .find(|e| {
            e.manually_validated
                && e.num_validators >= 2
                && e.total_tasks_passed >= 8 * e.num_validators
        })
        .map(|e| e.agent_hash.clone());

    let entries: Vec<LeaderboardEntryResponse> = lb
        .iter()
        .enumerate()
        .map(|(i, e)| {
            let weight = if Some(&e.agent_hash) == winner_hash.as_ref() {
                1.0
            } else {
                0.0
            };
            // Calculate success rate as percentage
            let success_rate = if e.total_tasks > 0 {
                (e.total_tasks_passed as f64 / e.total_tasks as f64) * 100.0
            } else {
                0.0
            };

            LeaderboardEntryResponse {
                rank: (i + 1) as u32,
                agent_hash: e.agent_hash.clone(),
                miner_hotkey: e.miner_hotkey.clone(),
                name: e.name.clone(),
                status: e.status.clone(),
                tasks_passed: e.total_tasks_passed,
                tasks_total: e.total_tasks,
                success_rate,
                evaluation_count: e.num_validators as u32,
                manually_validated: e.manually_validated,
                total_cost_usd: e.total_cost_usd,
                weight,
                submitted_at: e.created_at.to_rfc3339(),
            }
        })
        .collect();

    let total_count = entries.len();

    Ok(Json(LeaderboardResponse {
        challenge_id: state.challenge_id.clone(),
        entries,
        total_count,
    }))
}

// ============================================================================
// LOCAL LLM PROXY (Validator Mode)
// ============================================================================

/// Load validator's sr25519 keypair from environment variable
///
/// Tries in order:
/// 1. VALIDATOR_SECRET
/// 2. VALIDATOR_SECRET_KEY (used by platform validator-node)
///
/// Supports:
/// - Hex-encoded 32-byte seed (with or without 0x prefix)
/// - URI format with derivation path (e.g., "mnemonic words//path")
/// - BIP39 mnemonic phrase (12 or 24 words)
fn load_validator_keypair() -> anyhow::Result<sp_core::sr25519::Pair> {
    use sp_core::{sr25519, Pair};

    let secret = std::env::var("VALIDATOR_SECRET")
        .or_else(|_| std::env::var("VALIDATOR_SECRET_KEY"))
        .map_err(|_| {
            anyhow::anyhow!("VALIDATOR_SECRET or VALIDATOR_SECRET_KEY environment variable not set")
        })?;

    let secret = secret.trim();
    let hex_str = secret.strip_prefix("0x").unwrap_or(secret);

    // Try hex seed first (32 bytes = 64 hex chars)
    if hex_str.len() == 64 {
        if let Ok(bytes) = hex::decode(hex_str) {
            if bytes.len() == 32 {
                let mut seed = [0u8; 32];
                seed.copy_from_slice(&bytes);
                return Ok(sr25519::Pair::from_seed(&seed));
            }
        }
    }

    // Try URI format (supports derivation paths like "mnemonic//hard/soft")
    // This is the most flexible format used by subkey and substrate tools
    if let Ok((pair, _)) = sr25519::Pair::from_string_with_seed(secret, None) {
        return Ok(pair);
    }

    // Try mnemonic phrase without derivation
    sr25519::Pair::from_phrase(secret, None)
        .map(|(pair, _)| pair)
        .map_err(|e| anyhow::anyhow!("Invalid secret key format: {:?}", e))
}

/// Request from agent inside task container
#[derive(Debug, Deserialize)]
pub struct LocalLlmProxyRequest {
    pub agent_hash: String,
    pub messages: Vec<serde_json::Value>,
    pub model: Option<String>,
    pub max_tokens: Option<u32>,
    pub temperature: Option<f32>,
    pub task_id: Option<String>,
}

/// POST /llm/proxy - Local LLM proxy for validator mode
///
/// Flow: Agent in container -> Validator's term-challenge -> Central server
/// The validator signs the request before forwarding to central.
pub async fn llm_local_proxy(
    State(state): State<Arc<ChallengeServerState>>,
    Json(req): Json<LocalLlmProxyRequest>,
) -> Result<Json<serde_json::Value>, (StatusCode, Json<serde_json::Value>)> {
    use sp_core::{sr25519, Pair};
    use std::time::{SystemTime, UNIX_EPOCH};

    // Get validator hotkey from environment
    let validator_hotkey = std::env::var("VALIDATOR_HOTKEY").unwrap_or_default();
    if validator_hotkey.is_empty() {
        return Err((
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(serde_json::json!({
                "success": false,
                "error": "Validator hotkey not configured (VALIDATOR_HOTKEY env var)"
            })),
        ));
    }

    // Load validator keypair for signing
    let keypair = load_validator_keypair().map_err(|e| {
        error!("Failed to load validator keypair: {}", e);
        (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(serde_json::json!({
                "success": false,
                "error": format!("Validator secret key not configured: {}", e)
            })),
        )
    })?;

    let timestamp = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .unwrap()
        .as_secs() as i64;

    // Sign with validator's sr25519 keypair
    // Message format must match what central server expects: "llm_chat:{timestamp}:{agent_hash}"
    let message = format!("llm_chat:{}:{}", timestamp, req.agent_hash);
    let signature_bytes = keypair.sign(message.as_bytes());
    let signature = format!("0x{}", hex::encode(signature_bytes.0));

    // Forward to central server via bridge
    let central_url = state.platform_client.base_url();
    let forward_url = format!(
        "{}/api/v1/bridge/{}/api/v1/llm/chat",
        central_url, state.challenge_id
    );

    let forward_payload = serde_json::json!({
        "validator_hotkey": validator_hotkey,
        "signature": signature,
        "timestamp": timestamp,
        "agent_hash": req.agent_hash,
        "messages": req.messages,
        "model": req.model,
        "max_tokens": req.max_tokens,
        "temperature": req.temperature,
        "task_id": req.task_id,
    });

    info!(
        "LLM local proxy: forwarding request for agent {} via bridge to {}",
        &req.agent_hash[..12.min(req.agent_hash.len())],
        forward_url
    );

    let client = reqwest::Client::new();
    let response = client
        .post(&forward_url)
        .header("Content-Type", "application/json")
        .json(&forward_payload)
        .send()
        .await
        .map_err(|e| {
            error!("Failed to forward LLM request: {}", e);
            (
                StatusCode::BAD_GATEWAY,
                Json(serde_json::json!({
                    "success": false,
                    "error": format!("Failed to reach central server: {}", e)
                })),
            )
        })?;

    let status = response.status();

    // Read body as text first to handle both JSON and non-JSON error responses
    let body_text = response.text().await.map_err(|e| {
        error!("LLM local proxy: failed to read response body: {}", e);
        (
            StatusCode::BAD_GATEWAY,
            Json(serde_json::json!({
                "success": false,
                "error": format!("Failed to read response from central server: {}", e)
            })),
        )
    })?;

    // Try to parse as JSON
    let body: serde_json::Value = match serde_json::from_str(&body_text) {
        Ok(json) => json,
        Err(parse_err) => {
            // Log the raw response for debugging (truncate if too long)
            let truncated = if body_text.len() > 500 {
                format!("{}...(truncated)", &body_text[..500])
            } else {
                body_text.clone()
            };

            warn!(
                "LLM local proxy: central server returned non-JSON (status {}): {}",
                status, truncated
            );

            // Preserve original status code, return structured error
            let http_status =
                StatusCode::from_u16(status.as_u16()).unwrap_or(StatusCode::BAD_GATEWAY);

            return Err((
                http_status,
                Json(serde_json::json!({
                    "success": false,
                    "error": format!("Invalid response from central server: {}", parse_err),
                    "status_code": status.as_u16(),
                    "raw_response": truncated,
                    "hint": "Check if central server is running and accessible"
                })),
            ));
        }
    };

    // Preserve the original HTTP status code
    let http_status = StatusCode::from_u16(status.as_u16()).unwrap_or(StatusCode::BAD_GATEWAY);

    if status.is_success() {
        Ok(Json(body))
    } else {
        // Log error response for debugging
        warn!(
            "LLM local proxy: central server returned error (status {}): {:?}",
            status, body
        );
        Err((http_status, Json(body)))
    }
}

/// POST /llm/proxy/stream - Streaming local LLM proxy for validator mode
///
/// Flow: Agent in container -> Validator's term-challenge -> Central server (streaming)
pub async fn llm_local_proxy_stream(
    State(state): State<Arc<ChallengeServerState>>,
    Json(req): Json<LocalLlmProxyRequest>,
) -> Result<axum::response::Response, (StatusCode, Json<serde_json::Value>)> {
    use axum::body::Body;
    use sp_core::{sr25519, Pair};
    use std::time::{SystemTime, UNIX_EPOCH};

    // Get validator hotkey from environment
    let validator_hotkey = std::env::var("VALIDATOR_HOTKEY").unwrap_or_default();
    if validator_hotkey.is_empty() {
        return Err((
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(serde_json::json!({
                "success": false,
                "error": "Validator hotkey not configured (VALIDATOR_HOTKEY env var)"
            })),
        ));
    }

    // Load validator keypair for signing
    let keypair = load_validator_keypair().map_err(|e| {
        error!("Failed to load validator keypair: {}", e);
        (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(serde_json::json!({
                "success": false,
                "error": format!("Validator secret key not configured: {}", e)
            })),
        )
    })?;

    let timestamp = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .unwrap()
        .as_secs() as i64;

    // Sign with validator's sr25519 keypair
    // Message format must match what central server expects: "llm_chat:{timestamp}:{agent_hash}"
    let message = format!("llm_chat:{}:{}", timestamp, req.agent_hash);
    let signature_bytes = keypair.sign(message.as_bytes());
    let signature = format!("0x{}", hex::encode(signature_bytes.0));

    // Forward to central server via bridge (streaming endpoint)
    let central_url = state.platform_client.base_url();
    let forward_url = format!(
        "{}/api/v1/bridge/{}/api/v1/llm/chat/stream",
        central_url, state.challenge_id
    );

    let forward_payload = serde_json::json!({
        "validator_hotkey": validator_hotkey,
        "signature": signature,
        "timestamp": timestamp,
        "agent_hash": req.agent_hash,
        "messages": req.messages,
        "model": req.model,
        "max_tokens": req.max_tokens,
        "temperature": req.temperature,
        "task_id": req.task_id,
    });

    info!(
        "LLM local proxy stream: forwarding request for agent {} via bridge to {}",
        &req.agent_hash[..12.min(req.agent_hash.len())],
        forward_url
    );

    let client = reqwest::Client::new();
    let response = client
        .post(&forward_url)
        .header("Content-Type", "application/json")
        .json(&forward_payload)
        .send()
        .await
        .map_err(|e| {
            error!("Failed to forward LLM stream request: {}", e);
            (
                StatusCode::BAD_GATEWAY,
                Json(serde_json::json!({
                    "success": false,
                    "error": format!("Failed to reach central server: {}", e)
                })),
            )
        })?;

    let status = response.status();
    if !status.is_success() {
        let error_text = response.text().await.unwrap_or_default();
        return Err((
            StatusCode::from_u16(status.as_u16()).unwrap_or(StatusCode::BAD_GATEWAY),
            Json(serde_json::json!({
                "success": false,
                "error": error_text
            })),
        ));
    }

    // Stream the response through
    let stream = response.bytes_stream();
    let body = Body::from_stream(stream);

    Ok(axum::response::Response::builder()
        .status(StatusCode::OK)
        .header("Content-Type", "text/event-stream")
        .header("Cache-Control", "no-cache")
        .header("Connection", "keep-alive")
        .body(body)
        .unwrap())
}

// ============================================================================
// FALLBACK/ERROR HANDLERS
// ============================================================================

/// Global fallback handler for unmatched routes (404)
pub async fn fallback_handler(uri: axum::http::Uri) -> (StatusCode, Json<serde_json::Value>) {
    warn!("404 Not Found: {}", uri);
    (
        StatusCode::NOT_FOUND,
        Json(serde_json::json!({
            "error": "Not Found",
            "message": format!("No route matches '{}'", uri.path()),
            "status": 404
        })),
    )
}

// ============================================================================
// /health ENDPOINT
// ============================================================================

/// Simple health check for load balancers
pub async fn health_check() -> &'static str {
    "OK"
}

/// Detailed health check response
#[derive(Debug, Serialize)]
pub struct HealthStatus {
    pub status: String,
    pub database: Option<String>,
    pub docker: Option<String>,
    pub uptime_secs: u64,
}

/// Static start time for uptime calculation
static START_TIME: std::sync::OnceLock<std::time::Instant> = std::sync::OnceLock::new();

/// GET /health/detailed - Detailed health check with dependency verification
pub async fn health_check_detailed(
    State(state): State<Arc<ChallengeServerState>>,
) -> Result<Json<HealthStatus>, (StatusCode, Json<HealthStatus>)> {
    let start = START_TIME.get_or_init(std::time::Instant::now);
    let uptime_secs = start.elapsed().as_secs();

    let mut status = HealthStatus {
        status: "ok".to_string(),
        database: None,
        docker: None,
        uptime_secs,
    };

    let mut all_healthy = true;

    // Check database connectivity
    if let Some(ref pg) = state.pg_storage {
        match pg.get_current_epoch().await {
            Ok(_) => {
                status.database = Some("healthy".to_string());
            }
            Err(e) => {
                status.database = Some(format!("unhealthy: {}", e));
                all_healthy = false;
            }
        }
    } else {
        status.database = Some("not_configured".to_string());
    }

    // Check Docker connectivity
    match bollard::Docker::connect_with_local_defaults() {
        Ok(docker) => match docker.ping().await {
            Ok(_) => {
                status.docker = Some("healthy".to_string());
            }
            Err(e) => {
                status.docker = Some(format!("unhealthy: {}", e));
                all_healthy = false;
            }
        },
        Err(e) => {
            status.docker = Some(format!("connection_failed: {}", e));
            all_healthy = false;
        }
    }

    if all_healthy {
        status.status = "ok".to_string();
        Ok(Json(status))
    } else {
        status.status = "degraded".to_string();
        Err((StatusCode::SERVICE_UNAVAILABLE, Json(status)))
    }
}

// ============================================================================
// SERVER STARTUP
// ============================================================================

pub async fn run_server(
    config: ChallengeConfig,
    platform_url: &str,
    challenge_id: &str,
    host: &str,
    port: u16,
) -> anyhow::Result<()> {
    run_server_with_mode(config, platform_url, challenge_id, host, port, false).await
}

pub async fn run_server_with_mode(
    config: ChallengeConfig,
    platform_url: &str,
    challenge_id: &str,
    host: &str,
    port: u16,
    test_mode: bool,
) -> anyhow::Result<()> {
    // Initialize PostgreSQL if DATABASE_URL is set (server mode)
    let pg_storage = if let Ok(database_url) = std::env::var("DATABASE_URL") {
        info!("DATABASE_URL found, initializing PostgreSQL storage (server mode)");
        match PgStorage::new(&database_url).await {
            Ok(pg) => {
                info!("PostgreSQL storage initialized successfully");

                // Run recovery tasks (stale claims, expired evaluations)
                if let Err(e) = pg.run_recovery().await {
                    warn!("Recovery tasks failed (non-fatal): {}", e);
                }

                Some(pg)
            }
            Err(e) => {
                error!("Failed to initialize PostgreSQL: {}", e);
                warn!("Continuing in validator mode (no persistent storage)");
                None
            }
        }
    } else {
        debug!("No DATABASE_URL, running in validator mode");
        None
    };

    // Load validator whitelist from env (comma-separated SS58 hotkeys)
    let validator_whitelist: Vec<String> = std::env::var("VALIDATOR_WHITELIST")
        .unwrap_or_default()
        .split(',')
        .map(|s| s.trim().to_string())
        .filter(|s| !s.is_empty())
        .collect();

    if !validator_whitelist.is_empty() {
        info!(
            "Loaded {} validators in whitelist",
            validator_whitelist.len()
        );
    }

    // Initialize container backend for image building
    match crate::container_backend::create_backend().await {
        Ok(backend) => {
            // Try to build the compiler image at startup
            // This is not fatal - the image may already exist or be built externally
            match crate::compiler::build_compiler_image(&backend).await {
                Ok(()) => info!("Compiler image is ready"),
                Err(e) => {
                    warn!(
                        "Could not build compiler image (this may be expected in containerized environments): {}",
                        e
                    );
                    warn!("Ensure term-compiler:latest is available before running compilations");
                }
            }
        }
        Err(e) => {
            warn!("Could not initialize container backend at startup: {}", e);
        }
    }

    let state = Arc::new(ChallengeServerState::with_options(
        config,
        platform_url,
        challenge_id,
        test_mode,
        pg_storage,
        validator_whitelist,
    ));

    // Initialize block sync to keep epoch in sync with the blockchain
    // This fetches current block/tempo from platform and polls for updates
    info!("Initializing block sync for epoch tracking...");
    let block_sync_config = BlockSyncConfig {
        platform_url: platform_url.to_string(),
        poll_interval_secs: 12, // ~1 block
        ..Default::default()
    };
    let block_sync = BlockSync::new(
        block_sync_config,
        state.epoch_calculator.clone(),
        state.pg_storage.as_ref().map(|pg| Arc::new(pg.clone())),
    );

    // Start block sync (polls platform for block updates and syncs epoch)
    if let Err(e) = block_sync.start().await {
        warn!(
            "Failed to start block sync: {} (epoch tracking may be delayed)",
            e
        );
    } else {
        info!(
            "Block sync started: epoch_zero_start_block={}, tempo={}",
            crate::epoch::EPOCH_ZERO_START_BLOCK,
            state.epoch_calculator.tempo()
        );
    }

    // Pre-download tasks at startup
    info!(
        "Pre-downloading tasks for dataset: {}",
        state.dataset_name()
    );
    match state.ensure_tasks_cached().await {
        Ok(tasks) => info!("Cached {} tasks", tasks.len()),
        Err(e) => warn!(
            "Failed to pre-download tasks: {} (will retry on first evaluation)",
            e
        ),
    }

    // SECURITY: Configure CORS with specific origins instead of Any
    // In production, set ALLOWED_ORIGINS env var to comma-separated list of allowed origins
    let allowed_origins = std::env::var("ALLOWED_ORIGINS")
        .unwrap_or_else(|_| "http://localhost:3000,http://localhost:8080".to_string());

    let cors = if allowed_origins == "*" {
        CorsLayer::new()
            .allow_origin(Any)
            .allow_methods(Any)
            .allow_headers(Any)
    } else {
        use tower_http::cors::AllowOrigin;
        let origins: Vec<_> = allowed_origins
            .split(',')
            .filter_map(|s| s.trim().parse().ok())
            .collect();
        CorsLayer::new()
            .allow_origin(AllowOrigin::list(origins))
            .allow_methods(Any)
            .allow_headers(Any)
    };

    // Base routes (always available)
    let mut app = Router::new()
        .route("/health", get(health_check))
        .route("/health/detailed", get(health_check_detailed))
        .route("/get_weights", get(get_weights))
        .route("/validate", post(validate_source))
        .route("/config", get(get_config))
        .route("/leaderboard", get(get_leaderboard))
        // Local LLM proxy for validator mode (agent -> validator -> central)
        .route("/llm/proxy", post(llm_local_proxy))
        .route("/llm/proxy/stream", post(llm_local_proxy_stream));

    // /evaluate only available in validator mode (no pg_storage)
    // In server mode, evaluations are done by validators via /api/v1/validator/* endpoints
    if state.pg_storage.is_none() {
        app = app.route("/evaluate", post(evaluate_agent));

        // In validator mode, try to start the evaluation worker
        // Worker requires VALIDATOR_SECRET or VALIDATOR_SECRET_KEY to sign requests
        match crate::server::load_validator_keypair() {
            Ok(keypair) => {
                info!("Starting validator evaluation worker...");

                let validator_hotkey = {
                    use sp_core::crypto::Ss58Codec;
                    use sp_core::Pair as _;
                    keypair.public().to_ss58check()
                };

                // Get platform URL and challenge ID from state/env
                let worker_platform_url = std::env::var("PLATFORM_URL")
                    .unwrap_or_else(|_| "https://chain.platform.network".to_string());
                let worker_challenge_id = challenge_id.to_string();

                // Spawn WebSocket client to receive events
                let event_rx =
                    crate::validator_ws_client::spawn(worker_platform_url.clone(), keypair.clone());

                // Spawn worker
                tokio::spawn(async move {
                    match crate::validator_worker::ValidatorWorker::new(
                        worker_platform_url,
                        worker_challenge_id,
                        keypair,
                    )
                    .await
                    {
                        Ok(worker) => worker.run(event_rx).await,
                        Err(e) => {
                            tracing::error!("Failed to create validator worker: {}", e);
                        }
                    }
                });

                info!(
                    "Validator worker started (hotkey: {}...)",
                    &validator_hotkey[..16]
                );
            }
            Err(e) => {
                warn!(
                    "Validator worker NOT started: {}. Set VALIDATOR_SECRET or VALIDATOR_SECRET_KEY to enable.",
                    e
                );
                // Continue without worker - server will still serve /evaluate endpoint
            }
        }
    }

    let mut app = app
        .layer(cors.clone())
        .layer(RequestBodyLimitLayer::new(10 * 1024 * 1024)) // 10MB limit
        .layer(TraceLayer::new_for_http())
        .with_state(state.clone());

    // API v1 routes (only in server mode with PostgreSQL)
    if let Some(ref pg) = state.pg_storage {
        info!("Enabling submission API endpoints (server mode)");

        // Get platform URL for validator communication
        let platform_url = state.platform_client.base_url().to_string();

        // Internal evaluation URL (same server)
        let evaluate_url = format!("http://127.0.0.1:{}", port);

        // Initialize WebSocket client for validator notifications
        let platform_ws_client = crate::platform_ws_client::create_from_env().await;

        // Initialize metagraph cache for stake-based validator auth
        let metagraph_cache = Arc::new(crate::metagraph_cache::MetagraphCache::new(
            platform_url.clone(),
        ));
        // Start background refresh (every 60s)
        metagraph_cache.clone().start_background_refresh();
        // Initial refresh
        if let Err(e) = metagraph_cache.refresh().await {
            warn!("Initial metagraph cache refresh failed: {} (will retry)", e);
        }

        // Start periodic maintenance task (every 60 seconds)
        // This expires old evaluation windows and marks submissions as completed
        let maintenance_pg = pg.clone();
        tokio::spawn(async move {
            let mut interval = tokio::time::interval(std::time::Duration::from_secs(60));
            loop {
                interval.tick().await;
                if let Err(e) = maintenance_pg.run_maintenance().await {
                    tracing::warn!("Periodic maintenance error: {:?}", e);
                }
            }
        });
        info!("Started periodic maintenance task (every 60s)");

        // Clone storage for API state
        let api_state = Arc::new(ApiState {
            storage: pg.clone(),
            auth: AuthManager::with_whitelist(state.auth_manager.get_whitelist().await),
            platform_url,
            evaluate_url: Some(evaluate_url),
            challenge_id: challenge_id.to_string(),
            platform_ws_client: platform_ws_client.map(Arc::new),
            metagraph_cache: Some(metagraph_cache),
        });

        let api_routes = Router::new()
            .route("/submit", post(api::submit_agent))
            .route("/leaderboard", get(api::get_leaderboard))
            .route("/leaderboard/:agent_hash", get(api::get_agent_details))
            .route("/agent/:agent_hash/code", get(api::get_agent_code))
            .route("/my/agents", post(api::list_my_agents))
            .route(
                "/my/agents/:agent_hash/source",
                post(api::get_my_agent_source),
            )
            .route("/validator/claim_jobs", post(api::claim_jobs))
            .route("/validator/heartbeat", post(api::validator_heartbeat))
            .route("/validator/log_task", post(api::log_task))
            .route("/validator/submit_result", post(api::submit_result))
            .route("/validator/my_jobs", post(api::get_my_jobs))
            .route("/validators/readiness", get(api::get_validators_readiness))
            .route("/validators/ready", get(api::get_ready_validators))
            .route(
                "/validator/get_evaluation_progress",
                post(api::get_evaluation_progress),
            )
            .route(
                "/validator/agent_status/:agent_hash",
                get(api::get_agent_eval_status),
            )
            // Binary download endpoint for validators
            .route(
                "/validator/download_binary/:agent_hash",
                post(api::download_binary),
            )
            // Task observability endpoints
            .route("/agent/:agent_hash/tasks", get(api::get_agent_tasks))
            .route(
                "/agent/:agent_hash/tasks/:task_id",
                get(api::get_agent_task_detail),
            )
            .route("/agent/:agent_hash/progress", get(api::get_agent_progress))
            // Detailed agent status (all phases and timings)
            .route("/agent/:agent_hash/status", get(api::get_detailed_status))
            .route(
                "/validator/:hotkey/evaluations",
                get(api::get_validator_evaluations_list),
            )
            .route(
                "/validator/:hotkey/agent/:agent_hash/tasks",
                get(api::get_validator_agent_tasks),
            )
            .route("/status", get(api::get_status))
            // LLM proxy endpoints (validator authenticated - central server)
            .route("/llm/chat", post(api::llm_chat_proxy))
            .route("/llm/chat/stream", post(api::llm_chat_proxy_stream))
            // Sudo endpoints (subnet owner only)
            .route(
                "/sudo/relaunch/:agent_hash",
                post(api::sudo_relaunch_evaluation),
            )
            .route("/sudo/approve/:agent_hash", post(api::sudo_approve_agent))
            .route("/sudo/reject/:agent_hash", post(api::sudo_reject_agent))
            .route(
                "/sudo/set_status/:agent_hash",
                post(api::sudo_set_agent_status),
            )
            .route("/sudo/cancel/:agent_hash", post(api::sudo_cancel_agent))
            // Public endpoints (no authentication required)
            .route("/pending", get(api::get_pending_submissions))
            .route("/assignments", get(api::get_all_assignments))
            .route("/assignments/:agent_hash", get(api::get_agent_assignments))
            .layer(cors.clone()) // Use same CORS config as main routes
            .with_state(api_state);

        app = app.nest("/api/v1", api_routes);
    }

    // Add global fallback handler for 404
    app = app.fallback(fallback_handler);

    // Start compile worker in server mode (compiles agents in background)
    // Need to create WebSocket client for notifying validators when binary is ready
    if state.is_server_mode() {
        if let Some(ref pg) = state.pg_storage {
            info!("Starting agent compile worker...");

            // Create a separate WebSocket client for the compile worker
            let compile_ws_client = crate::platform_ws_client::create_from_env().await;

            // Get platform URL for validator assignment
            let compile_platform_url = state.platform_client.base_url().to_string();

            crate::compile_worker::spawn_compile_worker(
                Arc::new(pg.clone()),
                compile_ws_client.map(Arc::new),
                crate::compile_worker::CompileWorkerConfig::default(),
                compile_platform_url.clone(),
            );

            // Start assignment monitor to detect and reassign stale validator assignments
            info!("Starting assignment monitor...");
            crate::assignment_monitor::spawn_assignment_monitor(
                Arc::new(pg.clone()),
                compile_platform_url,
                crate::assignment_monitor::AssignmentMonitorConfig::default(),
            );
        }
    }

    let addr = format!("{}:{}", host, port);
    let listener = tokio::net::TcpListener::bind(&addr).await?;

    info!("╔══════════════════════════════════════════════════════════════╗");
    info!("║     Terminal Benchmark Challenge - Production Server        ║");
    info!("╠══════════════════════════════════════════════════════════════╣");
    info!("║  Challenge ID: {:<45} ║", challenge_id);
    info!("║  Platform URL: {:<45} ║", platform_url);
    info!("║  Listening on: {:<45} ║", addr);
    info!(
        "║  Dataset: {:<50} ║",
        format!(
            "{}@{}",
            if test_mode {
                TEST_DATASET
            } else {
                DEFAULT_DATASET
            },
            if test_mode {
                TEST_DATASET_VERSION
            } else {
                DEFAULT_DATASET_VERSION
            }
        )
    );
    info!(
        "║  Dataset Mode: {:<45} ║",
        if test_mode { "TEST" } else { "PRODUCTION" }
    );
    info!(
        "║  Storage Mode: {:<45} ║",
        if state.is_server_mode() {
            "SERVER (PostgreSQL)"
        } else {
            "VALIDATOR (API only)"
        }
    );
    info!(
        "║  Epoch Config: start_block={}, tempo={}             ║",
        crate::epoch::EPOCH_ZERO_START_BLOCK,
        state.epoch_calculator.tempo()
    );
    info!(
        "║  Current: block={}, epoch={}                           ║",
        state.current_block(),
        state.current_epoch()
    );
    info!("╠══════════════════════════════════════════════════════════════╣");
    info!("║  Endpoints:                                                  ║");
    info!("║    GET  /health      - Health check                          ║");
    info!("║    GET  /get_weights - Deterministic weights (epoch)         ║");
    info!("║    POST /evaluate    - Run agent on real tasks               ║");
    info!("║    POST /validate    - Whitelist validation                  ║");
    info!("║    GET  /config      - Challenge configuration               ║");
    info!("║    GET  /leaderboard - Challenge leaderboard                 ║");
    if state.is_server_mode() {
        info!("╠══════════════════════════════════════════════════════════════╣");
        info!("║  API v1 (Server Mode):                                       ║");
        info!("║    POST /api/v1/submit              - Submit agent           ║");
        info!("║    GET  /api/v1/leaderboard         - Get leaderboard        ║");
        info!("║    GET  /api/v1/leaderboard/:hash   - Get agent details      ║");
        info!("║    POST /api/v1/my/agents           - List my agents         ║");
        info!("║    POST /api/v1/my/agents/:h/source - Get my agent source    ║");
        info!("║    POST /api/v1/validator/claim_jobs - Claim jobs (batch)     ║");
        info!("║    POST /api/v1/validator/log_task - Log task (realtime)     ║");
        info!("║    POST /api/v1/validator/submit_result - Submit evaluation  ║");
        info!("║    POST /api/v1/validator/my_jobs - Get my pending jobs      ║");
        info!("║    POST /api/v1/validator/get_evaluation_progress - Resume   ║");
        info!("║    GET  /api/v1/validator/agent_status/:h - Agent eval status║");
        info!("║    GET  /api/v1/status              - Challenge status       ║");
        info!("╠══════════════════════════════════════════════════════════════╣");
        info!("║  Public API (no auth):                                       ║");
        info!("║    GET  /api/v1/pending             - Pending submissions    ║");
        info!("║    GET  /api/v1/assignments         - All agent assignments  ║");
        info!("║    GET  /api/v1/assignments/:hash   - Agent's validators     ║");
    }
    info!("╚══════════════════════════════════════════════════════════════╝");

    // Setup graceful shutdown
    let shutdown_state = state.clone();
    let shutdown_signal = async move {
        let ctrl_c = async {
            tokio::signal::ctrl_c()
                .await
                .expect("Failed to install Ctrl+C handler");
        };

        #[cfg(unix)]
        let terminate = async {
            tokio::signal::unix::signal(tokio::signal::unix::SignalKind::terminate())
                .expect("Failed to install SIGTERM handler")
                .recv()
                .await;
        };

        #[cfg(not(unix))]
        let terminate = std::future::pending::<()>();

        tokio::select! {
            _ = ctrl_c => {},
            _ = terminate => {},
        }

        info!("Shutdown signal received, starting graceful shutdown...");

        // Run maintenance tasks before shutdown
        if let Some(ref pg) = shutdown_state.pg_storage {
            info!("Running final maintenance tasks...");
            if let Err(e) = pg.run_maintenance().await {
                warn!("Maintenance task error during shutdown: {:?}", e);
            }
        }

        info!("Graceful shutdown complete");
    };

    axum::serve(listener, app)
        .with_graceful_shutdown(shutdown_signal)
        .await?;

    Ok(())
}
