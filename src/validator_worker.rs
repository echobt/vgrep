//! Validator Worker - Handles evaluation assignments
//!
//! Responsibilities:
//! 1. Recover pending assignments on startup and after reconnection
//! 2. Poll /api/v1/validator/my_jobs every 1 minute (fallback)
//! 3. Handle binary_ready events from WebSocket
//! 4. Download binaries, run evaluation in Docker, submit results
//! 5. Load tasks from terminal-bench@2.0 registry (first 30 tasks)

use crate::bench::registry::RegistryClient;
use crate::container_backend::{ContainerBackend, ContainerHandle, SandboxConfig};
use crate::task::{Task, TaskRegistry};
use crate::validator_ws_client::ValidatorEvent;
use anyhow::{Context, Result};
use base64::Engine;
use sp_core::{sr25519, Pair};
use std::collections::{HashMap, HashSet};
use std::sync::Arc;
use std::time::Duration;
use tokio::sync::{mpsc, RwLock, Semaphore};
use tracing::{debug, error, info, warn};

/// Polling interval for pending jobs
const POLL_INTERVAL: Duration = Duration::from_secs(60);

/// Number of tasks to evaluate each agent on
const TASKS_PER_EVALUATION: usize = 30;

/// Number of tasks per validator (30 total / 3 validators = 10)
const TASKS_PER_VALIDATOR: usize = 10;

/// Maximum concurrent task containers (prevents resource exhaustion)
const MAX_CONCURRENT_TASK_CONTAINERS: usize = 5;

/// Dataset to load tasks from
const TASK_DATASET_NAME: &str = "terminal-bench";
const TASK_DATASET_VERSION: &str = "2.0";

/// Result of an evaluation
#[derive(Debug)]
pub struct EvalResult {
    pub score: f64,
    pub tasks_passed: i32,
    pub tasks_total: i32,
    pub tasks_failed: i32,
    pub total_cost: f64,
}

/// Result of a single task execution
#[derive(Debug)]
struct TaskResult {
    passed: bool,
    duration_ms: i64,
    error: Option<String>,
    /// Agent stderr output (for debugging)
    agent_stderr: Option<String>,
    /// Test script output
    test_output: Option<String>,
    /// Number of steps executed by the agent
    steps_executed: Option<i32>,
}

pub struct ValidatorWorker {
    platform_url: String,
    challenge_id: String,
    keypair: sr25519::Pair,
    validator_hotkey: String,
    http_client: reqwest::Client,
    /// Track in-progress evaluations to avoid duplicates
    in_progress: Arc<RwLock<HashSet<String>>>,
    /// Loaded task registry (first 30 tasks from terminal-bench@2.0)
    task_registry: Arc<RwLock<Option<TaskRegistry>>>,
    /// Container backend for running tasks (broker or direct Docker)
    container_backend: Arc<dyn ContainerBackend>,
    /// Binary cache to avoid re-downloading (agent_hash -> binary)
    binary_cache: Arc<RwLock<HashMap<String, Vec<u8>>>>,
    /// Semaphore to limit concurrent task containers
    task_container_semaphore: Arc<Semaphore>,
}

impl ValidatorWorker {
    pub async fn new(
        platform_url: String,
        challenge_id: String,
        keypair: sr25519::Pair,
    ) -> Result<Self> {
        use sp_core::crypto::Ss58Codec;
        let validator_hotkey = keypair.public().to_ss58check();

        // Create container backend (will use broker if available, Docker as fallback)
        let container_backend = crate::container_backend::create_backend()
            .await
            .context("Failed to create container backend")?;

        // Cleanup stale task containers from previous runs
        // This prevents orphaned containers from accumulating after crashes/restarts
        match container_backend.cleanup(&challenge_id).await {
            Ok(count) => {
                if count > 0 {
                    info!(
                        "Cleaned up {} stale task containers from previous runs",
                        count
                    );
                }
            }
            Err(e) => {
                warn!("Failed to cleanup stale containers at startup: {}", e);
                // Continue anyway - stale containers are not fatal
            }
        }

        // Cleanup orphan volumes from previous runs
        // This prevents disk space from being consumed by unused volumes
        match container_backend.cleanup_volumes(&challenge_id).await {
            Ok(count) => {
                if count > 0 {
                    info!("Cleaned up {} orphan volumes from previous runs", count);
                }
            }
            Err(e) => {
                warn!("Failed to cleanup orphan volumes at startup: {}", e);
            }
        }

        Ok(Self {
            platform_url,
            challenge_id,
            keypair,
            validator_hotkey,
            http_client: reqwest::Client::builder()
                .timeout(Duration::from_secs(300))
                .build()
                .unwrap_or_default(),
            in_progress: Arc::new(RwLock::new(HashSet::new())),
            task_registry: Arc::new(RwLock::new(None)),
            container_backend,
            binary_cache: Arc::new(RwLock::new(HashMap::new())),
            task_container_semaphore: Arc::new(Semaphore::new(MAX_CONCURRENT_TASK_CONTAINERS)),
        })
    }

    /// Load tasks from terminal-bench@2.0 registry
    async fn load_tasks(&self) -> Result<()> {
        // Check if already loaded
        {
            let guard = self.task_registry.read().await;
            if guard.is_some() {
                return Ok(());
            }
        }

        info!(
            "Loading tasks from {}@{}...",
            TASK_DATASET_NAME, TASK_DATASET_VERSION
        );

        // Download dataset
        let mut client = RegistryClient::new();
        let task_paths = client
            .download_dataset(TASK_DATASET_NAME, TASK_DATASET_VERSION, false)
            .await
            .context("Failed to download terminal-bench@2.0 dataset")?;

        info!("Downloaded {} tasks from registry", task_paths.len());

        // Create task registry from downloaded paths (take first 30)
        let tasks_dir = crate::bench::registry::cache_dir();
        let registry = TaskRegistry::new(tasks_dir)?;

        let task_count = registry.count();
        info!(
            "Loaded {} tasks into registry (using first {})",
            task_count, TASKS_PER_EVALUATION
        );

        let mut guard = self.task_registry.write().await;
        *guard = Some(registry);

        Ok(())
    }

    /// Get the first N tasks for evaluation (sorted by ID for determinism)
    async fn get_evaluation_tasks(&self) -> Result<Vec<Task>> {
        // Ensure tasks are loaded
        self.load_tasks().await?;

        let guard = self.task_registry.read().await;
        let registry = guard
            .as_ref()
            .ok_or_else(|| anyhow::anyhow!("Task registry not loaded"))?;

        // Get all tasks, sort by ID for deterministic selection, then take first N
        let mut task_infos: Vec<_> = registry.list_tasks();
        task_infos.sort_by(|a, b| a.id.cmp(&b.id));

        let tasks: Vec<Task> = task_infos
            .into_iter()
            .take(TASKS_PER_EVALUATION)
            .filter_map(|info| registry.get(&info.id).cloned())
            .collect();

        if tasks.is_empty() {
            anyhow::bail!("No tasks available for evaluation");
        }

        info!("Selected {} tasks for evaluation", tasks.len());
        Ok(tasks)
    }

    /// Check broker WSS connectivity before starting validation
    async fn check_broker_connectivity(&self) -> bool {
        info!("Checking broker WSS connectivity...");

        // Try to get broker URL from container backend
        let broker_url = std::env::var("BROKER_WSS_URL")
            .unwrap_or_else(|_| "wss://broker.platform.network".to_string());

        // Simple connectivity check - try to establish connection
        match tokio_tungstenite::connect_async(&broker_url).await {
            Ok((_, _)) => {
                info!("Broker WSS connectivity OK: {}", broker_url);
                true
            }
            Err(e) => {
                warn!("Broker WSS connectivity FAILED: {} - {}", broker_url, e);
                warn!("Validation may fail if broker is required for container execution");
                false
            }
        }
    }

    /// Main entry point - runs forever
    pub async fn run(&self, mut event_rx: mpsc::Receiver<ValidatorEvent>) {
        info!("Validator worker starting...");

        // 0. Check broker connectivity (non-blocking warning)
        self.check_broker_connectivity().await;

        // 1. Recover pending assignments on startup
        self.recover_pending_assignments().await;

        // 2. Start polling ticker
        let poll_handle = {
            let worker = self.clone_ref();
            tokio::spawn(async move {
                worker.poll_loop().await;
            })
        };

        // 3. Handle WebSocket events
        while let Some(event) = event_rx.recv().await {
            match event {
                ValidatorEvent::BinaryReady { agent_hash, .. } => {
                    let worker = self.clone_ref();
                    tokio::spawn(async move {
                        worker.handle_binary_ready(&agent_hash).await;
                    });
                }
                ValidatorEvent::NewSubmissionAssigned { agent_hash, .. } => {
                    // Just log - we wait for binary_ready before evaluating
                    info!(
                        "Noted assignment for agent {} (waiting for binary)",
                        &agent_hash[..16.min(agent_hash.len())]
                    );
                }
                ValidatorEvent::Reconnected => {
                    // Recover pending after reconnection
                    info!("WebSocket reconnected, recovering pending assignments...");
                    self.recover_pending_assignments().await;
                }
            }
        }

        poll_handle.abort();
    }

    fn clone_ref(&self) -> Self {
        Self {
            platform_url: self.platform_url.clone(),
            challenge_id: self.challenge_id.clone(),
            keypair: self.keypair.clone(),
            validator_hotkey: self.validator_hotkey.clone(),
            http_client: self.http_client.clone(),
            in_progress: self.in_progress.clone(),
            task_registry: self.task_registry.clone(),
            container_backend: self.container_backend.clone(),
            binary_cache: self.binary_cache.clone(),
            task_container_semaphore: self.task_container_semaphore.clone(),
        }
    }

    /// Called on startup AND after reconnection
    pub async fn recover_pending_assignments(&self) {
        info!("Recovering pending assignments...");

        match self.fetch_my_jobs().await {
            Ok(jobs) => {
                let ready_count = jobs.iter().filter(|j| j.binary_ready).count();
                info!(
                    "Found {} pending jobs ({} with binary ready)",
                    jobs.len(),
                    ready_count
                );

                for job in jobs {
                    if job.binary_ready {
                        let worker = self.clone_ref();
                        let agent_hash = job.agent_hash.clone();
                        tokio::spawn(async move {
                            worker.handle_binary_ready(&agent_hash).await;
                        });
                    }
                }
            }
            Err(e) => {
                error!("Failed to fetch pending jobs: {}", e);
            }
        }
    }

    /// Polling loop - every 1 minute
    async fn poll_loop(&self) {
        let mut interval = tokio::time::interval(POLL_INTERVAL);

        loop {
            interval.tick().await;
            debug!("Polling for pending jobs...");

            match self.fetch_my_jobs().await {
                Ok(jobs) => {
                    if jobs.is_empty() {
                        debug!("No pending jobs");
                    } else {
                        info!("Found {} pending jobs", jobs.len());
                    }

                    // Use write lock to atomically check and add to in_progress
                    // This prevents race conditions where the same job could be started twice
                    let mut in_progress = self.in_progress.write().await;

                    for job in jobs {
                        if job.binary_ready && !in_progress.contains(&job.agent_hash) {
                            // Mark as in progress BEFORE spawning task
                            in_progress.insert(job.agent_hash.clone());
                            drop(in_progress);

                            let worker = self.clone_ref();
                            let agent_hash = job.agent_hash.clone();
                            tokio::spawn(async move {
                                worker.run_evaluation(&agent_hash).await;
                            });

                            break; // One at a time to avoid overload
                        }
                    }
                }
                Err(e) => {
                    warn!("Poll failed: {}", e);
                }
            }
        }
    }

    /// Handle binary_ready event from WebSocket
    pub async fn handle_binary_ready(&self, agent_hash: &str) {
        // Atomically check and add to in_progress
        {
            let mut in_progress = self.in_progress.write().await;
            if in_progress.contains(agent_hash) {
                debug!(
                    "Agent {} already in progress, skipping",
                    &agent_hash[..16.min(agent_hash.len())]
                );
                return;
            }
            in_progress.insert(agent_hash.to_string());
        }

        self.run_evaluation(agent_hash).await;
    }

    /// Run evaluation (assumes already marked as in_progress)
    async fn run_evaluation(&self, agent_hash: &str) {
        let short_hash = &agent_hash[..16.min(agent_hash.len())];
        info!("Starting evaluation for agent {}", short_hash);

        // Run evaluation
        let result = self.evaluate_agent(agent_hash).await;

        // Remove from in_progress
        {
            let mut in_progress = self.in_progress.write().await;
            in_progress.remove(agent_hash);
        }

        match result {
            Ok(_) => {
                info!("Evaluation completed for agent {}", short_hash);
            }
            Err(e) => {
                error!("Evaluation failed for agent {}: {}", short_hash, e);
            }
        }
    }

    /// Core evaluation: download → run → submit
    async fn evaluate_agent(&self, agent_hash: &str) -> Result<()> {
        let short_hash = &agent_hash[..16.min(agent_hash.len())];

        // 1. Download binary
        info!("Downloading binary for agent {}...", short_hash);
        let binary = match self.download_binary(agent_hash).await {
            Ok(b) => b,
            Err(e) => {
                error!("Download failed for agent {}: {:?}", short_hash, e);
                // Log global failure to server for visibility
                if let Err(log_err) = self
                    .log_global_failure(
                        agent_hash,
                        "download",
                        &format!("{}", e),
                        &format!("{:?}", e),
                    )
                    .await
                {
                    warn!("Failed to log download failure: {}", log_err);
                }
                return Err(e);
            }
        };
        info!("Downloaded binary: {} bytes", binary.len());

        // 2. Run evaluation in Docker
        info!("Running evaluation in Docker...");
        let result = match self.run_binary_in_docker(&binary, agent_hash).await {
            Ok(r) => r,
            Err(e) => {
                error!("Docker evaluation failed for agent {}: {:?}", short_hash, e);
                // Log global failure to server for visibility
                if let Err(log_err) = self
                    .log_global_failure(
                        agent_hash,
                        "docker_evaluation",
                        &format!("{}", e),
                        &format!("{:?}", e),
                    )
                    .await
                {
                    warn!("Failed to log evaluation failure: {}", log_err);
                }
                return Err(e);
            }
        };
        info!(
            "Evaluation result: score={:.2}%, passed={}/{}",
            result.score * 100.0,
            result.tasks_passed,
            result.tasks_total
        );

        // 3. Submit result
        info!("Submitting result...");
        if let Err(e) = self.submit_result(agent_hash, &result).await {
            error!("Submit result failed for agent {}: {:?}", short_hash, e);
            // Log global failure to server for visibility
            if let Err(log_err) = self
                .log_global_failure(
                    agent_hash,
                    "submit_result",
                    &format!("{}", e),
                    &format!("{:?}", e),
                )
                .await
            {
                warn!("Failed to log submit failure: {}", log_err);
            }
            return Err(e);
        }
        info!("Result submitted for agent {}", short_hash);

        Ok(())
    }

    /// Fetch pending jobs from server
    async fn fetch_my_jobs(&self) -> Result<Vec<ValidatorJob>> {
        let url = format!(
            "{}/api/v1/bridge/{}/api/v1/validator/my_jobs",
            self.platform_url, self.challenge_id
        );

        let timestamp = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)?
            .as_secs() as i64;

        let message = format!("get_my_jobs:{}", timestamp);
        let signature = self.sign_message(&message);

        let response = self
            .http_client
            .post(&url)
            .json(&serde_json::json!({
                "validator_hotkey": self.validator_hotkey,
                "timestamp": timestamp,
                "signature": signature,
            }))
            .send()
            .await?;

        if !response.status().is_success() {
            let status = response.status();
            let text = response.text().await.unwrap_or_default();
            anyhow::bail!("my_jobs request failed: {} - {}", status, text);
        }

        let body: serde_json::Value = response.json().await?;
        // Server returns "pending_jobs" field
        let jobs = body["pending_jobs"]
            .as_array()
            .map(|arr| {
                arr.iter()
                    .filter_map(|j| {
                        Some(ValidatorJob {
                            agent_hash: j["agent_hash"].as_str()?.to_string(),
                            miner_hotkey: j["miner_hotkey"].as_str().unwrap_or("").to_string(),
                            submission_id: j["submission_id"].as_str().unwrap_or("").to_string(),
                            binary_ready: j["binary_ready"]
                                .as_bool()
                                .or_else(|| j["compile_status"].as_str().map(|s| s == "success"))
                                .unwrap_or(false),
                        })
                    })
                    .collect()
            })
            .unwrap_or_default();

        Ok(jobs)
    }

    /// Download compiled binary via bridge (with caching)
    async fn download_binary(&self, agent_hash: &str) -> Result<Vec<u8>> {
        // Check cache first
        {
            let cache = self.binary_cache.read().await;
            if let Some(binary) = cache.get(agent_hash) {
                debug!(
                    "Binary cache hit for agent {} ({} bytes)",
                    &agent_hash[..16.min(agent_hash.len())],
                    binary.len()
                );
                return Ok(binary.clone());
            }
        }

        let url = format!(
            "{}/api/v1/bridge/{}/api/v1/validator/download_binary/{}",
            self.platform_url, self.challenge_id, agent_hash
        );

        let timestamp = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)?
            .as_secs() as i64;

        let message = format!("download_binary:{}:{}", agent_hash, timestamp);
        let signature = self.sign_message(&message);

        let response = self
            .http_client
            .post(&url)
            .json(&serde_json::json!({
                "validator_hotkey": self.validator_hotkey,
                "timestamp": timestamp,
                "signature": signature,
            }))
            .send()
            .await?;

        if !response.status().is_success() {
            let status = response.status();
            let text = response.text().await.unwrap_or_default();
            anyhow::bail!("Binary download failed: {} - {}", status, text);
        }

        let binary = response.bytes().await?.to_vec();

        if binary.is_empty() {
            anyhow::bail!("Downloaded binary is empty");
        }

        // Cache the binary
        {
            let mut cache = self.binary_cache.write().await;
            cache.insert(agent_hash.to_string(), binary.clone());
            // Limit cache size to prevent memory issues (keep last 20 binaries)
            if cache.len() > 20 {
                // Remove oldest entry (simple LRU-ish approach)
                if let Some(oldest_key) = cache.keys().next().cloned() {
                    cache.remove(&oldest_key);
                }
            }
        }

        Ok(binary)
    }

    /// Run binary in Docker container against real tasks
    async fn run_binary_in_docker(&self, binary: &[u8], agent_hash: &str) -> Result<EvalResult> {
        use std::collections::HashSet;
        use std::io::Write;
        use tempfile::NamedTempFile;

        let short_hash = &agent_hash[..16.min(agent_hash.len())];

        // Check for existing progress to resume from
        let progress = self.get_evaluation_progress(agent_hash).await.ok();
        let completed_task_ids: HashSet<String> = progress
            .as_ref()
            .map(|p| {
                p.completed_tasks
                    .iter()
                    .map(|t| t.task_id.clone())
                    .collect()
            })
            .unwrap_or_default();

        // Initialize counters from existing progress
        let mut tasks_passed = progress
            .as_ref()
            .map(|p| p.completed_tasks.iter().filter(|t| t.passed).count() as i32)
            .unwrap_or(0);
        let mut tasks_failed = progress
            .as_ref()
            .map(|p| p.completed_tasks.iter().filter(|t| !t.passed).count() as i32)
            .unwrap_or(0);

        if !completed_task_ids.is_empty() {
            info!(
                "Resuming evaluation for agent {}: {}/{} tasks already completed (passed={}, failed={})",
                short_hash,
                completed_task_ids.len(),
                progress.as_ref().map(|p| p.total_tasks).unwrap_or(0),
                tasks_passed,
                tasks_failed
            );
        }

        // Write binary to temp file
        // IMPORTANT: We must close the file handle before executing to avoid "Text file busy" error on Linux
        let mut temp_file = NamedTempFile::new().context("Failed to create temp file")?;
        temp_file
            .write_all(binary)
            .context("Failed to write binary")?;
        temp_file.flush().context("Failed to flush binary")?;

        // Get path and convert to TempPath (this closes the file handle but keeps the path valid)
        let temp_path = temp_file.into_temp_path();
        let binary_path = temp_path.to_string_lossy().to_string();

        // Make executable
        #[cfg(unix)]
        {
            use std::os::unix::fs::PermissionsExt;
            let mut perms = std::fs::metadata(&binary_path)?.permissions();
            perms.set_mode(0o755);
            std::fs::set_permissions(&binary_path, perms)?;
        }

        // Keep temp_path alive (it will be deleted when dropped at end of function)
        let _temp_path_guard = temp_path;

        // Get real tasks from terminal-bench@2.0
        let tasks = self.get_evaluation_tasks().await?;

        let tasks_total = tasks.len() as i32;
        let tasks_remaining = tasks
            .iter()
            .filter(|t| !completed_task_ids.contains(t.id()))
            .count();

        info!(
            "Agent {}: {} total tasks, {} remaining to evaluate",
            short_hash, tasks_total, tasks_remaining
        );

        for task in &tasks {
            let task_id = task.id();

            // Skip already completed tasks
            if completed_task_ids.contains(task_id) {
                debug!("Skipping already completed task: {}", task_id);
                continue;
            }

            let instruction = task.instruction();
            info!(
                "Running task: {} - {}",
                task_id,
                &instruction[..50.min(instruction.len())]
            );

            let result = self
                .run_task_in_docker(&binary_path, task, agent_hash)
                .await;

            let task_result = match result {
                Ok(tr) => {
                    if tr.passed {
                        info!("Task {} PASSED", task_id);
                        tasks_passed += 1;
                    } else {
                        info!("Task {} FAILED", task_id);
                        tasks_failed += 1;
                    }
                    tr
                }
                Err(e) => {
                    // Log full error chain with :? for debugging Docker issues
                    warn!("Task {} error: {:?}", task_id, e);
                    tasks_failed += 1;
                    TaskResult {
                        passed: false,
                        duration_ms: 0,
                        error: Some(format!("{:?}", e)),
                        agent_stderr: Some(format!("Task execution error: {:?}", e)),
                        test_output: None,
                        steps_executed: None,
                    }
                }
            };

            // Log task result to platform server with full verbose details
            if let Err(e) = self
                .log_task_result(
                    agent_hash,
                    task_id,
                    task_result.passed,
                    task_result.duration_ms,
                    task_result.error.clone(),
                    task_result.agent_stderr.clone(),
                    None, // agent_stdout not separately tracked
                    task_result.test_output.clone(),
                    task_result.steps_executed,
                    None, // not a global failure
                )
                .await
            {
                warn!("Failed to log task {} result: {}", task_id, e);
            }
        }

        let score = if tasks_total > 0 {
            tasks_passed as f64 / tasks_total as f64
        } else {
            0.0
        };

        Ok(EvalResult {
            score,
            tasks_passed,
            tasks_total,
            tasks_failed,
            total_cost: 0.0,
        })
    }

    /// Execute single task using the container backend (broker or Docker)
    async fn run_task_in_docker(
        &self,
        binary_path: &str,
        task: &Task,
        agent_hash: &str,
    ) -> Result<TaskResult> {
        use crate::container_backend::MountConfig;
        use std::time::Instant;

        // Acquire semaphore permit to limit concurrent containers
        let _permit = self
            .task_container_semaphore
            .acquire()
            .await
            .map_err(|_| anyhow::anyhow!("Task container semaphore closed"))?;

        let start = Instant::now();
        let task_id = task.id();
        let timeout_secs = task.config.timeout_secs as u64;

        // Build environment variables from task config
        let mut env = std::collections::HashMap::new();
        for var in &task.config.env {
            if let Some((k, v)) = var.split_once('=') {
                env.insert(k.to_string(), v.to_string());
            }
        }
        env.insert("TEST_DIR".to_string(), "/tests".to_string());
        env.insert("TERM".to_string(), "xterm-256color".to_string());

        // LLM proxy configuration - agent reaches validator container via platform-network
        // HOSTNAME is set to container name by Docker (e.g., challenge-term-bench-xxx)
        let validator_hostname =
            std::env::var("HOSTNAME").unwrap_or_else(|_| "localhost".to_string());
        let validator_port = std::env::var("PORT").unwrap_or_else(|_| "8080".to_string());
        env.insert(
            "LLM_PROXY_URL".to_string(),
            format!("http://{}:{}", validator_hostname, validator_port),
        );
        env.insert("TERM_AGENT_HASH".to_string(), agent_hash.to_string());
        env.insert("TERM_TASK_ID".to_string(), task_id.to_string());
        env.insert("EVALUATION_MODE".to_string(), "true".to_string());

        // Parse memory limit (e.g., "2g" -> bytes)
        let memory_bytes = parse_memory_string(&task.config.memory_limit);

        // Build mounts if task has a path
        let mounts = if let Some(task_path) = &task.path {
            // For Docker-in-Docker, map container paths to host paths
            let path_str = task_path.to_string_lossy();
            let source_path = map_path_for_dind(&path_str);
            vec![MountConfig {
                source: source_path,
                target: "/task".to_string(),
                read_only: true,
            }]
        } else {
            vec![]
        };

        // Create sandbox config
        let config = SandboxConfig {
            image: task.config.docker_image.clone(),
            memory_bytes,
            cpu_cores: task.config.cpu_limit,
            env,
            working_dir: "/app".to_string(),
            network_mode: "isolated".to_string(), // Use platform-network for LLM proxy access
            mounts,
            cmd: Some(vec![
                "tail".to_string(),
                "-f".to_string(),
                "/dev/null".to_string(),
            ]),
            challenge_id: self.challenge_id.clone(),
            owner_id: self.validator_hotkey.clone(),
            name: None,
            auto_remove: false,
            user: Some("root".to_string()),
        };

        // Create and start container via backend
        debug!(
            "Creating task container with image: {}",
            task.config.docker_image
        );
        let task_container = self
            .container_backend
            .create_sandbox(config)
            .await
            .with_context(|| {
                format!(
                    "Failed to create task container (image: {}, task_path: {:?})",
                    task.config.docker_image, task.path
                )
            })?;

        let container_endpoint = task_container
            .start()
            .await
            .context("Failed to start task container")?;

        // Log container endpoint for HTTP communication
        if let Some(ref endpoint) = container_endpoint {
            info!("Task container endpoint: {}", endpoint);
        } else {
            debug!("Task container has no direct network endpoint, will use exec for HTTP");
        }

        // Run setup script if present
        if let Some(setup_script) = &task.setup_script {
            debug!("Running setup script");
            if let Err(e) = task_container.exec(&["bash", "-c", setup_script]).await {
                warn!("Setup script failed: {}", e);
            }
        }

        // Copy test files to container
        if !task.test_files.is_empty() {
            debug!("Copying {} test files", task.test_files.len());
            let _ = task_container.exec(&["mkdir", "-p", "/tests"]).await;
            for (filename, content) in &task.test_files {
                // Use write_file from ContainerHandle
                let file_path = format!("/tests/{}", filename);
                if let Err(e) = task_container
                    .write_file(&file_path, content.as_bytes())
                    .await
                {
                    warn!("Failed to write test file {}: {}", filename, e);
                    // Fallback to exec with base64
                    let encoded = base64::engine::general_purpose::STANDARD.encode(content);
                    let cmd = format!("echo '{}' | base64 -d > '{}'", encoded, file_path);
                    let _ = task_container.exec(&["sh", "-c", &cmd]).await;
                }
            }
        }

        // Run the agent binary against this task
        let instruction = task.instruction();
        let llm_proxy_url = format!("http://{}:{}", validator_hostname, validator_port);
        let (agent_completed, agent_stderr, steps_executed) = match self
            .run_agent_loop(
                task_container.as_ref(),
                binary_path,
                instruction,
                timeout_secs,
                agent_hash,
                task_id,
                &llm_proxy_url,
                container_endpoint.as_deref(),
            )
            .await
        {
            Ok(result) => result,
            Err(e) => {
                // Log the error with full context instead of silently ignoring
                error!("Agent loop failed for task {}: {:?}", task_id, e);
                // Return error details in stderr so they're visible in UI
                let error_msg =
                    format!("Agent execution error: {}\n\nFull error chain:\n{:?}", e, e);
                (false, error_msg, 0)
            }
        };

        // Run verification (test script) with test timeout
        let test_timeout_secs = task.config.test_timeout_secs as u64;
        let (test_passed, test_output) = if agent_completed {
            match self
                .run_test_script(
                    task_container.as_ref(),
                    &task.test_script,
                    test_timeout_secs,
                )
                .await
            {
                Ok((passed, output)) => (passed, Some(output)),
                Err(e) => (false, Some(format!("Test error: {}", e))),
            }
        } else {
            // Include agent stderr in the "did not complete" message
            let msg = if agent_stderr.is_empty() {
                format!(
                    "Agent did not complete after {} steps (no stderr)",
                    steps_executed
                )
            } else {
                format!(
                    "Agent did not complete after {} steps. Stderr:\n{}",
                    steps_executed,
                    // Truncate stderr to avoid huge payloads
                    if agent_stderr.len() > 1000 {
                        format!("{}... (truncated)", &agent_stderr[..1000])
                    } else {
                        agent_stderr.clone()
                    }
                )
            };
            (false, Some(msg))
        };

        // Force cleanup - always stop and remove container
        if let Err(e) = task_container.stop().await {
            debug!("Failed to stop container (may already be stopped): {}", e);
        }
        if let Err(e) = task_container.remove().await {
            warn!("Failed to remove container: {}", e);
        }

        // Cleanup orphan volumes in background to not block evaluation
        let backend = self.container_backend.clone();
        let cid = self.challenge_id.clone();
        tokio::spawn(async move {
            match backend.cleanup_volumes(&cid).await {
                Ok(count) if count > 0 => {
                    info!("Background cleanup: removed {} orphan volumes", count);
                }
                Err(e) => {
                    debug!("Background volume cleanup failed: {}", e);
                }
                _ => {}
            }
        });

        let elapsed = start.elapsed();
        debug!(
            "Task {} completed in {:?}: {}",
            task_id, elapsed, test_passed
        );

        Ok(TaskResult {
            passed: test_passed,
            duration_ms: elapsed.as_millis() as i64,
            error: None,
            agent_stderr: if agent_stderr.is_empty() {
                None
            } else {
                Some(agent_stderr)
            },
            test_output,
            steps_executed: Some(steps_executed),
        })
    }

    /// Run the agent binary using SDK 2.0 architecture
    ///
    /// SDK 2.0: The agent runs autonomously and executes commands via subprocess.
    /// Communication:
    ///   - POST /start - Send instruction, max_steps, timeout_secs to start execution
    ///   - GET /status - Poll for execution status (running/completed/failed)
    ///
    /// If `container_endpoint` is provided (container name for Docker DNS resolution),
    /// HTTP requests are made directly. Otherwise, falls back to using docker exec with bash /dev/tcp.
    ///
    /// Returns (completed, accumulated_logs, steps_executed)
    #[allow(clippy::too_many_arguments)]
    async fn run_agent_loop(
        &self,
        task_container: &dyn ContainerHandle,
        binary_path: &str,
        instruction: &str,
        timeout_secs: u64,
        agent_hash: &str,
        task_id: &str,
        llm_proxy_url: &str,
        container_endpoint: Option<&str>,
    ) -> Result<(bool, String, i32)> {
        const AGENT_PORT: u16 = 8765;
        const MAX_STEPS: usize = 500;
        const STATUS_POLL_INTERVAL_MS: u64 = 500;
        const AGENT_STARTUP_TIMEOUT_MS: u64 = 15000; // 15 seconds to start

        let short_hash = &agent_hash[..16.min(agent_hash.len())];
        info!(
            "Starting agent (SDK 2.0) for {} on task {} (HTTP mode)",
            short_hash, task_id
        );

        // Step 1: Copy binary to task container
        info!("Copying agent binary to task container...");
        let binary_data =
            std::fs::read(binary_path).context("Failed to read agent binary from local path")?;

        info!("Binary size: {} bytes", binary_data.len());

        // Create agent directory
        task_container
            .exec(&["mkdir", "-p", "/agent"])
            .await
            .context("Failed to create /agent directory")?;

        // Write binary to container
        task_container
            .write_file("/agent/agent", &binary_data)
            .await
            .context("Failed to copy binary to container")?;

        // Make executable
        task_container
            .exec(&["chmod", "+x", "/agent/agent"])
            .await
            .context("Failed to make binary executable")?;

        info!("Binary copied successfully, starting HTTP server...");

        // Step 2: Start the agent HTTP server
        // Environment variables are passed to configure the agent
        let start_cmd = format!(
            "AGENT_PORT={} LLM_PROXY_URL='{}' TERM_AGENT_HASH='{}' TERM_TASK_ID='{}' \
             EVALUATION_MODE=true FORCE_HTTP_SERVER=1 PYTHONUNBUFFERED=1 \
             nohup /agent/agent > /agent/stdout.log 2>/agent/stderr.log &",
            AGENT_PORT, llm_proxy_url, agent_hash, task_id
        );

        task_container
            .exec(&["sh", "-c", &start_cmd])
            .await
            .context("Failed to start agent HTTP server")?;

        // Step 3: Wait for agent HTTP server to be ready
        // Build the agent base URL - use direct HTTP if we have an endpoint (container name), otherwise use exec
        let agent_base_url =
            container_endpoint.map(|host| format!("http://{}:{}", host, AGENT_PORT));

        info!(
            "Waiting for agent HTTP server on port {} (mode: {})...",
            AGENT_PORT,
            if agent_base_url.is_some() {
                "direct HTTP"
            } else {
                "exec"
            }
        );

        let mut agent_ready = false;
        let startup_start = std::time::Instant::now();
        let max_attempts = (AGENT_STARTUP_TIMEOUT_MS / 100) as usize;

        for attempt in 1..=max_attempts {
            tokio::time::sleep(Duration::from_millis(100)).await;

            // Check health endpoint
            let health_ok = if let Some(ref base_url) = agent_base_url {
                // Direct HTTP request to container
                match self
                    .http_client
                    .get(format!("{}/health", base_url))
                    .timeout(Duration::from_secs(2))
                    .send()
                    .await
                {
                    Ok(resp) if resp.status().is_success() => {
                        resp.text().await.map(|t| t.contains("ok")).unwrap_or(false)
                    }
                    _ => false,
                }
            } else {
                // Fallback: use exec with bash /dev/tcp (works without curl)
                let health_cmd = format!(
                    r#"exec 3<>/dev/tcp/127.0.0.1/{} && echo -e "GET /health HTTP/1.0\r\nHost: 127.0.0.1\r\n\r\n" >&3 && cat <&3 | tail -1"#,
                    AGENT_PORT
                );
                match task_container.exec(&["bash", "-c", &health_cmd]).await {
                    Ok(result) => result.success() && result.stdout.contains("ok"),
                    Err(_) => false,
                }
            };

            if health_ok {
                agent_ready = true;
                info!(
                    "Agent HTTP server ready after {}ms ({} attempts)",
                    startup_start.elapsed().as_millis(),
                    attempt
                );
                break;
            }

            // Log progress every 2 seconds
            if attempt % 20 == 0 {
                debug!(
                    "Still waiting for agent... attempt {}/{} ({}ms elapsed)",
                    attempt,
                    max_attempts,
                    startup_start.elapsed().as_millis()
                );

                // Check if process is still running
                let ps_result = task_container
                    .exec(&[
                        "sh",
                        "-c",
                        "ps aux | grep agent | grep -v grep || echo 'No agent process'",
                    ])
                    .await;
                if let Ok(ps) = ps_result {
                    debug!("Process status: {}", ps.stdout.trim());
                }
            }
        }

        if !agent_ready {
            // Read logs for diagnosis
            let stderr = self
                .read_container_file(task_container, "/agent/stderr.log")
                .await;
            let stdout = self
                .read_container_file(task_container, "/agent/stdout.log")
                .await;

            error!(
                "Agent HTTP server failed to start within {}ms",
                AGENT_STARTUP_TIMEOUT_MS
            );
            error!(
                "=== Agent stderr.log ===\n{}",
                &stderr[..stderr.len().min(3000)]
            );
            error!(
                "=== Agent stdout.log ===\n{}",
                &stdout[..stdout.len().min(1000)]
            );

            return Err(anyhow::anyhow!(
                "Agent HTTP server failed to start within {}ms.\n\n\
                 === STDERR ===\n{}\n\n\
                 === STDOUT ===\n{}",
                AGENT_STARTUP_TIMEOUT_MS,
                stderr,
                stdout
            ));
        }

        // Step 4: SDK 2.0 - Send /start request then poll /status
        let loop_start = std::time::Instant::now();
        let timeout = Duration::from_secs(timeout_secs);

        // Build the /start request body
        let start_body = serde_json::json!({
            "instruction": instruction,
            "max_steps": MAX_STEPS,
            "timeout_secs": timeout_secs,
        });

        info!(
            "Sending POST /start to agent (instruction: {} chars)",
            instruction.len()
        );

        // Send /start request
        let start_success = if let Some(ref base_url) = agent_base_url {
            // Direct HTTP request
            let start_result = tokio::time::timeout(
                Duration::from_secs(10),
                self.http_client
                    .post(format!("{}/start", base_url))
                    .json(&start_body)
                    .send(),
            )
            .await;

            match start_result {
                Ok(Ok(resp)) if resp.status().is_success() => {
                    info!("Agent acknowledged /start request");
                    true
                }
                Ok(Ok(resp)) => {
                    let status = resp.status();
                    let body = resp.text().await.unwrap_or_default();
                    error!("Agent /start failed: {} - {}", status, body);
                    false
                }
                Ok(Err(e)) => {
                    error!("Agent /start request error: {}", e);
                    false
                }
                Err(_) => {
                    error!("Agent /start timeout");
                    false
                }
            }
        } else {
            // Fallback: exec with bash /dev/tcp
            let request_json = start_body.to_string();
            let escaped_json = request_json.replace('\\', "\\\\").replace('"', "\\\"");
            let http_cmd = format!(
                r#"exec 3<>/dev/tcp/127.0.0.1/{port} && echo -e "POST /start HTTP/1.0\r\nHost: 127.0.0.1\r\nContent-Type: application/json\r\nContent-Length: {len}\r\n\r\n{body}" >&3 && cat <&3 | tail -1"#,
                port = AGENT_PORT,
                len = request_json.len(),
                body = escaped_json
            );

            match task_container.exec(&["bash", "-c", &http_cmd]).await {
                Ok(result) if result.success() && result.stdout.contains("started") => {
                    info!("Agent acknowledged /start request (exec mode)");
                    true
                }
                Ok(result) => {
                    error!(
                        "Agent /start failed (exec): exit={}, out={}",
                        result.exit_code,
                        result.stdout.trim()
                    );
                    false
                }
                Err(e) => {
                    error!("Agent /start exec error: {}", e);
                    false
                }
            }
        };

        if !start_success {
            let logs = self.read_agent_logs(task_container).await;
            return Err(anyhow::anyhow!(
                "Agent failed to acknowledge /start request.\n\nAgent logs:\n{}",
                logs
            ));
        }

        // Step 5: Poll /status until completion or timeout
        let mut last_step = 0i32;
        let mut consecutive_errors = 0usize;
        const MAX_CONSECUTIVE_ERRORS: usize = 5;

        loop {
            // Check global timeout
            if loop_start.elapsed() > timeout {
                warn!(
                    "Task timeout after {}s (last step: {})",
                    loop_start.elapsed().as_secs(),
                    last_step
                );
                let logs = self.read_agent_logs(task_container).await;
                return Ok((false, logs, last_step));
            }

            // Wait before polling
            tokio::time::sleep(Duration::from_millis(STATUS_POLL_INTERVAL_MS)).await;

            // Poll /status
            let status_response = if let Some(ref base_url) = agent_base_url {
                // Direct HTTP request
                let status_result = tokio::time::timeout(
                    Duration::from_secs(5),
                    self.http_client.get(format!("{}/status", base_url)).send(),
                )
                .await;

                match status_result {
                    Ok(Ok(resp)) if resp.status().is_success() => match resp.text().await {
                        Ok(text) => Some(text),
                        Err(e) => {
                            warn!("Failed to read /status response: {}", e);
                            None
                        }
                    },
                    Ok(Ok(resp)) => {
                        warn!("Agent /status returned: {}", resp.status());
                        None
                    }
                    Ok(Err(e)) => {
                        warn!("Agent /status request error: {}", e);
                        None
                    }
                    Err(_) => {
                        warn!("Agent /status timeout");
                        None
                    }
                }
            } else {
                // Fallback: exec with bash /dev/tcp
                let http_cmd = format!(
                    r#"exec 3<>/dev/tcp/127.0.0.1/{} && echo -e "GET /status HTTP/1.0\r\nHost: 127.0.0.1\r\n\r\n" >&3 && cat <&3 | sed '1,/^\r$/d'"#,
                    AGENT_PORT
                );

                match task_container.exec(&["bash", "-c", &http_cmd]).await {
                    Ok(result) if result.success() => Some(result.stdout),
                    Ok(result) => {
                        warn!("Agent /status exec failed: {}", result.stderr.trim());
                        None
                    }
                    Err(e) => {
                        warn!("Agent /status exec error: {}", e);
                        None
                    }
                }
            };

            // Parse status response
            let status: serde_json::Value = match status_response {
                Some(text) => match serde_json::from_str(&text) {
                    Ok(v) => {
                        consecutive_errors = 0;
                        v
                    }
                    Err(e) => {
                        warn!(
                            "Invalid /status JSON: {} - raw: {}",
                            e,
                            &text[..text.len().min(200)]
                        );
                        consecutive_errors += 1;
                        if consecutive_errors >= MAX_CONSECUTIVE_ERRORS {
                            error!("Too many /status errors, aborting");
                            let logs = self.read_agent_logs(task_container).await;
                            return Ok((false, logs, last_step));
                        }
                        continue;
                    }
                },
                None => {
                    consecutive_errors += 1;
                    if consecutive_errors >= MAX_CONSECUTIVE_ERRORS {
                        error!("Too many /status errors, aborting");
                        let logs = self.read_agent_logs(task_container).await;
                        return Ok((false, logs, last_step));
                    }
                    continue;
                }
            };

            // Extract status fields
            let agent_status = status["status"].as_str().unwrap_or("unknown");
            let steps = status["steps"].as_i64().unwrap_or(0) as i32;
            let elapsed = status["elapsed_secs"].as_i64().unwrap_or(0);
            let error_msg = status["error"].as_str();
            let is_done = status["done"].as_bool().unwrap_or(false);

            // Update step count
            if steps > last_step {
                last_step = steps;
                debug!(
                    "Agent at step {}, elapsed {}s, status: {}",
                    steps, elapsed, agent_status
                );
            }

            // Check completion
            match agent_status {
                "completed" => {
                    info!(
                        "Agent completed successfully at step {} ({}s)",
                        steps, elapsed
                    );
                    let logs = self.read_agent_logs(task_container).await;
                    return Ok((true, logs, steps));
                }
                "failed" => {
                    let err = error_msg.unwrap_or("unknown error");
                    warn!("Agent failed at step {}: {}", steps, err);
                    let logs = self.read_agent_logs(task_container).await;
                    return Ok((false, logs, steps));
                }
                "running" | "idle" => {
                    // Still running, continue polling
                    // Log progress every 10 seconds
                    if elapsed % 10 == 0 && elapsed > 0 {
                        info!("Agent running: step {}, elapsed {}s", steps, elapsed);
                    }
                }
                _ => {
                    debug!("Unknown agent status: {}", agent_status);
                }
            }

            // Also check done flag (backwards compatibility)
            if is_done {
                info!("Agent marked done at step {} ({}s)", steps, elapsed);
                let logs = self.read_agent_logs(task_container).await;
                return Ok((true, logs, steps));
            }
        }
    }

    /// Read a file from the container, returning empty string on error
    async fn read_container_file(&self, container: &dyn ContainerHandle, path: &str) -> String {
        match container.exec(&["cat", path]).await {
            Ok(result) => result.stdout,
            Err(_) => String::new(),
        }
    }

    /// Read agent logs from container (both stdout and stderr)
    async fn read_agent_logs(&self, container: &dyn ContainerHandle) -> String {
        let stderr = self
            .read_container_file(container, "/agent/stderr.log")
            .await;
        let stdout = self
            .read_container_file(container, "/agent/stdout.log")
            .await;

        let mut logs = String::new();
        if !stderr.is_empty() {
            logs.push_str("=== Agent stderr ===\n");
            logs.push_str(&stderr);
            logs.push('\n');
        }
        if !stdout.is_empty() {
            logs.push_str("=== Agent stdout ===\n");
            logs.push_str(&stdout);
        }
        logs
    }

    /// Run the test script to verify task completion
    /// Returns (passed, output)
    async fn run_test_script(
        &self,
        task_container: &dyn ContainerHandle,
        test_script: &str,
        timeout_secs: u64,
    ) -> Result<(bool, String)> {
        // Create /logs/verifier directory for Harbor compatibility
        let _ = task_container
            .exec(&["mkdir", "-p", "/logs/verifier"])
            .await;

        // Run test script with timeout
        let result = tokio::time::timeout(
            Duration::from_secs(timeout_secs),
            task_container.exec(&["bash", "-c", test_script]),
        )
        .await;

        // Handle timeout
        let result = match result {
            Ok(r) => r,
            Err(_) => {
                warn!("Test script timed out after {}s", timeout_secs);
                return Ok((
                    false,
                    format!("Test script timed out after {}s", timeout_secs),
                ));
            }
        };

        match result {
            Ok(exec_result) => {
                let output = exec_result.combined();

                // Try to read reward.txt (Harbor standard) - this is the authoritative source
                let reward_result = task_container
                    .exec(&["cat", "/logs/verifier/reward.txt"])
                    .await;

                let passed = if let Ok(reward_output) = reward_result {
                    let reward_str = reward_output.stdout.trim();
                    // Harbor writes "1" for pass, "0" for fail
                    reward_str == "1" || reward_str == "1.0" || reward_str.starts_with("1")
                } else {
                    // Fallback: use exit code only (not keyword matching)
                    exec_result.success()
                };

                Ok((passed, output))
            }
            Err(e) => {
                debug!("Test script failed: {}", e);
                Ok((false, format!("Test execution error: {}", e)))
            }
        }
    }

    /// Submit result via bridge
    async fn submit_result(&self, agent_hash: &str, result: &EvalResult) -> Result<()> {
        let url = format!(
            "{}/api/v1/bridge/{}/api/v1/validator/submit_result",
            self.platform_url, self.challenge_id
        );

        let timestamp = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)?
            .as_secs() as i64;

        let message = format!("submit_result:{}:{}", agent_hash, timestamp);
        let signature = self.sign_message(&message);

        let response = self
            .http_client
            .post(&url)
            .json(&serde_json::json!({
                "agent_hash": agent_hash,
                "validator_hotkey": self.validator_hotkey,
                "score": result.score,
                "tasks_passed": result.tasks_passed,
                "tasks_total": result.tasks_total,
                "tasks_failed": result.tasks_failed,
                "total_cost_usd": result.total_cost,
                "timestamp": timestamp,
                "signature": signature,
            }))
            .send()
            .await?;

        if !response.status().is_success() {
            let status = response.status();
            let text = response.text().await.unwrap_or_default();
            anyhow::bail!("Submit result failed: {} - {}", status, text);
        }

        Ok(())
    }

    /// Sign message with validator keypair
    fn sign_message(&self, message: &str) -> String {
        hex::encode(self.keypair.sign(message.as_bytes()).0)
    }

    /// Log individual task result to platform server with verbose details
    #[allow(clippy::too_many_arguments)]
    async fn log_task_result(
        &self,
        agent_hash: &str,
        task_id: &str,
        passed: bool,
        duration_ms: i64,
        error: Option<String>,
        agent_stderr: Option<String>,
        agent_stdout: Option<String>,
        test_output: Option<String>,
        steps_executed: Option<i32>,
        failure_stage: Option<String>,
    ) -> Result<()> {
        let url = format!(
            "{}/api/v1/bridge/{}/api/v1/validator/log_task",
            self.platform_url, self.challenge_id
        );

        let now = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)?
            .as_secs() as i64;

        let message = format!("log_task:{}:{}:{}", agent_hash, task_id, now);
        let signature = self.sign_message(&message);

        // API expects these fields from LogTaskRequest
        let response = self
            .http_client
            .post(&url)
            .json(&serde_json::json!({
                "validator_hotkey": self.validator_hotkey,
                "signature": signature,
                "timestamp": now,
                "agent_hash": agent_hash,
                "task_id": task_id,
                "task_name": task_id,  // Use task_id as task_name
                "passed": passed,
                "score": if passed { 1.0 } else { 0.0 },
                "execution_time_ms": duration_ms,
                "steps": steps_executed.unwrap_or(0),
                "cost_usd": 0.0,  // Not tracked currently
                "error": error,
                "execution_log": null,
                "trajectory": null,
                "started_at": now - (duration_ms / 1000),
                // Verbose logging fields
                "agent_stderr": agent_stderr,
                "agent_stdout": agent_stdout,
                "test_output": test_output,
                "steps_executed": steps_executed,
                "failure_stage": failure_stage,
            }))
            .send()
            .await?;

        if !response.status().is_success() {
            let status = response.status();
            let text = response.text().await.unwrap_or_default();
            anyhow::bail!("log_task failed: {} - {}", status, text);
        }

        Ok(())
    }

    /// Log a global failure (before tasks can run) - e.g., download failed, container creation failed
    async fn log_global_failure(
        &self,
        agent_hash: &str,
        failure_stage: &str,
        error_message: &str,
        error_debug: &str,
    ) -> Result<()> {
        // Log as a special task with task_id = "__evaluation_failure__"
        self.log_task_result(
            agent_hash,
            "__evaluation_failure__",
            false,
            0,
            Some(error_message.to_string()),
            Some(error_debug.to_string()), // Put full debug in agent_stderr for visibility
            None,
            None,
            None,
            Some(failure_stage.to_string()),
        )
        .await
    }

    /// Get evaluation progress to resume interrupted evaluations
    async fn get_evaluation_progress(&self, agent_hash: &str) -> Result<GetProgressResponse> {
        let url = format!(
            "{}/api/v1/bridge/{}/api/v1/validator/get_evaluation_progress",
            self.platform_url, self.challenge_id
        );

        let timestamp = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)?
            .as_secs() as i64;

        let message = format!("get_progress:{}:{}", agent_hash, timestamp);
        let signature = self.sign_message(&message);

        let response = self
            .http_client
            .post(&url)
            .json(&serde_json::json!({
                "validator_hotkey": self.validator_hotkey,
                "signature": signature,
                "timestamp": timestamp,
                "agent_hash": agent_hash,
            }))
            .send()
            .await?;

        if !response.status().is_success() {
            let status = response.status();
            let text = response.text().await.unwrap_or_default();
            anyhow::bail!("get_evaluation_progress failed: {} - {}", status, text);
        }

        let body: GetProgressResponse = response.json().await?;
        Ok(body)
    }
}

/// Response from get_evaluation_progress API
#[derive(Debug, Clone, serde::Deserialize)]
struct GetProgressResponse {
    pub success: bool,
    pub agent_hash: String,
    pub total_tasks: i32,
    pub completed_tasks: Vec<CompletedTaskInfo>,
    pub remaining_task_ids: Vec<String>,
    pub partial_score: f64,
    pub error: Option<String>,
}

#[derive(Debug, Clone, serde::Deserialize)]
struct CompletedTaskInfo {
    pub task_id: String,
    pub passed: bool,
    pub score: f64,
}

#[derive(Debug)]
struct ValidatorJob {
    agent_hash: String,
    miner_hotkey: String,
    submission_id: String,
    binary_ready: bool,
}

/// Parse memory string like "2g", "512m", "1024k" to bytes
fn parse_memory_string(s: &str) -> i64 {
    let s = s.trim().to_lowercase();
    let (num_str, multiplier) = if s.ends_with("g") || s.ends_with("gb") {
        (
            s.trim_end_matches("gb").trim_end_matches("g"),
            1024 * 1024 * 1024,
        )
    } else if s.ends_with("m") || s.ends_with("mb") {
        (s.trim_end_matches("mb").trim_end_matches("m"), 1024 * 1024)
    } else if s.ends_with("k") || s.ends_with("kb") {
        (s.trim_end_matches("kb").trim_end_matches("k"), 1024)
    } else {
        (s.as_str(), 1)
    };

    num_str.parse::<i64>().unwrap_or(2 * 1024 * 1024 * 1024) * multiplier
}

/// Map container paths to host paths for Docker-in-Docker scenarios
///
/// When running inside a container that uses Docker-in-Docker (via broker),
/// bind mount paths must reference the host filesystem, not the container filesystem.
///
/// Supports:
/// - HOST_CACHE_DIR/CACHE_DIR: For downloaded datasets (e.g., /root/.cache/term-challenge)
/// - HOST_TASKS_DIR/TASKS_DIR: For task data (e.g., /app/data/tasks)
fn map_path_for_dind(path: &str) -> String {
    // Try cache directory mapping first (for downloaded datasets)
    // Cache dir is typically /root/.cache/term-challenge/datasets/...
    if path.contains(".cache/term-challenge") || path.contains("/datasets/") {
        if let Ok(host_cache_dir) = std::env::var("HOST_CACHE_DIR") {
            let cache_dir = std::env::var("CACHE_DIR")
                .unwrap_or_else(|_| "/root/.cache/term-challenge".to_string());
            if path.starts_with(&cache_dir) {
                let relative = path.strip_prefix(&cache_dir).unwrap_or(path);
                let mapped = format!("{}{}", host_cache_dir, relative);
                tracing::debug!(
                    "Docker-in-Docker cache path mapping: {} -> {}",
                    path,
                    mapped
                );
                return mapped;
            }
        }
    }

    // Try tasks directory mapping
    if let Ok(host_tasks_dir) = std::env::var("HOST_TASKS_DIR") {
        let tasks_dir =
            std::env::var("TASKS_DIR").unwrap_or_else(|_| "/app/data/tasks".to_string());
        if path.starts_with(&tasks_dir) {
            let relative = path.strip_prefix(&tasks_dir).unwrap_or(path);
            let mapped = format!("{}{}", host_tasks_dir, relative);
            tracing::debug!(
                "Docker-in-Docker tasks path mapping: {} -> {}",
                path,
                mapped
            );
            return mapped;
        }
    }

    // No mapping needed
    path.to_string()
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_map_path_for_dind_cache() {
        // Simulate Docker-in-Docker environment with Docker volume paths
        std::env::set_var(
            "HOST_CACHE_DIR",
            "/var/lib/docker/volumes/term-challenge-cache/_data",
        );
        std::env::set_var("CACHE_DIR", "/root/.cache/term-challenge");

        let input = "/root/.cache/term-challenge/datasets/custom-memory-heap-crash";
        let output = map_path_for_dind(input);
        assert_eq!(
            output,
            "/var/lib/docker/volumes/term-challenge-cache/_data/datasets/custom-memory-heap-crash"
        );

        // Clean up
        std::env::remove_var("HOST_CACHE_DIR");
        std::env::remove_var("CACHE_DIR");
    }

    #[test]
    fn test_map_path_for_dind_tasks() {
        // Simulate Docker-in-Docker environment with Docker volume paths
        std::env::set_var(
            "HOST_TASKS_DIR",
            "/var/lib/docker/volumes/term-challenge-tasks/_data",
        );
        std::env::set_var("TASKS_DIR", "/app/data/tasks");

        let input = "/app/data/tasks/some-task";
        let output = map_path_for_dind(input);
        assert_eq!(
            output,
            "/var/lib/docker/volumes/term-challenge-tasks/_data/some-task"
        );

        // Clean up
        std::env::remove_var("HOST_TASKS_DIR");
        std::env::remove_var("TASKS_DIR");
    }

    #[test]
    fn test_map_path_for_dind_unaffected_path() {
        // A path that doesn't match any mapping patterns should be unchanged
        // even if env vars are set
        std::env::set_var(
            "HOST_CACHE_DIR",
            "/var/lib/docker/volumes/term-challenge-cache/_data",
        );
        std::env::set_var("CACHE_DIR", "/root/.cache/term-challenge");

        let input = "/some/random/path/that/doesnt/match";
        let output = map_path_for_dind(input);
        assert_eq!(output, input);

        // Clean up
        std::env::remove_var("HOST_CACHE_DIR");
        std::env::remove_var("CACHE_DIR");
    }
}
