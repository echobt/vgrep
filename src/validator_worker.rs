//! Validator Worker - Handles evaluation assignments
//!
//! Responsibilities:
//! 1. Recover pending assignments on startup and after reconnection
//! 2. Poll /api/v1/validator/my_jobs every 1 minute (fallback)
//! 3. Handle binary_ready events from WebSocket
//! 4. Download binaries, run evaluation in Docker, submit results
//! 5. Load tasks from terminal-bench@2.0 registry (first 30 tasks)

use crate::bench::registry::RegistryClient;
use crate::container_backend::{ContainerBackend, ContainerHandle, SandboxConfig};
use crate::task::{Task, TaskRegistry};
use crate::validator_ws_client::ValidatorEvent;
use anyhow::{Context, Result};
use base64::Engine;
use sp_core::{sr25519, Pair};
use std::collections::{HashMap, HashSet};
use std::sync::Arc;
use std::time::Duration;
use tokio::sync::{mpsc, RwLock};
use tracing::{debug, error, info, warn};

/// Polling interval for pending jobs
const POLL_INTERVAL: Duration = Duration::from_secs(60);

/// Number of tasks to evaluate each agent on
const TASKS_PER_EVALUATION: usize = 30;

/// Dataset to load tasks from
const TASK_DATASET_NAME: &str = "terminal-bench";
const TASK_DATASET_VERSION: &str = "2.0";

/// Result of an evaluation
#[derive(Debug)]
pub struct EvalResult {
    pub score: f64,
    pub tasks_passed: i32,
    pub tasks_total: i32,
    pub tasks_failed: i32,
    pub total_cost: f64,
}

/// Result of a single task execution
#[derive(Debug)]
struct TaskResult {
    passed: bool,
    duration_ms: i64,
    error: Option<String>,
    /// Agent stderr output (for debugging)
    agent_stderr: Option<String>,
    /// Test script output
    test_output: Option<String>,
}

pub struct ValidatorWorker {
    platform_url: String,
    challenge_id: String,
    keypair: sr25519::Pair,
    validator_hotkey: String,
    http_client: reqwest::Client,
    /// Track in-progress evaluations to avoid duplicates
    in_progress: Arc<RwLock<HashSet<String>>>,
    /// Loaded task registry (first 30 tasks from terminal-bench@2.0)
    task_registry: Arc<RwLock<Option<TaskRegistry>>>,
    /// Container backend for running tasks (broker or direct Docker)
    container_backend: Arc<dyn ContainerBackend>,
    /// Binary cache to avoid re-downloading (agent_hash -> binary)
    binary_cache: Arc<RwLock<HashMap<String, Vec<u8>>>>,
}

impl ValidatorWorker {
    pub async fn new(
        platform_url: String,
        challenge_id: String,
        keypair: sr25519::Pair,
    ) -> Result<Self> {
        use sp_core::crypto::Ss58Codec;
        let validator_hotkey = keypair.public().to_ss58check();

        // Create container backend (will use broker if available, Docker as fallback)
        let container_backend = crate::container_backend::create_backend()
            .await
            .context("Failed to create container backend")?;

        Ok(Self {
            platform_url,
            challenge_id,
            keypair,
            validator_hotkey,
            http_client: reqwest::Client::builder()
                .timeout(Duration::from_secs(300))
                .build()
                .unwrap_or_default(),
            in_progress: Arc::new(RwLock::new(HashSet::new())),
            task_registry: Arc::new(RwLock::new(None)),
            container_backend,
            binary_cache: Arc::new(RwLock::new(HashMap::new())),
        })
    }

    /// Load tasks from terminal-bench@2.0 registry
    async fn load_tasks(&self) -> Result<()> {
        // Check if already loaded
        {
            let guard = self.task_registry.read().await;
            if guard.is_some() {
                return Ok(());
            }
        }

        info!(
            "Loading tasks from {}@{}...",
            TASK_DATASET_NAME, TASK_DATASET_VERSION
        );

        // Download dataset
        let mut client = RegistryClient::new();
        let task_paths = client
            .download_dataset(TASK_DATASET_NAME, TASK_DATASET_VERSION, false)
            .await
            .context("Failed to download terminal-bench@2.0 dataset")?;

        info!("Downloaded {} tasks from registry", task_paths.len());

        // Create task registry from downloaded paths (take first 30)
        let tasks_dir = crate::bench::registry::cache_dir();
        let registry = TaskRegistry::new(tasks_dir)?;

        let task_count = registry.count();
        info!(
            "Loaded {} tasks into registry (using first {})",
            task_count, TASKS_PER_EVALUATION
        );

        let mut guard = self.task_registry.write().await;
        *guard = Some(registry);

        Ok(())
    }

    /// Get the first N tasks for evaluation
    async fn get_evaluation_tasks(&self) -> Result<Vec<Task>> {
        // Ensure tasks are loaded
        self.load_tasks().await?;

        let guard = self.task_registry.read().await;
        let registry = guard
            .as_ref()
            .ok_or_else(|| anyhow::anyhow!("Task registry not loaded"))?;

        // Get all tasks and take first TASKS_PER_EVALUATION
        let tasks: Vec<Task> = registry
            .list_tasks()
            .into_iter()
            .take(TASKS_PER_EVALUATION)
            .filter_map(|info| registry.get(&info.id).cloned())
            .collect();

        if tasks.is_empty() {
            anyhow::bail!("No tasks available for evaluation");
        }

        info!("Selected {} tasks for evaluation", tasks.len());
        Ok(tasks)
    }

    /// Main entry point - runs forever
    pub async fn run(&self, mut event_rx: mpsc::Receiver<ValidatorEvent>) {
        info!("Validator worker starting...");

        // 1. Recover pending assignments on startup
        self.recover_pending_assignments().await;

        // 2. Start polling ticker
        let poll_handle = {
            let worker = self.clone_ref();
            tokio::spawn(async move {
                worker.poll_loop().await;
            })
        };

        // 3. Handle WebSocket events
        while let Some(event) = event_rx.recv().await {
            match event {
                ValidatorEvent::BinaryReady { agent_hash, .. } => {
                    let worker = self.clone_ref();
                    tokio::spawn(async move {
                        worker.handle_binary_ready(&agent_hash).await;
                    });
                }
                ValidatorEvent::NewSubmissionAssigned { agent_hash, .. } => {
                    // Just log - we wait for binary_ready before evaluating
                    info!(
                        "Noted assignment for agent {} (waiting for binary)",
                        &agent_hash[..16.min(agent_hash.len())]
                    );
                }
                ValidatorEvent::Reconnected => {
                    // Recover pending after reconnection
                    info!("WebSocket reconnected, recovering pending assignments...");
                    self.recover_pending_assignments().await;
                }
            }
        }

        poll_handle.abort();
    }

    fn clone_ref(&self) -> Self {
        Self {
            platform_url: self.platform_url.clone(),
            challenge_id: self.challenge_id.clone(),
            keypair: self.keypair.clone(),
            validator_hotkey: self.validator_hotkey.clone(),
            http_client: self.http_client.clone(),
            in_progress: self.in_progress.clone(),
            task_registry: self.task_registry.clone(),
            container_backend: self.container_backend.clone(),
            binary_cache: self.binary_cache.clone(),
        }
    }

    /// Called on startup AND after reconnection
    pub async fn recover_pending_assignments(&self) {
        info!("Recovering pending assignments...");

        match self.fetch_my_jobs().await {
            Ok(jobs) => {
                let ready_count = jobs.iter().filter(|j| j.binary_ready).count();
                info!(
                    "Found {} pending jobs ({} with binary ready)",
                    jobs.len(),
                    ready_count
                );

                for job in jobs {
                    if job.binary_ready {
                        let worker = self.clone_ref();
                        let agent_hash = job.agent_hash.clone();
                        tokio::spawn(async move {
                            worker.handle_binary_ready(&agent_hash).await;
                        });
                    }
                }
            }
            Err(e) => {
                error!("Failed to fetch pending jobs: {}", e);
            }
        }
    }

    /// Polling loop - every 1 minute
    async fn poll_loop(&self) {
        let mut interval = tokio::time::interval(POLL_INTERVAL);

        loop {
            interval.tick().await;
            debug!("Polling for pending jobs...");

            match self.fetch_my_jobs().await {
                Ok(jobs) => {
                    if jobs.is_empty() {
                        debug!("No pending jobs");
                    } else {
                        info!("Found {} pending jobs", jobs.len());
                    }
                    let in_progress = self.in_progress.read().await;

                    for job in jobs {
                        if job.binary_ready && !in_progress.contains(&job.agent_hash) {
                            drop(in_progress);

                            let worker = self.clone_ref();
                            let agent_hash = job.agent_hash.clone();
                            tokio::spawn(async move {
                                worker.handle_binary_ready(&agent_hash).await;
                            });

                            break; // One at a time to avoid overload
                        }
                    }
                }
                Err(e) => {
                    warn!("Poll failed: {}", e);
                }
            }
        }
    }

    /// Handle binary_ready event
    pub async fn handle_binary_ready(&self, agent_hash: &str) {
        // Check if already in progress
        {
            let mut in_progress = self.in_progress.write().await;
            if in_progress.contains(agent_hash) {
                debug!(
                    "Agent {} already in progress, skipping",
                    &agent_hash[..16.min(agent_hash.len())]
                );
                return;
            }
            in_progress.insert(agent_hash.to_string());
        }

        let short_hash = &agent_hash[..16.min(agent_hash.len())];
        info!("Starting evaluation for agent {}", short_hash);

        // Run evaluation
        let result = self.evaluate_agent(agent_hash).await;

        // Remove from in_progress
        {
            let mut in_progress = self.in_progress.write().await;
            in_progress.remove(agent_hash);
        }

        match result {
            Ok(_) => {
                info!("Evaluation completed for agent {}", short_hash);
            }
            Err(e) => {
                error!("Evaluation failed for agent {}: {}", short_hash, e);
            }
        }
    }

    /// Core evaluation: download → run → submit
    async fn evaluate_agent(&self, agent_hash: &str) -> Result<()> {
        let short_hash = &agent_hash[..16.min(agent_hash.len())];

        // 1. Download binary
        info!("Downloading binary for agent {}...", short_hash);
        let binary = self.download_binary(agent_hash).await?;
        info!("Downloaded binary: {} bytes", binary.len());

        // 2. Run evaluation in Docker
        info!("Running evaluation in Docker...");
        let result = self.run_binary_in_docker(&binary, agent_hash).await?;
        info!(
            "Evaluation result: score={:.2}%, passed={}/{}",
            result.score * 100.0,
            result.tasks_passed,
            result.tasks_total
        );

        // 3. Submit result
        info!("Submitting result...");
        self.submit_result(agent_hash, &result).await?;
        info!("Result submitted for agent {}", short_hash);

        Ok(())
    }

    /// Fetch pending jobs from server
    async fn fetch_my_jobs(&self) -> Result<Vec<ValidatorJob>> {
        let url = format!(
            "{}/api/v1/bridge/{}/api/v1/validator/my_jobs",
            self.platform_url, self.challenge_id
        );

        let timestamp = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)?
            .as_secs() as i64;

        let message = format!("get_my_jobs:{}", timestamp);
        let signature = self.sign_message(&message);

        let response = self
            .http_client
            .post(&url)
            .json(&serde_json::json!({
                "validator_hotkey": self.validator_hotkey,
                "timestamp": timestamp,
                "signature": signature,
            }))
            .send()
            .await?;

        if !response.status().is_success() {
            let status = response.status();
            let text = response.text().await.unwrap_or_default();
            anyhow::bail!("my_jobs request failed: {} - {}", status, text);
        }

        let body: serde_json::Value = response.json().await?;
        // Server returns "pending_jobs" field
        let jobs = body["pending_jobs"]
            .as_array()
            .map(|arr| {
                arr.iter()
                    .filter_map(|j| {
                        Some(ValidatorJob {
                            agent_hash: j["agent_hash"].as_str()?.to_string(),
                            miner_hotkey: j["miner_hotkey"].as_str().unwrap_or("").to_string(),
                            submission_id: j["submission_id"].as_str().unwrap_or("").to_string(),
                            binary_ready: j["binary_ready"]
                                .as_bool()
                                .or_else(|| j["compile_status"].as_str().map(|s| s == "success"))
                                .unwrap_or(false),
                        })
                    })
                    .collect()
            })
            .unwrap_or_default();

        Ok(jobs)
    }

    /// Download compiled binary via bridge (with caching)
    async fn download_binary(&self, agent_hash: &str) -> Result<Vec<u8>> {
        // Check cache first
        {
            let cache = self.binary_cache.read().await;
            if let Some(binary) = cache.get(agent_hash) {
                debug!(
                    "Binary cache hit for agent {} ({} bytes)",
                    &agent_hash[..16.min(agent_hash.len())],
                    binary.len()
                );
                return Ok(binary.clone());
            }
        }

        let url = format!(
            "{}/api/v1/bridge/{}/api/v1/validator/download_binary/{}",
            self.platform_url, self.challenge_id, agent_hash
        );

        let timestamp = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)?
            .as_secs() as i64;

        let message = format!("download_binary:{}:{}", agent_hash, timestamp);
        let signature = self.sign_message(&message);

        let response = self
            .http_client
            .post(&url)
            .json(&serde_json::json!({
                "validator_hotkey": self.validator_hotkey,
                "timestamp": timestamp,
                "signature": signature,
            }))
            .send()
            .await?;

        if !response.status().is_success() {
            let status = response.status();
            let text = response.text().await.unwrap_or_default();
            anyhow::bail!("Binary download failed: {} - {}", status, text);
        }

        let binary = response.bytes().await?.to_vec();

        if binary.is_empty() {
            anyhow::bail!("Downloaded binary is empty");
        }

        // Cache the binary
        {
            let mut cache = self.binary_cache.write().await;
            cache.insert(agent_hash.to_string(), binary.clone());
            // Limit cache size to prevent memory issues (keep last 20 binaries)
            if cache.len() > 20 {
                // Remove oldest entry (simple LRU-ish approach)
                if let Some(oldest_key) = cache.keys().next().cloned() {
                    cache.remove(&oldest_key);
                }
            }
        }

        Ok(binary)
    }

    /// Run binary in Docker container against real tasks
    async fn run_binary_in_docker(&self, binary: &[u8], agent_hash: &str) -> Result<EvalResult> {
        use std::io::Write;
        use tempfile::NamedTempFile;

        // Write binary to temp file
        let mut temp_file = NamedTempFile::new().context("Failed to create temp file")?;
        temp_file
            .write_all(binary)
            .context("Failed to write binary")?;
        let binary_path = temp_file.path().to_string_lossy().to_string();

        // Make executable
        #[cfg(unix)]
        {
            use std::os::unix::fs::PermissionsExt;
            let mut perms = std::fs::metadata(&binary_path)?.permissions();
            perms.set_mode(0o755);
            std::fs::set_permissions(&binary_path, perms)?;
        }

        // Get real tasks from terminal-bench@2.0
        let tasks = self.get_evaluation_tasks().await?;

        let tasks_total = tasks.len() as i32;
        let mut tasks_passed = 0i32;
        let mut tasks_failed = 0i32;

        for task in &tasks {
            let task_id = task.id();
            let instruction = task.instruction();

            info!(
                "Running task: {} - {}",
                task_id,
                &instruction[..50.min(instruction.len())]
            );

            let result = self.run_task_in_docker(&binary_path, task).await;

            let task_result = match result {
                Ok(tr) => {
                    if tr.passed {
                        info!("Task {} PASSED", task_id);
                        tasks_passed += 1;
                    } else {
                        info!("Task {} FAILED", task_id);
                        tasks_failed += 1;
                    }
                    tr
                }
                Err(e) => {
                    // Log full error chain with :? for debugging Docker issues
                    warn!("Task {} error: {:?}", task_id, e);
                    tasks_failed += 1;
                    TaskResult {
                        passed: false,
                        duration_ms: 0,
                        error: Some(format!("{:?}", e)),
                        agent_stderr: None,
                        test_output: None,
                    }
                }
            };

            // Log task result to platform server (include stderr and test output for debugging)
            let error_details = task_result.error.clone().or_else(|| {
                // If no error but task failed, include test output and stderr for debugging
                if !task_result.passed {
                    let mut details = Vec::new();
                    if let Some(ref stderr) = task_result.agent_stderr {
                        details.push(format!("Agent stderr: {}", stderr));
                    }
                    if let Some(ref output) = task_result.test_output {
                        // Truncate test output to avoid huge payloads
                        let truncated = if output.len() > 500 {
                            format!("{}... (truncated)", &output[..500])
                        } else {
                            output.clone()
                        };
                        details.push(format!("Test output: {}", truncated));
                    }
                    if details.is_empty() {
                        None
                    } else {
                        Some(details.join("\n"))
                    }
                } else {
                    None
                }
            });

            if let Err(e) = self
                .log_task_result(
                    agent_hash,
                    task_id,
                    task_result.passed,
                    task_result.duration_ms,
                    error_details,
                )
                .await
            {
                warn!("Failed to log task {} result: {}", task_id, e);
            }
        }

        let score = if tasks_total > 0 {
            tasks_passed as f64 / tasks_total as f64
        } else {
            0.0
        };

        Ok(EvalResult {
            score,
            tasks_passed,
            tasks_total,
            tasks_failed,
            total_cost: 0.0,
        })
    }

    /// Execute single task using the container backend (broker or Docker)
    async fn run_task_in_docker(&self, binary_path: &str, task: &Task) -> Result<TaskResult> {
        use crate::container_backend::MountConfig;
        use std::time::Instant;

        let start = Instant::now();
        let task_id = task.id();
        let timeout_secs = task.config.timeout_secs as u64;

        // Build environment variables from task config
        let mut env = std::collections::HashMap::new();
        for var in &task.config.env {
            if let Some((k, v)) = var.split_once('=') {
                env.insert(k.to_string(), v.to_string());
            }
        }
        env.insert("TEST_DIR".to_string(), "/tests".to_string());
        env.insert("TERM".to_string(), "xterm-256color".to_string());

        // Parse memory limit (e.g., "2g" -> bytes)
        let memory_bytes = parse_memory_string(&task.config.memory_limit);

        // Build mounts if task has a path
        let mounts = if let Some(task_path) = &task.path {
            // For Docker-in-Docker, map container paths to host paths
            let path_str = task_path.to_string_lossy();
            let source_path = map_path_for_dind(&path_str);
            vec![MountConfig {
                source: source_path,
                target: "/task".to_string(),
                read_only: true,
            }]
        } else {
            vec![]
        };

        // Create sandbox config
        let config = SandboxConfig {
            image: task.config.docker_image.clone(),
            memory_bytes,
            cpu_cores: task.config.cpu_limit,
            env,
            working_dir: "/app".to_string(),
            network_mode: "bridge".to_string(),
            mounts,
            cmd: Some(vec![
                "tail".to_string(),
                "-f".to_string(),
                "/dev/null".to_string(),
            ]),
            challenge_id: self.challenge_id.clone(),
            owner_id: self.validator_hotkey.clone(),
            name: None,
        };

        // Create and start container via backend
        debug!(
            "Creating task container with image: {}",
            task.config.docker_image
        );
        let task_container = self
            .container_backend
            .create_sandbox(config)
            .await
            .with_context(|| {
                format!(
                    "Failed to create task container (image: {}, task_path: {:?})",
                    task.config.docker_image, task.path
                )
            })?;

        task_container
            .start()
            .await
            .context("Failed to start task container")?;

        // Run setup script if present
        if let Some(setup_script) = &task.setup_script {
            debug!("Running setup script");
            if let Err(e) = task_container.exec(&["sh", "-c", setup_script]).await {
                warn!("Setup script failed: {}", e);
            }
        }

        // Copy test files to container
        if !task.test_files.is_empty() {
            debug!("Copying {} test files", task.test_files.len());
            let _ = task_container.exec(&["mkdir", "-p", "/tests"]).await;
            for (filename, content) in &task.test_files {
                // Use write_file from ContainerHandle
                let file_path = format!("/tests/{}", filename);
                if let Err(e) = task_container
                    .write_file(&file_path, content.as_bytes())
                    .await
                {
                    warn!("Failed to write test file {}: {}", filename, e);
                    // Fallback to exec with base64
                    let encoded = base64::engine::general_purpose::STANDARD.encode(content);
                    let cmd = format!("echo '{}' | base64 -d > '{}'", encoded, file_path);
                    let _ = task_container.exec(&["sh", "-c", &cmd]).await;
                }
            }
        }

        // Run the agent binary against this task
        let instruction = task.instruction();
        let (agent_completed, agent_stderr) = self
            .run_agent_loop(
                task_container.as_ref(),
                binary_path,
                instruction,
                timeout_secs,
            )
            .await
            .unwrap_or((false, String::new()));

        // Run verification (test script)
        let (test_passed, test_output) = if agent_completed {
            match self
                .run_test_script(task_container.as_ref(), &task.test_script)
                .await
            {
                Ok((passed, output)) => (passed, Some(output)),
                Err(e) => (false, Some(format!("Test error: {}", e))),
            }
        } else {
            (false, Some("Agent did not complete".to_string()))
        };

        // Cleanup
        let _ = task_container.stop().await;
        let _ = task_container.remove().await;

        let elapsed = start.elapsed();
        debug!(
            "Task {} completed in {:?}: {}",
            task_id, elapsed, test_passed
        );

        Ok(TaskResult {
            passed: test_passed,
            duration_ms: elapsed.as_millis() as i64,
            error: None,
            agent_stderr: if agent_stderr.is_empty() {
                None
            } else {
                Some(agent_stderr)
            },
            test_output,
        })
    }

    /// Run the agent binary in a loop until completion or timeout
    /// Returns (completed, accumulated_stderr)
    async fn run_agent_loop(
        &self,
        task_container: &dyn ContainerHandle,
        binary_path: &str,
        instruction: &str,
        _timeout_secs: u64,
    ) -> Result<(bool, String)> {
        use std::process::Stdio;
        use tokio::io::AsyncWriteExt;
        use tokio::process::Command;

        const MAX_STEPS: usize = 50;

        let mut last_output = String::new();
        let mut last_exit_code = 0i32;
        let mut accumulated_stderr = String::new();

        for step in 1..=MAX_STEPS {
            let input = serde_json::json!({
                "instruction": instruction,
                "step": step,
                "output": last_output,
                "exit_code": last_exit_code,
                "cwd": "/app"
            });

            // Run agent binary to get next command
            let agent_response = tokio::time::timeout(Duration::from_secs(30), async {
                let mut child = Command::new(binary_path)
                    .stdin(Stdio::piped())
                    .stdout(Stdio::piped())
                    .stderr(Stdio::piped())
                    .spawn()?;

                if let Some(mut stdin) = child.stdin.take() {
                    stdin.write_all(format!("{}\n", input).as_bytes()).await?;
                    stdin.flush().await?;
                }

                let output = child.wait_with_output().await?;
                let stdout = String::from_utf8_lossy(&output.stdout).to_string();
                let stderr = String::from_utf8_lossy(&output.stderr).to_string();
                Ok::<_, anyhow::Error>((stdout, stderr))
            })
            .await
            .map_err(|_| anyhow::anyhow!("Agent timeout"))?;

            let (stdout, stderr) = agent_response?;

            // Accumulate stderr for debugging agent issues
            if !stderr.is_empty() {
                debug!("Agent stderr at step {}: {}", step, stderr.trim());
                if !accumulated_stderr.is_empty() {
                    accumulated_stderr.push('\n');
                }
                accumulated_stderr.push_str(&format!("[step {}] {}", step, stderr.trim()));
            }

            // Parse agent response
            let response: serde_json::Value = stdout
                .lines()
                .last()
                .and_then(|line| serde_json::from_str(line).ok())
                .unwrap_or_default();

            // Check if agent is done
            if response["done"].as_bool().unwrap_or(false) {
                debug!("Agent signaled completion at step {}", step);
                return Ok((true, accumulated_stderr));
            }

            // Get command to execute
            let command = match response["command"].as_str() {
                Some(cmd) if !cmd.is_empty() => cmd.to_string(),
                _ => {
                    debug!("No command from agent at step {}", step);
                    continue;
                }
            };

            // Execute command in task container
            let exec_result = task_container.exec(&["sh", "-c", &command]).await;
            match exec_result {
                Ok(result) => {
                    last_output = result.combined();
                    last_exit_code = result.exit_code;
                }
                Err(e) => {
                    last_output = format!("Error: {}", e);
                    last_exit_code = 1;
                }
            }
        }

        warn!("Agent reached max steps without completion");
        Ok((false, accumulated_stderr))
    }

    /// Run the test script to verify task completion
    /// Returns (passed, output)
    async fn run_test_script(
        &self,
        task_container: &dyn ContainerHandle,
        test_script: &str,
    ) -> Result<(bool, String)> {
        let result = task_container.exec(&["sh", "-c", test_script]).await;

        match result {
            Ok(exec_result) => {
                let output = exec_result.combined();
                // Check exit code first
                if exec_result.success() {
                    return Ok((true, output));
                }
                // Check for common test success indicators in output
                let passed = output.contains("PASS")
                    || output.contains("OK")
                    || output.contains("passed")
                    || (!output.contains("FAIL") && !output.contains("ERROR"));
                Ok((passed, output))
            }
            Err(e) => {
                debug!("Test script failed: {}", e);
                Ok((false, format!("Test execution error: {}", e)))
            }
        }
    }

    /// Submit result via bridge
    async fn submit_result(&self, agent_hash: &str, result: &EvalResult) -> Result<()> {
        let url = format!(
            "{}/api/v1/bridge/{}/api/v1/validator/submit_result",
            self.platform_url, self.challenge_id
        );

        let timestamp = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)?
            .as_secs() as i64;

        let message = format!("submit_result:{}:{}", agent_hash, timestamp);
        let signature = self.sign_message(&message);

        let response = self
            .http_client
            .post(&url)
            .json(&serde_json::json!({
                "agent_hash": agent_hash,
                "validator_hotkey": self.validator_hotkey,
                "score": result.score,
                "tasks_passed": result.tasks_passed,
                "tasks_total": result.tasks_total,
                "tasks_failed": result.tasks_failed,
                "total_cost_usd": result.total_cost,
                "timestamp": timestamp,
                "signature": signature,
            }))
            .send()
            .await?;

        if !response.status().is_success() {
            let status = response.status();
            let text = response.text().await.unwrap_or_default();
            anyhow::bail!("Submit result failed: {} - {}", status, text);
        }

        Ok(())
    }

    /// Sign message with validator keypair
    fn sign_message(&self, message: &str) -> String {
        hex::encode(self.keypair.sign(message.as_bytes()).0)
    }

    /// Log individual task result to platform server
    async fn log_task_result(
        &self,
        agent_hash: &str,
        task_id: &str,
        passed: bool,
        duration_ms: i64,
        error: Option<String>,
    ) -> Result<()> {
        let url = format!(
            "{}/api/v1/bridge/{}/api/v1/validator/log_task",
            self.platform_url, self.challenge_id
        );

        let now = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)?
            .as_secs() as i64;

        let message = format!("log_task:{}:{}:{}", agent_hash, task_id, now);
        let signature = self.sign_message(&message);

        // API expects these fields from LogTaskRequest
        let response = self
            .http_client
            .post(&url)
            .json(&serde_json::json!({
                "validator_hotkey": self.validator_hotkey,
                "signature": signature,
                "timestamp": now,
                "agent_hash": agent_hash,
                "task_id": task_id,
                "task_name": task_id,  // Use task_id as task_name
                "passed": passed,
                "score": if passed { 1.0 } else { 0.0 },
                "execution_time_ms": duration_ms,
                "steps": 0,  // Not tracked currently
                "cost_usd": 0.0,  // Not tracked currently
                "error": error,
                "execution_log": null,
                "trajectory": null,
                "started_at": now - (duration_ms / 1000),
            }))
            .send()
            .await?;

        if !response.status().is_success() {
            let status = response.status();
            let text = response.text().await.unwrap_or_default();
            anyhow::bail!("log_task failed: {} - {}", status, text);
        }

        Ok(())
    }
}

#[derive(Debug)]
struct ValidatorJob {
    agent_hash: String,
    miner_hotkey: String,
    submission_id: String,
    binary_ready: bool,
}

/// Parse memory string like "2g", "512m", "1024k" to bytes
fn parse_memory_string(s: &str) -> i64 {
    let s = s.trim().to_lowercase();
    let (num_str, multiplier) = if s.ends_with("g") || s.ends_with("gb") {
        (
            s.trim_end_matches("gb").trim_end_matches("g"),
            1024 * 1024 * 1024,
        )
    } else if s.ends_with("m") || s.ends_with("mb") {
        (s.trim_end_matches("mb").trim_end_matches("m"), 1024 * 1024)
    } else if s.ends_with("k") || s.ends_with("kb") {
        (s.trim_end_matches("kb").trim_end_matches("k"), 1024)
    } else {
        (s.as_str(), 1)
    };

    num_str.parse::<i64>().unwrap_or(2 * 1024 * 1024 * 1024) * multiplier
}

/// Map container paths to host paths for Docker-in-Docker scenarios
///
/// When running inside a container that uses Docker-in-Docker (via broker),
/// bind mount paths must reference the host filesystem, not the container filesystem.
///
/// Supports:
/// - HOST_CACHE_DIR/CACHE_DIR: For downloaded datasets (e.g., /root/.cache/term-challenge)
/// - HOST_TASKS_DIR/TASKS_DIR: For task data (e.g., /app/data/tasks)
fn map_path_for_dind(path: &str) -> String {
    // Try cache directory mapping first (for downloaded datasets)
    // Cache dir is typically /root/.cache/term-challenge/datasets/...
    if path.contains(".cache/term-challenge") || path.contains("/datasets/") {
        if let Ok(host_cache_dir) = std::env::var("HOST_CACHE_DIR") {
            let cache_dir = std::env::var("CACHE_DIR")
                .unwrap_or_else(|_| "/root/.cache/term-challenge".to_string());
            if path.starts_with(&cache_dir) {
                let relative = path.strip_prefix(&cache_dir).unwrap_or(path);
                let mapped = format!("{}{}", host_cache_dir, relative);
                tracing::debug!(
                    "Docker-in-Docker cache path mapping: {} -> {}",
                    path,
                    mapped
                );
                return mapped;
            }
        }
    }

    // Try tasks directory mapping
    if let Ok(host_tasks_dir) = std::env::var("HOST_TASKS_DIR") {
        let tasks_dir =
            std::env::var("TASKS_DIR").unwrap_or_else(|_| "/app/data/tasks".to_string());
        if path.starts_with(&tasks_dir) {
            let relative = path.strip_prefix(&tasks_dir).unwrap_or(path);
            let mapped = format!("{}{}", host_tasks_dir, relative);
            tracing::debug!(
                "Docker-in-Docker tasks path mapping: {} -> {}",
                path,
                mapped
            );
            return mapped;
        }
    }

    // No mapping needed
    path.to_string()
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_map_path_for_dind_cache() {
        // Simulate Docker-in-Docker environment
        std::env::set_var("HOST_CACHE_DIR", "/tmp/platform-cache");
        std::env::set_var("CACHE_DIR", "/root/.cache/term-challenge");

        let input = "/root/.cache/term-challenge/datasets/custom-memory-heap-crash";
        let output = map_path_for_dind(input);
        assert_eq!(
            output,
            "/tmp/platform-cache/datasets/custom-memory-heap-crash"
        );

        // Clean up
        std::env::remove_var("HOST_CACHE_DIR");
        std::env::remove_var("CACHE_DIR");
    }

    #[test]
    fn test_map_path_for_dind_tasks() {
        // Simulate Docker-in-Docker environment
        std::env::set_var("HOST_TASKS_DIR", "/tmp/platform-tasks");
        std::env::set_var("TASKS_DIR", "/app/data/tasks");

        let input = "/app/data/tasks/some-task";
        let output = map_path_for_dind(input);
        assert_eq!(output, "/tmp/platform-tasks/some-task");

        // Clean up
        std::env::remove_var("HOST_TASKS_DIR");
        std::env::remove_var("TASKS_DIR");
    }

    #[test]
    fn test_map_path_for_dind_unaffected_path() {
        // A path that doesn't match any mapping patterns should be unchanged
        // even if env vars are set
        std::env::set_var("HOST_CACHE_DIR", "/tmp/platform-cache");
        std::env::set_var("CACHE_DIR", "/root/.cache/term-challenge");

        let input = "/some/random/path/that/doesnt/match";
        let output = map_path_for_dind(input);
        assert_eq!(output, input);

        // Clean up
        std::env::remove_var("HOST_CACHE_DIR");
        std::env::remove_var("CACHE_DIR");
    }
}
