//! PostgreSQL Storage for Challenge Server Mode
//!
//! Provides persistent storage for challenge server running in subnet owner mode.
//! Uses the same PostgreSQL instance as platform-server but with a separate database.
//!
//! Schema is managed via migrations in the `migrations/` directory.
//!
//! API keys are encrypted at rest using ChaCha20-Poly1305.

use crate::encrypted_api_key::{self, ApiKeyError};
use crate::epoch::EpochCalculator;
use crate::migrations;
use anyhow::Result;
use deadpool_postgres::{Config, Pool, Runtime};
use serde::{Deserialize, Serialize};
use tokio_postgres::NoTls;
use tracing::{debug, error, info, warn};

/// Minimum seconds between submissions for the same miner (3.6 hours)
pub const SUBMISSION_COOLDOWN_SECS: i64 = 360 * 12 * 3; // 12960 seconds = 3.6 hours

/// Maximum cost limit per validator in USD
pub const MAX_COST_LIMIT_USD: f64 = 100.0;

/// Default cost limit per validator in USD
pub const DEFAULT_COST_LIMIT_USD: f64 = 80.0;

/// Maximum number of validators per agent evaluation
pub const MAX_VALIDATORS_PER_AGENT: i32 = 2;

/// Maximum log size per field (1 MB)
const MAX_LOG_SIZE: usize = 4 * 1024 * 1024; // 4MB

/// Truncate log string to maximum size
fn truncate_log(log: Option<String>) -> Option<String> {
    log.map(|s| {
        if s.len() > MAX_LOG_SIZE {
            format!(
                "{}...[TRUNCATED, {} bytes total]",
                &s[..MAX_LOG_SIZE],
                s.len()
            )
        } else {
            s
        }
    })
}

// Legacy schema kept for reference - migrations are now in migrations/ directory
#[allow(dead_code)]
const LEGACY_SCHEMA: &str = r#"
-- ============================================================================
-- MIGRATION: Drop old pending_evaluations table if it has old schema
-- ============================================================================
DO $$
BEGIN
    -- Check if pending_evaluations has old schema (claimed_by column)
    IF EXISTS (
        SELECT 1 FROM information_schema.columns 
        WHERE table_name = 'pending_evaluations' AND column_name = 'claimed_by'
    ) THEN
        -- Drop old table and its indexes
        DROP TABLE IF EXISTS pending_evaluations CASCADE;
        RAISE NOTICE 'Dropped old pending_evaluations table (migration to new schema)';
    END IF;
END $$;

-- ============================================================================
-- SCHEMA
-- ============================================================================

-- Agent submissions (source code is SENSITIVE - only owner and validators can access)
CREATE TABLE IF NOT EXISTS submissions (
    id TEXT PRIMARY KEY,
    agent_hash TEXT NOT NULL UNIQUE,
    miner_hotkey TEXT NOT NULL,
    source_code TEXT NOT NULL,
    source_hash TEXT NOT NULL,
    name TEXT,
    epoch BIGINT NOT NULL DEFAULT 0,
    status TEXT NOT NULL DEFAULT 'pending',
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS idx_submissions_agent ON submissions(agent_hash);
CREATE INDEX IF NOT EXISTS idx_submissions_miner ON submissions(miner_hotkey);
CREATE INDEX IF NOT EXISTS idx_submissions_status ON submissions(status);
CREATE INDEX IF NOT EXISTS idx_submissions_epoch ON submissions(epoch);

-- Evaluation results from this challenge
CREATE TABLE IF NOT EXISTS evaluations (
    id TEXT PRIMARY KEY,
    submission_id TEXT NOT NULL,
    agent_hash TEXT NOT NULL,
    miner_hotkey TEXT NOT NULL,
    score REAL NOT NULL,
    tasks_passed INTEGER NOT NULL,
    tasks_total INTEGER NOT NULL,
    tasks_failed INTEGER NOT NULL,
    total_cost_usd REAL NOT NULL DEFAULT 0.0,
    execution_time_ms BIGINT,
    task_results JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS idx_evaluations_agent ON evaluations(agent_hash);
CREATE INDEX IF NOT EXISTS idx_evaluations_submission ON evaluations(submission_id);
CREATE INDEX IF NOT EXISTS idx_evaluations_created ON evaluations(created_at DESC);

-- Leaderboard for this challenge (PUBLIC - no source code)
CREATE TABLE IF NOT EXISTS leaderboard (
    agent_hash TEXT PRIMARY KEY,
    miner_hotkey TEXT NOT NULL,
    name TEXT,
    best_score REAL NOT NULL,
    avg_score REAL NOT NULL,
    evaluation_count INTEGER NOT NULL DEFAULT 0,
    total_cost_usd REAL NOT NULL DEFAULT 0.0,
    rank INTEGER,
    first_seen TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    last_updated TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS idx_leaderboard_rank ON leaderboard(rank);
CREATE INDEX IF NOT EXISTS idx_leaderboard_score ON leaderboard(best_score DESC);

-- Pending evaluations (queued for processing by ALL validators)
-- Each agent needs evaluation by ALL active validators
CREATE TABLE IF NOT EXISTS pending_evaluations (
    id TEXT PRIMARY KEY,
    submission_id TEXT NOT NULL,
    agent_hash TEXT NOT NULL UNIQUE,
    miner_hotkey TEXT NOT NULL,
    epoch BIGINT NOT NULL DEFAULT 0,
    status TEXT NOT NULL DEFAULT 'pending',
    validators_completed INTEGER NOT NULL DEFAULT 0,
    total_validators INTEGER NOT NULL DEFAULT 0,
    window_started_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    window_expires_at TIMESTAMPTZ NOT NULL DEFAULT (NOW() + INTERVAL '6 hours'),
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS idx_pending_status ON pending_evaluations(status);
CREATE INDEX IF NOT EXISTS idx_pending_agent ON pending_evaluations(agent_hash);
CREATE INDEX IF NOT EXISTS idx_pending_window ON pending_evaluations(window_expires_at);

-- Validator evaluations: ONE evaluation per validator per agent
-- ALL validators must evaluate each agent (except late ones after 6h)
CREATE TABLE IF NOT EXISTS validator_evaluations (
    id TEXT PRIMARY KEY,
    agent_hash TEXT NOT NULL,
    validator_hotkey TEXT NOT NULL,
    submission_id TEXT NOT NULL,
    miner_hotkey TEXT NOT NULL,
    score REAL NOT NULL,
    tasks_passed INTEGER NOT NULL,
    tasks_total INTEGER NOT NULL,
    tasks_failed INTEGER NOT NULL,
    total_cost_usd REAL NOT NULL DEFAULT 0.0,
    execution_time_ms BIGINT,
    task_results JSONB,
    epoch BIGINT NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    -- UNIQUE: 1 evaluation per validator per agent
    UNIQUE(agent_hash, validator_hotkey)
);

CREATE INDEX IF NOT EXISTS idx_val_evals_agent ON validator_evaluations(agent_hash);
CREATE INDEX IF NOT EXISTS idx_val_evals_validator ON validator_evaluations(validator_hotkey);
CREATE INDEX IF NOT EXISTS idx_val_evals_epoch ON validator_evaluations(epoch);

-- Track which validators are ASSIGNED to evaluate which agents
-- This is set when the agent is submitted (deterministic selection)
CREATE TABLE IF NOT EXISTS validator_assignments (
    id TEXT PRIMARY KEY,
    agent_hash TEXT NOT NULL,
    validator_hotkey TEXT NOT NULL,
    status TEXT NOT NULL DEFAULT 'pending',
    assigned_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    -- UNIQUE: 1 assignment per validator per agent
    UNIQUE(agent_hash, validator_hotkey)
);

CREATE INDEX IF NOT EXISTS idx_assignments_agent ON validator_assignments(agent_hash);
CREATE INDEX IF NOT EXISTS idx_assignments_validator ON validator_assignments(validator_hotkey);

-- Track which validators have claimed which agents (in progress)
CREATE TABLE IF NOT EXISTS validator_claims (
    id TEXT PRIMARY KEY,
    agent_hash TEXT NOT NULL,
    validator_hotkey TEXT NOT NULL,
    claimed_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    status TEXT NOT NULL DEFAULT 'claimed',
    
    -- UNIQUE: 1 active claim per validator per agent
    UNIQUE(agent_hash, validator_hotkey)
);

CREATE INDEX IF NOT EXISTS idx_claims_agent ON validator_claims(agent_hash);
CREATE INDEX IF NOT EXISTS idx_claims_validator ON validator_claims(validator_hotkey);

-- Config cache
CREATE TABLE IF NOT EXISTS config (
    key TEXT PRIMARY KEY,
    value TEXT NOT NULL,
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- Current epoch tracking
CREATE TABLE IF NOT EXISTS epoch_state (
    id INTEGER PRIMARY KEY DEFAULT 1 CHECK (id = 1),
    current_epoch BIGINT NOT NULL DEFAULT 0,
    last_epoch_change TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

INSERT INTO epoch_state (id, current_epoch) VALUES (1, 0) ON CONFLICT DO NOTHING;
"#;

// ============================================================================
// DATA STRUCTURES
// ============================================================================

/// Agent submission record
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Submission {
    pub id: String,
    pub agent_hash: String,
    pub miner_hotkey: String,
    pub source_code: String,
    pub source_hash: String,
    pub name: Option<String>,
    /// Agent version (auto-incremented per miner+name)
    pub version: i32,
    pub epoch: i64,
    pub status: String,
    /// User's API key for LLM inferences (bridge for agent requests)
    pub api_key: Option<String>,
    /// API provider: openrouter, chutes, openai, anthropic, grok
    pub api_provider: Option<String>,
    /// Cost limit per validator in USD (user chooses, max 100$)
    pub cost_limit_usd: f64,
    /// Total cost accumulated for this submission
    pub total_cost_usd: f64,
    pub created_at: i64,
    /// Compiled PyInstaller binary (only set after successful compilation)
    #[serde(skip_serializing)]
    pub binary: Option<Vec<u8>>,
    /// Size of compiled binary in bytes
    pub binary_size: i32,
    /// Compilation status: pending, compiling, success, failed
    pub compile_status: String,
    /// Compilation error message if failed
    pub compile_error: Option<String>,
    /// Compilation time in milliseconds
    pub compile_time_ms: i32,
    /// Whether agent passed LLM security review
    pub llm_approved: bool,
    /// Whether agent is flagged for manual review
    pub flagged: bool,
    /// Reason for flagging if flagged=true
    pub flag_reason: Option<String>,
}

/// Submission without source code (for listings)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SubmissionInfo {
    pub id: String,
    pub agent_hash: String,
    pub miner_hotkey: String,
    pub name: Option<String>,
    pub version: i32,
    pub epoch: i64,
    pub status: String,
    pub cost_limit_usd: f64,
    pub total_cost_usd: f64,
    pub created_at: i64,
}

/// Miner submission history for rate limiting
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MinerSubmissionHistory {
    pub miner_hotkey: String,
    pub last_submission_epoch: i64,
    pub last_submission_at: i64,
    pub total_submissions: i32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EvaluationRecord {
    pub id: String,
    pub submission_id: String,
    pub agent_hash: String,
    pub miner_hotkey: String,
    pub score: f64,
    pub tasks_passed: i32,
    pub tasks_total: i32,
    pub tasks_failed: i32,
    pub total_cost_usd: f64,
    pub execution_time_ms: Option<i64>,
    pub task_results: Option<serde_json::Value>,
    pub created_at: i64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LeaderboardEntry {
    pub agent_hash: String,
    pub miner_hotkey: String,
    pub name: Option<String>,
    pub best_score: f64,
    pub avg_score: f64,
    pub evaluation_count: i32,
    pub total_cost_usd: f64,
    pub rank: Option<i32>,
}

/// Pending evaluation - one per agent, ALL validators must evaluate
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PendingEvaluation {
    pub id: String,
    pub submission_id: String,
    pub agent_hash: String,
    pub miner_hotkey: String,
    pub epoch: i64,
    pub status: String,
    pub validators_completed: i32,
    pub total_validators: i32,
    pub window_started_at: i64,
    pub window_expires_at: i64,
    pub created_at: i64,
}

/// Validator's evaluation result for one agent
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ValidatorEvaluation {
    pub id: String,
    pub agent_hash: String,
    pub validator_hotkey: String,
    pub submission_id: String,
    pub miner_hotkey: String,
    pub score: f64,
    pub tasks_passed: i32,
    pub tasks_total: i32,
    pub tasks_failed: i32,
    pub total_cost_usd: f64,
    pub execution_time_ms: Option<i64>,
    pub task_results: Option<serde_json::Value>,
    pub epoch: i64,
    pub created_at: i64,
}

/// Active claim - validator is working on this agent
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ValidatorClaim {
    pub id: String,
    pub agent_hash: String,
    pub validator_hotkey: String,
    pub claimed_at: i64,
    pub status: String,
}

/// Job info returned when claiming
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ClaimableJob {
    pub pending_id: String,
    pub submission_id: String,
    pub agent_hash: String,
    pub miner_hotkey: String,
    /// Compiled binary (base64 encoded for JSON transport)
    pub binary_base64: String,
    /// Binary size in bytes
    pub binary_size: i32,
    pub window_expires_at: i64,
    pub tasks: Vec<TaskAssignment>,
}

/// Validator job info with compile status (for get_my_jobs endpoint)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ValidatorJobInfo {
    pub agent_hash: String,
    pub miner_hotkey: String,
    pub submission_id: String,
    pub assigned_at: i64,
    pub compile_status: String, // "pending", "compiling", "success", "failed"
}

/// Task assignment info for validators
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TaskAssignment {
    pub task_id: String,
    pub task_name: String,
}

/// Individual task log from validator (real-time reporting)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TaskLog {
    pub id: String,
    pub agent_hash: String,
    pub validator_hotkey: String,
    pub task_id: String,
    pub task_name: String,
    pub passed: bool,
    pub score: f64,
    pub execution_time_ms: i64,
    pub steps: i32,
    pub cost_usd: f64,
    pub error: Option<String>,
    pub execution_log: Option<String>,
    pub trajectory: Option<serde_json::Value>,
    pub started_at: i64,
    pub completed_at: i64,
    // Verbose logging fields for debugging agent failures
    pub agent_stderr: Option<String>,
    pub agent_stdout: Option<String>,
    pub test_output: Option<String>,
    pub steps_executed: Option<i32>,
    /// For global failures (before tasks run): "download", "container_create", "binary_exec", etc.
    pub failure_stage: Option<String>,
}

/// Summary of task logs for verification
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct TaskLogSummary {
    pub total_tasks: i32,
    pub completed_tasks: i32,
    pub passed_tasks: i32,
    pub failed_tasks: i32,
    pub total_score: f64,
    pub total_cost_usd: f64,
    pub total_execution_time_ms: i64,
}

/// Evaluation progress for resuming interrupted evaluations
#[derive(Debug, Clone, Default)]
pub struct EvaluationProgress {
    pub total_tasks: i32,
    pub completed_tasks: Vec<crate::api::CompletedTaskInfo>,
    pub remaining_task_ids: Vec<String>,
    pub partial_score: f64,
}

/// Progress of a validator's evaluation of an agent
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ValidatorEvaluationProgress {
    pub validator_hotkey: String,
    pub status: String, // "pending", "in_progress", "completed"
    pub total_tasks: i32,
    pub completed_tasks: i32,
    pub passed_tasks: i32,
    pub failed_tasks: i32,
    pub remaining_task_ids: Vec<String>,
    pub current_task: Option<String>,
    pub started_at: Option<i64>,
    pub last_update: Option<i64>,
}

/// LLM usage record for tracking API calls during evaluation
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LlmUsageRecord {
    pub agent_hash: String,
    pub validator_hotkey: String,
    pub task_id: Option<String>,
    pub model: String,
    pub prompt_tokens: i32,
    pub completion_tokens: i32,
    pub cost_usd: f64,
}

/// Stale validator assignment (no task started within timeout)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StaleAssignment {
    pub agent_hash: String,
    pub validator_hotkey: String,
    pub assigned_at: i64,
    pub reassignment_count: i32,
}

/// Reassignment history record for audit logging
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ReassignmentHistory {
    pub id: String,
    pub agent_hash: String,
    pub old_validator_hotkey: String,
    pub new_validator_hotkey: String,
    pub reassignment_number: i32,
    pub reason: String,
    pub created_at: i64,
}

/// Database query timeout in seconds
const DB_QUERY_TIMEOUT_SECS: u64 = 30;

/// Database pool configuration
const DB_POOL_MAX_SIZE: usize = 20;
const DB_POOL_MIN_IDLE: usize = 2;

#[derive(Clone)]
pub struct PgStorage {
    pool: Pool,
}

impl PgStorage {
    /// Create storage from DATABASE_URL with production-ready pool configuration
    pub async fn new(database_url: &str) -> Result<Self> {
        use deadpool_postgres::{ManagerConfig, PoolConfig, RecyclingMethod};
        use std::time::Duration;

        let mut config = Config::new();
        config.url = Some(database_url.to_string());

        // Configure connection manager with statement timeout
        config.manager = Some(ManagerConfig {
            recycling_method: RecyclingMethod::Fast,
        });

        // Configure pool size and timeouts
        config.pool = Some(PoolConfig {
            max_size: DB_POOL_MAX_SIZE,
            timeouts: deadpool_postgres::Timeouts {
                wait: Some(Duration::from_secs(DB_QUERY_TIMEOUT_SECS)),
                create: Some(Duration::from_secs(10)),
                recycle: Some(Duration::from_secs(30)),
            },
            ..Default::default()
        });

        let pool = config.create_pool(Some(Runtime::Tokio1), NoTls)?;

        // Test connection and set statement timeout
        let client = pool.get().await?;

        // Set default statement timeout for all queries (30 seconds)
        client
            .execute(
                &format!("SET statement_timeout = '{}s'", DB_QUERY_TIMEOUT_SECS),
                &[],
            )
            .await?;

        info!(
            "Connected to PostgreSQL (pool_size: {}, query_timeout: {}s)",
            DB_POOL_MAX_SIZE, DB_QUERY_TIMEOUT_SECS
        );

        // Run migrations from embedded migrations
        migrations::run_embedded_migrations(&client).await?;
        info!("Database migrations applied");

        Ok(Self { pool })
    }

    /// Get a client with statement timeout configured
    async fn get_client(&self) -> Result<deadpool_postgres::Client> {
        let client = self.pool.get().await?;
        // Ensure statement timeout is set on each connection
        client
            .execute(
                &format!("SET statement_timeout = '{}s'", DB_QUERY_TIMEOUT_SECS),
                &[],
            )
            .await?;
        Ok(client)
    }

    /// Create storage from DATABASE_URL environment variable
    pub async fn from_env() -> Result<Self> {
        let url =
            std::env::var("DATABASE_URL").map_err(|_| anyhow::anyhow!("DATABASE_URL not set"))?;
        Self::new(&url).await
    }

    // ========================================================================
    // API KEY ENCRYPTION
    // ========================================================================

    /// Encryption key for API keys (derived from server secret)
    /// In production, this should come from a secure key management system
    fn get_api_key_encryption_key() -> [u8; 32] {
        use sha2::{Digest, Sha256};

        // Use SERVER_SECRET env var if set, otherwise derive from DATABASE_URL
        let secret = std::env::var("SERVER_SECRET")
            .or_else(|_| std::env::var("DATABASE_URL"))
            .unwrap_or_else(|_| "default-insecure-key-change-in-production".to_string());

        let mut hasher = Sha256::new();
        hasher.update(b"term-challenge-api-key-encryption:");
        hasher.update(secret.as_bytes());
        let result = hasher.finalize();

        let mut key = [0u8; 32];
        key.copy_from_slice(&result);
        key
    }

    /// Encrypt an API key for storage
    fn encrypt_api_key(api_key: &str) -> Result<String> {
        use chacha20poly1305::{aead::Aead, ChaCha20Poly1305, KeyInit};
        use rand::RngCore;

        let key = Self::get_api_key_encryption_key();
        let cipher = ChaCha20Poly1305::new_from_slice(&key)
            .map_err(|e| anyhow::anyhow!("Failed to create cipher: {}", e))?;

        // Generate random nonce
        let mut nonce_bytes = [0u8; 12];
        rand::thread_rng().fill_bytes(&mut nonce_bytes);
        let nonce = chacha20poly1305::Nonce::from_slice(&nonce_bytes);

        // Encrypt
        let ciphertext = cipher
            .encrypt(nonce, api_key.as_bytes())
            .map_err(|e| anyhow::anyhow!("Encryption failed: {}", e))?;

        // Return as nonce:ciphertext in hex
        Ok(format!(
            "{}:{}",
            hex::encode(nonce_bytes),
            hex::encode(ciphertext)
        ))
    }

    /// Decrypt an API key from storage
    fn decrypt_api_key(encrypted: &str) -> Result<String> {
        use chacha20poly1305::{aead::Aead, ChaCha20Poly1305, KeyInit};

        let parts: Vec<&str> = encrypted.split(':').collect();
        if parts.len() != 2 {
            return Err(anyhow::anyhow!("Invalid encrypted API key format"));
        }

        let nonce_bytes =
            hex::decode(parts[0]).map_err(|e| anyhow::anyhow!("Invalid nonce: {}", e))?;
        let ciphertext =
            hex::decode(parts[1]).map_err(|e| anyhow::anyhow!("Invalid ciphertext: {}", e))?;

        if nonce_bytes.len() != 12 {
            return Err(anyhow::anyhow!("Invalid nonce length"));
        }

        let key = Self::get_api_key_encryption_key();
        let cipher = ChaCha20Poly1305::new_from_slice(&key)
            .map_err(|e| anyhow::anyhow!("Failed to create cipher: {}", e))?;

        let nonce = chacha20poly1305::Nonce::from_slice(&nonce_bytes);
        let plaintext = cipher
            .decrypt(nonce, ciphertext.as_ref())
            .map_err(|e| anyhow::anyhow!("Decryption failed: {}", e))?;

        String::from_utf8(plaintext)
            .map_err(|e| anyhow::anyhow!("Invalid UTF-8 in decrypted API key: {}", e))
    }

    // ========================================================================
    // EVALUATIONS
    // ========================================================================

    /// Store an evaluation result
    pub async fn store_evaluation(&self, eval: &EvaluationRecord) -> Result<()> {
        let client = self.pool.get().await?;
        // Column is REAL (f32), so cast f64 to f32 for PostgreSQL type matching
        let cost_f32 = eval.total_cost_usd as f32;
        client.execute(
            "INSERT INTO evaluations (id, submission_id, agent_hash, miner_hotkey, score, tasks_passed, tasks_total, tasks_failed, total_cost_usd, execution_time_ms, task_results)
             VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11)
             ON CONFLICT(id) DO UPDATE SET
                score = EXCLUDED.score,
                tasks_passed = EXCLUDED.tasks_passed,
                tasks_total = EXCLUDED.tasks_total,
                tasks_failed = EXCLUDED.tasks_failed,
                total_cost_usd = EXCLUDED.total_cost_usd,
                execution_time_ms = EXCLUDED.execution_time_ms,
                task_results = EXCLUDED.task_results",
            &[
                &eval.id, &eval.submission_id, &eval.agent_hash, &eval.miner_hotkey,
                &eval.score, &eval.tasks_passed, &eval.tasks_total, &eval.tasks_failed,
                &cost_f32, &eval.execution_time_ms, &eval.task_results,
            ],
        ).await?;

        // Update leaderboard
        self.update_leaderboard(
            &eval.agent_hash,
            &eval.miner_hotkey,
            None, // No name from evaluation record
            eval.score,
            eval.total_cost_usd,
        )
        .await?;

        debug!(
            "Stored evaluation {} for agent {}",
            eval.id, eval.agent_hash
        );
        Ok(())
    }

    /// Get evaluations for an agent
    pub async fn get_evaluations(&self, agent_hash: &str) -> Result<Vec<EvaluationRecord>> {
        let client = self.pool.get().await?;
        let rows = client.query(
            "SELECT id, submission_id, agent_hash, miner_hotkey, score::FLOAT8, tasks_passed, tasks_total, tasks_failed, total_cost_usd::FLOAT8, execution_time_ms, task_results, EXTRACT(EPOCH FROM created_at)::BIGINT
             FROM evaluations WHERE agent_hash = $1 ORDER BY created_at DESC",
            &[&agent_hash],
        ).await?;

        Ok(rows
            .iter()
            .map(|r| EvaluationRecord {
                id: r.get(0),
                submission_id: r.get(1),
                agent_hash: r.get(2),
                miner_hotkey: r.get(3),
                score: r.get(4),
                tasks_passed: r.get(5),
                tasks_total: r.get(6),
                tasks_failed: r.get(7),
                total_cost_usd: r.get(8),
                execution_time_ms: r.get(9),
                task_results: r.get(10),
                created_at: r.get(11),
            })
            .collect())
    }

    // ========================================================================
    // LEADERBOARD
    // ========================================================================

    /// Update leaderboard entry (public for auto-evaluation)
    /// Uses transaction to ensure atomic upsert + rank update
    pub async fn update_leaderboard(
        &self,
        agent_hash: &str,
        miner_hotkey: &str,
        name: Option<&str>,
        score: f64,
        cost: f64,
    ) -> Result<()> {
        let mut client = self.pool.get().await?;
        let transaction = client.transaction().await?;

        // Cast f64 to f32 for PostgreSQL REAL columns
        let score_f32 = score as f32;
        let cost_f32 = cost as f32;

        // Upsert leaderboard entry
        transaction.execute(
            "INSERT INTO leaderboard (agent_hash, miner_hotkey, name, best_score, avg_score, evaluation_count, total_cost_usd)
             VALUES ($1, $2, $3, $4, $4, 1, $5)
             ON CONFLICT(agent_hash) DO UPDATE SET
                name = COALESCE(EXCLUDED.name, leaderboard.name),
                best_score = GREATEST(leaderboard.best_score, EXCLUDED.best_score),
                avg_score = (leaderboard.avg_score * leaderboard.evaluation_count + EXCLUDED.avg_score) / (leaderboard.evaluation_count + 1),
                evaluation_count = leaderboard.evaluation_count + 1,
                total_cost_usd = leaderboard.total_cost_usd + EXCLUDED.total_cost_usd,
                last_updated = NOW()",
            &[&agent_hash, &miner_hotkey, &name, &score_f32, &cost_f32],
        ).await?;

        // Update ranks (atomically with the upsert)
        transaction.execute(
            "UPDATE leaderboard SET rank = subq.new_rank
             FROM (SELECT agent_hash, ROW_NUMBER() OVER (ORDER BY best_score DESC) as new_rank FROM leaderboard) subq
             WHERE leaderboard.agent_hash = subq.agent_hash",
            &[],
        ).await?;

        transaction.commit().await?;

        info!(
            "Updated leaderboard for agent {}: score={:.2}%",
            &agent_hash[..16.min(agent_hash.len())],
            score * 100.0
        );

        Ok(())
    }

    /// Get leaderboard
    pub async fn get_leaderboard(&self, limit: i64) -> Result<Vec<LeaderboardEntry>> {
        let client = self.pool.get().await?;
        let rows = client.query(
            "SELECT agent_hash, miner_hotkey, name, best_score::FLOAT8, avg_score::FLOAT8, evaluation_count, total_cost_usd::FLOAT8, rank
             FROM leaderboard ORDER BY rank ASC NULLS LAST LIMIT $1",
            &[&limit],
        ).await?;

        Ok(rows
            .iter()
            .map(|r| LeaderboardEntry {
                agent_hash: r.get(0),
                miner_hotkey: r.get(1),
                name: r.get(2),
                best_score: r.get(3),
                avg_score: r.get(4),
                evaluation_count: r.get(5),
                total_cost_usd: r.get(6),
                rank: r.get(7),
            })
            .collect())
    }

    /// Get leaderboard entry for an agent
    pub async fn get_leaderboard_entry(
        &self,
        agent_hash: &str,
    ) -> Result<Option<LeaderboardEntry>> {
        let client = self.pool.get().await?;
        let row = client.query_opt(
            "SELECT agent_hash, miner_hotkey, name, best_score::FLOAT8, avg_score::FLOAT8, evaluation_count, total_cost_usd::FLOAT8, rank
             FROM leaderboard WHERE agent_hash = $1",
            &[&agent_hash],
        ).await?;

        Ok(row.map(|r| LeaderboardEntry {
            agent_hash: r.get(0),
            miner_hotkey: r.get(1),
            name: r.get(2),
            best_score: r.get(3),
            avg_score: r.get(4),
            evaluation_count: r.get(5),
            total_cost_usd: r.get(6),
            rank: r.get(7),
        }))
    }

    // ========================================================================
    // SUBMISSIONS (SENSITIVE - source code access controlled)
    // ========================================================================

    /// Check if miner can submit (rate limit: 1 agent per 3.6 hours)
    pub async fn can_miner_submit(&self, miner_hotkey: &str) -> Result<(bool, Option<String>)> {
        let client = self.pool.get().await?;

        let row = client
            .query_opt(
                "SELECT EXTRACT(EPOCH FROM (NOW() - last_submission_at))::BIGINT as secs_since 
             FROM miner_submission_history WHERE miner_hotkey = $1",
                &[&miner_hotkey],
            )
            .await?;

        if let Some(row) = row {
            let secs_since: Option<i64> = row.get(0);

            if let Some(secs_since) = secs_since {
                if secs_since < SUBMISSION_COOLDOWN_SECS {
                    let wait_secs = SUBMISSION_COOLDOWN_SECS - secs_since;
                    let wait_mins = wait_secs / 60;
                    let cooldown_hours = SUBMISSION_COOLDOWN_SECS / 3600;
                    return Ok((false, Some(format!(
                        "Rate limit: must wait {} more minutes before submitting again (1 submission per {} hours)",
                        wait_mins, cooldown_hours
                    ))));
                }
            }
        }

        Ok((true, None))
    }

    /// Get next version number for an agent name
    pub async fn get_next_version(&self, miner_hotkey: &str, name: Option<&str>) -> Result<i32> {
        let client = self.pool.get().await?;

        let row = match name {
            Some(n) => {
                client.query_opt(
                    "SELECT COALESCE(MAX(version), 0) + 1 FROM submissions WHERE miner_hotkey = $1 AND name = $2",
                    &[&miner_hotkey, &n],
                ).await?
            }
            None => {
                // No name provided, start at version 1
                return Ok(1);
            }
        };

        Ok(row.map(|r| r.get::<_, i32>(0)).unwrap_or(1))
    }

    /// Check if agent name is taken by another miner
    pub async fn is_name_taken_by_other(&self, name: &str, miner_hotkey: &str) -> Result<bool> {
        let client = self.pool.get().await?;

        let row = client
            .query_opt(
                "SELECT 1 FROM submissions WHERE name = $1 AND miner_hotkey != $2 LIMIT 1",
                &[&name, &miner_hotkey],
            )
            .await?;

        Ok(row.is_some())
    }

    /// Create a new submission
    pub async fn create_submission(&self, submission: &Submission) -> Result<()> {
        debug!(
            "Creating submission: id={}, agent_hash={}, miner={}, version={}",
            submission.id, submission.agent_hash, submission.miner_hotkey, submission.version
        );

        let client = self.pool.get().await.map_err(|e| {
            tracing::error!("Failed to get DB connection: {:?}", e);
            anyhow::anyhow!("db connection error: {}", e)
        })?;

        // Validate cost limit
        let cost_limit = submission.cost_limit_usd.clamp(0.0, MAX_COST_LIMIT_USD);

        // Encrypt API key if present
        let encrypted_api_key: Option<String> = match &submission.api_key {
            Some(key) if !key.is_empty() => match Self::encrypt_api_key(key) {
                Ok(encrypted) => Some(encrypted),
                Err(e) => {
                    warn!("Failed to encrypt API key: {:?}", e);
                    None
                }
            },
            _ => None,
        };

        debug!("Inserting into submissions table...");
        client.execute(
            "INSERT INTO submissions (id, agent_hash, miner_hotkey, source_code, source_hash, name, version, epoch, status, api_key, api_provider, cost_limit_usd, total_cost_usd)
             VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13)
             ON CONFLICT(agent_hash) DO UPDATE SET
                source_code = EXCLUDED.source_code,
                source_hash = EXCLUDED.source_hash,
                name = EXCLUDED.name,
                version = EXCLUDED.version,
                status = EXCLUDED.status,
                api_key = EXCLUDED.api_key,
                api_provider = EXCLUDED.api_provider,
                cost_limit_usd = EXCLUDED.cost_limit_usd",
            &[
                &submission.id, &submission.agent_hash, &submission.miner_hotkey,
                &submission.source_code, &submission.source_hash, &submission.name,
                &submission.version, &submission.epoch, &submission.status,
                &encrypted_api_key, &submission.api_provider, &(cost_limit as f32),
                &(submission.total_cost_usd as f32),
            ],
        ).await.map_err(|e| {
            tracing::error!("Failed to insert submission: {:?}", e);
            anyhow::anyhow!("db insert error: {}", e)
        })?;

        // Update miner submission history for rate limiting
        client.execute(
            "INSERT INTO miner_submission_history (miner_hotkey, last_submission_epoch, total_submissions)
             VALUES ($1, $2, 1)
             ON CONFLICT(miner_hotkey) DO UPDATE SET
                last_submission_epoch = EXCLUDED.last_submission_epoch,
                last_submission_at = NOW(),
                total_submissions = miner_submission_history.total_submissions + 1",
            &[&submission.miner_hotkey, &submission.epoch],
        ).await.map_err(|e| {
            warn!("Failed to update miner submission history: {:?}", e);
            // Don't fail the submission for this
            e
        }).ok();

        info!(
            "Created submission {} for agent {} (v{}, cost_limit: ${:.2})",
            submission.id, submission.agent_hash, submission.version, cost_limit
        );
        Ok(())
    }

    /// Update accumulated cost for a submission
    pub async fn add_submission_cost(&self, agent_hash: &str, cost_usd: f64) -> Result<f64> {
        let client = self.pool.get().await?;

        // Column is REAL (f32), so cast f64 to f32 for PostgreSQL type matching
        let cost_f32 = cost_usd as f32;
        let row = client
            .query_one(
                "UPDATE submissions SET total_cost_usd = total_cost_usd + $1 
             WHERE agent_hash = $2 
             RETURNING total_cost_usd::FLOAT8, cost_limit_usd::FLOAT8",
                &[&cost_f32, &agent_hash],
            )
            .await?;

        // Cast to FLOAT8 in SQL, read as f64 in Rust
        let total_cost: f64 = row.get(0);
        let cost_limit: f64 = row.get(1);

        if total_cost > cost_limit {
            warn!(
                "Agent {} exceeded cost limit: ${:.2} > ${:.2}",
                &agent_hash[..16.min(agent_hash.len())],
                total_cost,
                cost_limit
            );
        }

        Ok(total_cost)
    }

    /// Check if submission is within cost limit
    pub async fn check_cost_limit(&self, agent_hash: &str) -> Result<(bool, f64, f64)> {
        let client = self.pool.get().await?;

        let row = client
            .query_opt(
                "SELECT total_cost_usd::FLOAT8, cost_limit_usd::FLOAT8 FROM submissions WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await?;

        match row {
            Some(r) => {
                let total: f64 = r.get(0);
                let limit: f64 = r.get(1);
                Ok((total < limit, total, limit))
            }
            None => Ok((false, 0.0, 0.0)),
        }
    }

    /// Get current and limit costs for a submission
    /// Returns (total_cost_usd, cost_limit_usd)
    pub async fn get_submission_costs(&self, agent_hash: &str) -> Result<(f64, f64)> {
        let client = self.pool.get().await?;

        let row = client
            .query_opt(
                "SELECT COALESCE(total_cost_usd, 0.0)::FLOAT8, COALESCE(cost_limit_usd, 80.0)::FLOAT8 
                 FROM submissions WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await?;

        match row {
            Some(r) => {
                let total: f64 = r.get(0);
                let limit: f64 = r.get(1);
                Ok((total, limit))
            }
            None => Err(anyhow::anyhow!("Submission not found: {}", agent_hash)),
        }
    }

    /// Record an LLM usage entry for tracking and auditing
    pub async fn record_llm_usage(&self, record: LlmUsageRecord) -> Result<()> {
        let client = self.pool.get().await?;

        client
            .execute(
                "INSERT INTO llm_usage (agent_hash, validator_hotkey, task_id, model, prompt_tokens, completion_tokens, cost_usd)
                 VALUES ($1, $2, $3, $4, $5, $6, $7)",
                &[
                    &record.agent_hash,
                    &record.validator_hotkey,
                    &record.task_id,
                    &record.model,
                    &record.prompt_tokens,
                    &record.completion_tokens,
                    &(record.cost_usd as f32),
                ],
            )
            .await?;

        debug!(
            "Recorded LLM usage: agent={}, model={}, tokens={}, cost=${:.4}",
            &record.agent_hash[..12.min(record.agent_hash.len())],
            record.model,
            record.prompt_tokens + record.completion_tokens,
            record.cost_usd
        );

        Ok(())
    }

    /// Get total LLM usage cost for an agent
    pub async fn get_agent_llm_usage(&self, agent_hash: &str) -> Result<f64> {
        let client = self.pool.get().await?;

        let row = client
            .query_one(
                "SELECT COALESCE(SUM(cost_usd), 0.0)::FLOAT8 FROM llm_usage WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await?;

        Ok(row.get(0))
    }

    /// Get API key for a submission (for inference bridge)
    /// The API key is decrypted server-side - validators never see the raw key
    /// They call the server's bridge endpoint which uses this internally
    pub async fn get_submission_api_key(
        &self,
        agent_hash: &str,
    ) -> Result<Option<(String, String)>> {
        let client = self.pool.get().await?;

        let row = client.query_opt(
            "SELECT api_key, COALESCE(api_provider, 'openrouter') FROM submissions WHERE agent_hash = $1",
            &[&agent_hash],
        ).await?;

        match row {
            Some(r) => {
                let encrypted_key: Option<String> = r.get(0);
                let provider: String = r.get(1);

                match encrypted_key {
                    Some(encrypted) if !encrypted.is_empty() => {
                        // Try to decrypt - if it fails, key might be in old plaintext format
                        match Self::decrypt_api_key(&encrypted) {
                            Ok(decrypted) => Ok(Some((decrypted, provider))),
                            Err(e) => {
                                // Check if it looks like a raw API key (not encrypted)
                                // Raw keys don't contain ':' which our encrypted format uses
                                if !encrypted.contains(':') {
                                    warn!(
                                        "API key for {} appears to be unencrypted (legacy), using as-is",
                                        &agent_hash[..16.min(agent_hash.len())]
                                    );
                                    Ok(Some((encrypted, provider)))
                                } else {
                                    warn!(
                                        "Failed to decrypt API key for {}: {:?}",
                                        &agent_hash[..16.min(agent_hash.len())],
                                        e
                                    );
                                    Ok(None)
                                }
                            }
                        }
                    }
                    _ => Ok(None),
                }
            }
            None => Ok(None),
        }
    }

    /// Queue a submission for evaluation by all validators
    /// Call this after creating submission, with validator count from platform-server
    pub async fn queue_submission_for_evaluation(
        &self,
        submission_id: &str,
        agent_hash: &str,
        miner_hotkey: &str,
        total_validators: i32,
    ) -> Result<String> {
        debug!(
            "Queueing submission {} for {} validators",
            agent_hash, total_validators
        );

        self.queue_for_all_validators(submission_id, agent_hash, miner_hotkey, total_validators)
            .await
            .map_err(|e| {
                tracing::error!("Failed to queue evaluation: {:?}", e);
                anyhow::anyhow!("db queue error: {}", e)
            })
    }

    /// Get submission by agent hash (includes source code - SENSITIVE)
    pub async fn get_submission(&self, agent_hash: &str) -> Result<Option<Submission>> {
        let client = self.pool.get().await?;
        let row = client
            .query_opt(
                "SELECT id, agent_hash, miner_hotkey, source_code, source_hash, name, 
                    COALESCE(version, 1), epoch, status, api_key, 
                    COALESCE(api_provider, 'openrouter'), COALESCE(cost_limit_usd, 80.0)::FLOAT8, 
                    COALESCE(total_cost_usd, 0.0)::FLOAT8, EXTRACT(EPOCH FROM created_at)::BIGINT
             FROM submissions WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await?;

        Ok(row.map(|r| Submission {
            id: r.get(0),
            agent_hash: r.get(1),
            miner_hotkey: r.get(2),
            source_code: r.get(3),
            source_hash: r.get(4),
            name: r.get(5),
            version: r.get(6),
            epoch: r.get(7),
            status: r.get(8),
            api_key: r.get(9),
            api_provider: r.get(10),
            cost_limit_usd: r.get(11),
            total_cost_usd: r.get(12),
            created_at: r.get(13),
            // New fields - defaults for backwards compatibility
            binary: None,
            binary_size: 0,
            compile_status: "pending".to_string(),
            compile_error: None,
            compile_time_ms: 0,
            llm_approved: false,
            flagged: false,
            flag_reason: None,
        }))
    }

    /// Get submission info by agent hash (NO source code - safe for listings)
    pub async fn get_submission_info(&self, agent_hash: &str) -> Result<Option<SubmissionInfo>> {
        let client = self.pool.get().await?;
        let row = client
            .query_opt(
                "SELECT id, agent_hash, miner_hotkey, name, COALESCE(version, 1), epoch, status, 
                    COALESCE(cost_limit_usd, 80.0)::FLOAT8, COALESCE(total_cost_usd, 0.0)::FLOAT8, 
                    EXTRACT(EPOCH FROM created_at)::BIGINT
             FROM submissions WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await?;

        Ok(row.map(|r| SubmissionInfo {
            id: r.get(0),
            agent_hash: r.get(1),
            miner_hotkey: r.get(2),
            name: r.get(3),
            version: r.get(4),
            epoch: r.get(5),
            status: r.get(6),
            cost_limit_usd: r.get(7),
            total_cost_usd: r.get(8),
            created_at: r.get(9),
        }))
    }

    /// Get all submissions for a miner (NO source code)
    pub async fn get_miner_submissions(&self, miner_hotkey: &str) -> Result<Vec<SubmissionInfo>> {
        let client = self.pool.get().await?;
        let rows = client
            .query(
                "SELECT id, agent_hash, miner_hotkey, name, COALESCE(version, 1), epoch, status, 
                    COALESCE(cost_limit_usd, 80.0)::FLOAT8, COALESCE(total_cost_usd, 0.0)::FLOAT8, 
                    EXTRACT(EPOCH FROM created_at)::BIGINT
             FROM submissions WHERE miner_hotkey = $1 ORDER BY created_at DESC",
                &[&miner_hotkey],
            )
            .await?;

        Ok(rows
            .iter()
            .map(|r| SubmissionInfo {
                id: r.get(0),
                agent_hash: r.get(1),
                miner_hotkey: r.get(2),
                name: r.get(3),
                version: r.get(4),
                epoch: r.get(5),
                status: r.get(6),
                cost_limit_usd: r.get(7),
                total_cost_usd: r.get(8),
                created_at: r.get(9),
            })
            .collect())
    }

    /// Update submission status
    pub async fn update_submission_status(&self, agent_hash: &str, status: &str) -> Result<()> {
        let client = self.pool.get().await?;
        client
            .execute(
                "UPDATE submissions SET status = $1 WHERE agent_hash = $2",
                &[&status, &agent_hash],
            )
            .await?;
        Ok(())
    }

    /// Check if agent hash exists
    pub async fn submission_exists(&self, agent_hash: &str) -> Result<bool> {
        let client = self.pool.get().await?;
        let row = client
            .query_opt(
                "SELECT 1 FROM submissions WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await?;
        Ok(row.is_some())
    }

    // ========================================================================
    // DISTRIBUTED EVALUATION SYSTEM
    // Each agent is evaluated by exactly 3 validators (MAX_VALIDATORS_PER_AGENT).
    // 6h window for evaluation completion.
    // ========================================================================

    /// Queue an agent for evaluation by up to MAX_VALIDATORS_PER_AGENT validators
    /// Also assigns specific validators from the whitelist
    pub async fn queue_for_all_validators(
        &self,
        submission_id: &str,
        agent_hash: &str,
        miner_hotkey: &str,
        total_validators: i32,
    ) -> Result<String> {
        let client = self.pool.get().await?;
        let id = uuid::Uuid::new_v4().to_string();
        let epoch = self.get_current_epoch().await.unwrap_or(0);

        // Limit to MAX_VALIDATORS_PER_AGENT validators
        let actual_validators = total_validators.min(MAX_VALIDATORS_PER_AGENT);

        client.execute(
            "INSERT INTO pending_evaluations 
             (id, submission_id, agent_hash, miner_hotkey, epoch, status, total_validators, validators_completed)
             VALUES ($1, $2, $3, $4, $5, 'pending', $6, 0)
             ON CONFLICT(agent_hash) DO UPDATE SET
                total_validators = EXCLUDED.total_validators,
                status = CASE WHEN pending_evaluations.status = 'completed' THEN pending_evaluations.status ELSE 'pending' END",
            &[&id, &submission_id, &agent_hash, &miner_hotkey, &epoch, &actual_validators],
        ).await?;

        info!(
            "Queued agent {} for evaluation by {} validators (max {})",
            agent_hash, actual_validators, MAX_VALIDATORS_PER_AGENT
        );
        Ok(id)
    }

    /// Assign specific validators to evaluate an agent
    /// Called after queue_for_all_validators with selected validator hotkeys
    pub async fn assign_validators_to_agent(
        &self,
        agent_hash: &str,
        validator_hotkeys: &[String],
    ) -> Result<usize> {
        let client = self.pool.get().await?;
        let mut assigned = 0;

        for hotkey in validator_hotkeys
            .iter()
            .take(MAX_VALIDATORS_PER_AGENT as usize)
        {
            let id = uuid::Uuid::new_v4().to_string();
            let result = client
                .execute(
                    "INSERT INTO validator_assignments (id, agent_hash, validator_hotkey, status, assigned_at)
                 VALUES ($1, $2, $3, 'pending', NOW())
                 ON CONFLICT(agent_hash, validator_hotkey) DO NOTHING",
                    &[&id, &agent_hash, &hotkey],
                )
                .await?;

            if result > 0 {
                assigned += 1;
            }
        }

        info!(
            "Assigned {} validators to agent {}",
            assigned,
            &agent_hash[..16.min(agent_hash.len())]
        );
        Ok(assigned)
    }

    /// Clear all validator assignments for an agent
    /// Used before reassigning validators (e.g., during recompilation)
    pub async fn clear_validator_assignments(&self, agent_hash: &str) -> Result<usize> {
        let client = self.pool.get().await?;
        let result = client
            .execute(
                "DELETE FROM validator_assignments WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await?;

        if result > 0 {
            debug!(
                "Cleared {} validator assignments for agent {}",
                result,
                &agent_hash[..16.min(agent_hash.len())]
            );
        }
        Ok(result as usize)
    }

    /// Clear all evaluation task assignments for an agent
    /// Used before reassigning tasks (e.g., during recompilation)
    pub async fn clear_evaluation_tasks(&self, agent_hash: &str) -> Result<usize> {
        let client = self.pool.get().await?;
        let result = client
            .execute(
                "DELETE FROM evaluation_tasks WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await?;

        if result > 0 {
            debug!(
                "Cleared {} evaluation tasks for agent {}",
                result,
                &agent_hash[..16.min(agent_hash.len())]
            );
        }
        Ok(result as usize)
    }

    /// Check if a validator is assigned to evaluate an agent
    pub async fn is_validator_assigned(
        &self,
        agent_hash: &str,
        validator_hotkey: &str,
    ) -> Result<bool> {
        let client = self.pool.get().await?;
        let row = client.query_opt(
            "SELECT 1 FROM validator_assignments WHERE agent_hash = $1 AND validator_hotkey = $2",
            &[&agent_hash, &validator_hotkey],
        ).await?;
        Ok(row.is_some())
    }

    /// Get validators assigned to an agent
    pub async fn get_assigned_validators(&self, agent_hash: &str) -> Result<Vec<String>> {
        let client = self.pool.get().await?;
        let rows = client
            .query(
                "SELECT validator_hotkey FROM validator_assignments WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await?;
        Ok(rows.iter().map(|r| r.get(0)).collect())
    }

    /// Get stale validator assignments (no task_logs after timeout)
    /// Returns assignments where:
    /// 1. No task_logs exist for this agent+validator combination
    /// 2. Assignment is older than timeout_minutes
    /// 3. Agent has compile_status = 'success'
    /// 4. Reassignment count is less than max_reassignments
    pub async fn get_stale_assignments(
        &self,
        timeout_minutes: i64,
        max_reassignments: i32,
    ) -> Result<Vec<StaleAssignment>> {
        let client = self.pool.get().await?;

        let rows = client
            .query(
                "SELECT 
                    va.agent_hash,
                    va.validator_hotkey,
                    EXTRACT(EPOCH FROM va.assigned_at)::BIGINT as assigned_at,
                    COALESCE(s.reassignment_count, 0) as reassignment_count
                FROM validator_assignments va
                JOIN submissions s ON s.agent_hash = va.agent_hash
                LEFT JOIN task_logs tl ON tl.agent_hash = va.agent_hash 
                                      AND tl.validator_hotkey = va.validator_hotkey
                WHERE tl.id IS NULL
                  AND va.assigned_at < NOW() - ($1 || ' minutes')::INTERVAL
                  AND s.compile_status = 'success'
                  AND COALESCE(s.reassignment_count, 0) < $2",
                &[&timeout_minutes.to_string(), &max_reassignments],
            )
            .await?;

        let assignments = rows
            .iter()
            .map(|r| StaleAssignment {
                agent_hash: r.get(0),
                validator_hotkey: r.get(1),
                assigned_at: r.get(2),
                reassignment_count: r.get(3),
            })
            .collect();

        Ok(assignments)
    }

    /// Reassign an agent from one validator to another
    /// 1. Deletes old assignment
    /// 2. Creates new assignment
    /// 3. Increments reassignment_count in submissions
    /// 4. Records the reassignment in history table
    pub async fn reassign_validator(
        &self,
        agent_hash: &str,
        old_validator: &str,
        new_validator: &str,
        reason: &str,
    ) -> Result<()> {
        let client = self.pool.get().await?;

        // Start transaction
        let transaction_id = uuid::Uuid::new_v4().to_string();

        // 1. Delete old assignment
        client
            .execute(
                "DELETE FROM validator_assignments WHERE agent_hash = $1 AND validator_hotkey = $2",
                &[&agent_hash, &old_validator],
            )
            .await?;

        // 2. Create new assignment
        let new_id = uuid::Uuid::new_v4().to_string();
        client
            .execute(
                "INSERT INTO validator_assignments (id, agent_hash, validator_hotkey, status, assigned_at)
                 VALUES ($1, $2, $3, 'pending', NOW())
                 ON CONFLICT(agent_hash, validator_hotkey) DO NOTHING",
                &[&new_id, &agent_hash, &new_validator],
            )
            .await?;

        // 3. Increment reassignment_count and get current value
        let row = client
            .query_one(
                "UPDATE submissions 
                 SET reassignment_count = COALESCE(reassignment_count, 0) + 1 
                 WHERE agent_hash = $1
                 RETURNING reassignment_count",
                &[&agent_hash],
            )
            .await?;
        let reassignment_number: i32 = row.get(0);

        // 4. Record in history table
        let history_id = uuid::Uuid::new_v4().to_string();
        client
            .execute(
                "INSERT INTO reassignment_history 
                 (id, agent_hash, old_validator_hotkey, new_validator_hotkey, reassignment_number, reason)
                 VALUES ($1, $2, $3, $4, $5, $6)",
                &[
                    &history_id,
                    &agent_hash,
                    &old_validator,
                    &new_validator,
                    &reassignment_number,
                    &reason,
                ],
            )
            .await?;

        info!(
            "Reassigned agent {} from {} to {} (reassignment #{}), tx={}",
            &agent_hash[..16.min(agent_hash.len())],
            &old_validator[..16.min(old_validator.len())],
            &new_validator[..16.min(new_validator.len())],
            reassignment_number,
            &transaction_id[..8]
        );

        Ok(())
    }

    /// Get validators already assigned to an agent (for exclusion during reassignment)
    pub async fn get_validators_assigned_to_agent(&self, agent_hash: &str) -> Result<Vec<String>> {
        let client = self.pool.get().await?;

        // Get current assignments
        let current_rows = client
            .query(
                "SELECT validator_hotkey FROM validator_assignments WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await?;

        // Also get validators from reassignment history (they already failed)
        let history_rows = client
            .query(
                "SELECT DISTINCT old_validator_hotkey FROM reassignment_history WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await?;

        let mut validators: Vec<String> = current_rows.iter().map(|r| r.get(0)).collect();
        for row in history_rows {
            let v: String = row.get(0);
            if !validators.contains(&v) {
                validators.push(v);
            }
        }

        Ok(validators)
    }

    /// Get reassignment history for an agent
    pub async fn get_reassignment_history(
        &self,
        agent_hash: &str,
    ) -> Result<Vec<ReassignmentHistory>> {
        let client = self.pool.get().await?;

        let rows = client
            .query(
                "SELECT id, agent_hash, old_validator_hotkey, new_validator_hotkey, 
                        reassignment_number, reason, EXTRACT(EPOCH FROM created_at)::BIGINT
                 FROM reassignment_history 
                 WHERE agent_hash = $1 
                 ORDER BY created_at ASC",
                &[&agent_hash],
            )
            .await?;

        let history = rows
            .iter()
            .map(|r| ReassignmentHistory {
                id: r.get(0),
                agent_hash: r.get(1),
                old_validator_hotkey: r.get(2),
                new_validator_hotkey: r.get(3),
                reassignment_number: r.get(4),
                reason: r.get(5),
                created_at: r.get(6),
            })
            .collect();

        Ok(history)
    }

    /// Get jobs available for a specific validator
    /// Returns jobs that:
    /// 1. Are ASSIGNED to this validator (in validator_assignments table)
    /// 2. Are in 'pending' or 'evaluating' status
    /// 3. Have NOT been evaluated by this validator yet
    /// 4. Are within the 6h window (not expired)
    /// 5. Have been compiled successfully (binary available)
    pub async fn get_jobs_for_validator(
        &self,
        validator_hotkey: &str,
        limit: i64,
    ) -> Result<Vec<ClaimableJob>> {
        use base64::Engine;
        let client = self.pool.get().await?;

        // Only return jobs where binary is available (compiled successfully)
        let rows = client
            .query(
                "SELECT p.id, p.submission_id, p.agent_hash, p.miner_hotkey, s.agent_binary, s.binary_size,
                    EXTRACT(EPOCH FROM p.window_expires_at)::BIGINT
             FROM pending_evaluations p
             JOIN submissions s ON s.agent_hash = p.agent_hash
             JOIN validator_assignments va ON va.agent_hash = p.agent_hash AND va.validator_hotkey = $1
             WHERE p.status IN ('pending', 'evaluating')
               AND p.window_expires_at > NOW()
               AND s.compile_status = 'success'
               AND s.agent_binary IS NOT NULL
               AND (s.llm_approved = TRUE OR s.flagged = TRUE)
               AND NOT EXISTS (
                   SELECT 1 FROM validator_evaluations ve 
                   WHERE ve.agent_hash = p.agent_hash 
                   AND ve.validator_hotkey = $1
               )
               AND NOT EXISTS (
                   SELECT 1 FROM validator_claims vc
                   WHERE vc.agent_hash = p.agent_hash
                   AND vc.validator_hotkey = $1
                   AND vc.status = 'claimed'
               )
             ORDER BY p.created_at ASC
             LIMIT $2",
                &[&validator_hotkey, &limit],
            )
            .await?;

        // Build jobs with tasks
        let mut jobs = Vec::new();
        for r in rows.iter() {
            let agent_hash: String = r.get(2);
            let binary: Option<Vec<u8>> = r.get(4);
            let binary_size: i32 = r.get(5);

            // Skip if no binary (should not happen due to WHERE clause, but be safe)
            let binary_bytes = match binary {
                Some(b) => b,
                None => {
                    warn!(
                        "Agent {} has no binary, skipping",
                        &agent_hash[..16.min(agent_hash.len())]
                    );
                    continue;
                }
            };

            // Encode binary as base64 for JSON transport
            let binary_base64 = base64::engine::general_purpose::STANDARD.encode(&binary_bytes);

            // Get tasks assigned to this agent
            let tasks = match self.get_assigned_tasks(&agent_hash).await {
                Ok(t) => {
                    debug!(
                        "Found {} tasks for agent {}",
                        t.len(),
                        &agent_hash[..16.min(agent_hash.len())]
                    );
                    t
                }
                Err(e) => {
                    warn!(
                        "Failed to get tasks for agent {}: {:?}",
                        &agent_hash[..16.min(agent_hash.len())],
                        e
                    );
                    vec![]
                }
            };

            jobs.push(ClaimableJob {
                pending_id: r.get(0),
                submission_id: r.get(1),
                agent_hash,
                miner_hotkey: r.get(3),
                binary_base64,
                binary_size,
                window_expires_at: r.get(6),
                tasks,
            });
        }

        Ok(jobs)
    }

    /// Get validator jobs with compile status (for get_my_jobs endpoint)
    /// Returns all jobs assigned to this validator that haven't been evaluated yet,
    /// regardless of compile status. Allows validators to see pending compilations.
    pub async fn get_validator_jobs_with_status(
        &self,
        validator_hotkey: &str,
        limit: i64,
    ) -> Result<Vec<ValidatorJobInfo>> {
        let client = self.pool.get().await?;

        // Get all jobs assigned to this validator that haven't been evaluated yet
        // Join with submissions to get compile_status and submission_id
        let rows = client
            .query(
                "SELECT 
                    va.agent_hash,
                    s.miner_hotkey,
                    s.id as submission_id,
                    EXTRACT(EPOCH FROM va.assigned_at)::BIGINT,
                    s.compile_status
                FROM validator_assignments va
                JOIN submissions s ON s.agent_hash = va.agent_hash
                WHERE va.validator_hotkey = $1
                  AND va.agent_hash NOT IN (
                    SELECT agent_hash FROM validator_evaluations 
                    WHERE validator_hotkey = $1
                  )
                ORDER BY va.assigned_at ASC
                LIMIT $2",
                &[&validator_hotkey, &limit],
            )
            .await?;

        Ok(rows
            .iter()
            .map(|r| ValidatorJobInfo {
                agent_hash: r.get(0),
                miner_hotkey: r.get(1),
                submission_id: r.get(2),
                assigned_at: r.get(3),
                compile_status: r.get(4),
            })
            .collect())
    }

    /// Claim jobs for a validator (mark as in-progress)
    pub async fn claim_jobs(
        &self,
        validator_hotkey: &str,
        agent_hashes: &[String],
    ) -> Result<usize> {
        let client = self.pool.get().await?;
        let mut claimed = 0;

        for agent_hash in agent_hashes {
            let id = uuid::Uuid::new_v4().to_string();
            let result = client
                .execute(
                    "INSERT INTO validator_claims (id, agent_hash, validator_hotkey, status)
                 VALUES ($1, $2, $3, 'claimed')
                 ON CONFLICT(agent_hash, validator_hotkey) DO NOTHING",
                    &[&id, &agent_hash, &validator_hotkey],
                )
                .await?;

            if result > 0 {
                claimed += 1;
                debug!(
                    "Validator {} claimed agent {}",
                    validator_hotkey, agent_hash
                );
            }
        }

        Ok(claimed)
    }

    /// Check if validator has already evaluated an agent
    pub async fn has_validator_evaluated(
        &self,
        agent_hash: &str,
        validator_hotkey: &str,
    ) -> Result<bool> {
        let client = self.pool.get().await?;
        let row = client
            .query_opt(
                "SELECT 1 FROM validator_evaluations 
             WHERE agent_hash = $1 AND validator_hotkey = $2",
                &[&agent_hash, &validator_hotkey],
            )
            .await?;
        Ok(row.is_some())
    }

    /// Check if evaluation window has expired (6h rule)
    pub async fn is_window_expired(&self, agent_hash: &str) -> Result<bool> {
        let client = self.pool.get().await?;
        let row = client
            .query_opt(
                "SELECT 1 FROM pending_evaluations 
             WHERE agent_hash = $1 AND window_expires_at < NOW()",
                &[&agent_hash],
            )
            .await?;
        Ok(row.is_some())
    }

    /// Submit a validator's evaluation result
    /// Returns (is_late, consensus_reached, final_score)
    /// Uses transaction to ensure atomicity of all operations
    pub async fn submit_validator_evaluation(
        &self,
        eval: &ValidatorEvaluation,
    ) -> Result<(bool, bool, Option<f64>)> {
        // Validate score is in valid range [0.0, 1.0]
        let validated_score = eval.score.clamp(0.0, 1.0);
        if (validated_score - eval.score).abs() > 0.001 {
            warn!(
                "Score {} from validator {} clamped to {}",
                eval.score,
                &eval.validator_hotkey[..16.min(eval.validator_hotkey.len())],
                validated_score
            );
        }

        let mut client = self.pool.get().await?;

        // Start transaction for atomic operations
        let transaction = client.transaction().await?;

        // Check if window expired AND lock the row to prevent race conditions
        let window_row = transaction.query_opt(
            "SELECT window_expires_at < NOW() as expired, validators_completed, total_validators
             FROM pending_evaluations WHERE agent_hash = $1 FOR UPDATE",
            &[&eval.agent_hash],
        ).await?;

        let (is_expired, validators_completed, total_validators) = match window_row {
            Some(r) => {
                let expired: bool = r.get(0);
                let completed: i32 = r.get(1);
                let total: i32 = r.get(2);
                (expired, completed, total)
            }
            None => {
                transaction.rollback().await?;
                return Err(anyhow::anyhow!("Agent not found in pending evaluations"));
            }
        };

        if is_expired {
            info!(
                "Validator {} is LATE for agent {} (window expired)",
                &eval.validator_hotkey[..16.min(eval.validator_hotkey.len())],
                &eval.agent_hash[..16]
            );
            // Remove the claim since they're late
            transaction
                .execute(
                    "DELETE FROM validator_claims WHERE agent_hash = $1 AND validator_hotkey = $2",
                    &[&eval.agent_hash, &eval.validator_hotkey],
                )
                .await?;
            transaction.commit().await?;
            return Ok((true, false, None));
        }

        // Check if this validator already submitted (to avoid double-counting)
        let already_submitted = transaction.query_opt(
            "SELECT 1 FROM validator_evaluations WHERE agent_hash = $1 AND validator_hotkey = $2",
            &[&eval.agent_hash, &eval.validator_hotkey],
        ).await?.is_some();

        // Insert or update the evaluation
        // Cast f64 to f32 for PostgreSQL REAL columns
        let score_f32 = validated_score as f32;
        let cost_f32 = eval.total_cost_usd as f32;
        transaction.execute(
            "INSERT INTO validator_evaluations 
             (id, agent_hash, validator_hotkey, submission_id, miner_hotkey, score, 
              tasks_passed, tasks_total, tasks_failed, total_cost_usd, execution_time_ms, task_results, epoch)
             VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13)
             ON CONFLICT(agent_hash, validator_hotkey) DO UPDATE SET
                score = EXCLUDED.score,
                tasks_passed = EXCLUDED.tasks_passed,
                tasks_total = EXCLUDED.tasks_total,
                tasks_failed = EXCLUDED.tasks_failed,
                total_cost_usd = EXCLUDED.total_cost_usd,
                execution_time_ms = EXCLUDED.execution_time_ms,
                task_results = EXCLUDED.task_results",
            &[
                &eval.id, &eval.agent_hash, &eval.validator_hotkey, &eval.submission_id,
                &eval.miner_hotkey, &score_f32, &eval.tasks_passed, &eval.tasks_total,
                &eval.tasks_failed, &cost_f32, &eval.execution_time_ms,
                &eval.task_results, &eval.epoch,
            ],
        ).await?;

        // Update claim status
        transaction
            .execute(
                "UPDATE validator_claims SET status = 'completed' 
             WHERE agent_hash = $1 AND validator_hotkey = $2",
                &[&eval.agent_hash, &eval.validator_hotkey],
            )
            .await?;

        // Only increment counter if this is a NEW submission (not an update)
        let new_completed = if !already_submitted {
            transaction
                .execute(
                    "UPDATE pending_evaluations SET validators_completed = validators_completed + 1
                 WHERE agent_hash = $1",
                    &[&eval.agent_hash],
                )
                .await?;
            validators_completed + 1
        } else {
            validators_completed
        };

        // Check if all validators have completed
        let all_done = new_completed >= total_validators;

        // Commit the transaction before calculating consensus
        transaction.commit().await?;

        if all_done {
            // Calculate consensus score and finalize (separate transaction)
            let final_score = self.calculate_and_store_consensus(&eval.agent_hash).await?;
            return Ok((false, true, Some(final_score)));
        }

        info!(
            "Validator {} submitted evaluation for {} ({}/{} validators done)",
            &eval.validator_hotkey[..16.min(eval.validator_hotkey.len())],
            &eval.agent_hash[..16],
            new_completed,
            total_validators
        );

        Ok((false, false, None))
    }

    /// Calculate consensus score from all validator evaluations
    /// Currently uses simple average (can be extended to stake-weighted)
    /// Uses transaction to ensure atomic consensus calculation
    async fn calculate_and_store_consensus(&self, agent_hash: &str) -> Result<f64> {
        let mut client = self.pool.get().await?;
        let transaction = client.transaction().await?;

        // Lock the pending_evaluations row to prevent concurrent consensus calculations
        let lock_check = transaction
            .query_opt(
                "SELECT status FROM pending_evaluations WHERE agent_hash = $1 FOR UPDATE",
                &[&agent_hash],
            )
            .await?;

        // Check if already completed (another thread beat us)
        if let Some(row) = lock_check {
            let status: String = row.get(0);
            if status == "completed" {
                transaction.rollback().await?;
                // Get the existing score from leaderboard
                let lb = self.get_leaderboard_entry(agent_hash).await?;
                return Ok(lb.map(|e| e.best_score).unwrap_or(0.0));
            }
        }

        // Get all evaluations for this agent
        let rows = transaction
            .query(
                "SELECT score::FLOAT8, tasks_passed, tasks_total, tasks_failed, total_cost_usd::FLOAT8, 
                    execution_time_ms, submission_id, miner_hotkey
             FROM validator_evaluations WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await?;

        if rows.is_empty() {
            transaction.rollback().await?;
            return Err(anyhow::anyhow!("No evaluations found for agent"));
        }

        // Calculate averages
        let mut total_score = 0.0;
        let mut total_tasks_passed = 0;
        let mut total_tasks_total = 0;
        let mut total_tasks_failed = 0;
        let mut total_cost = 0.0;
        let mut total_time: i64 = 0;
        let count = rows.len() as f64;

        let mut submission_id = String::new();
        let mut miner_hotkey = String::new();

        for row in &rows {
            let score: f64 = row.get(0);
            let passed: i32 = row.get(1);
            let total: i32 = row.get(2);
            let failed: i32 = row.get(3);
            let cost: f64 = row.get(4);
            let time: Option<i64> = row.get(5);

            total_score += score;
            total_tasks_passed += passed;
            total_tasks_total += total;
            total_tasks_failed += failed;
            total_cost += cost;
            total_time += time.unwrap_or(0);

            if submission_id.is_empty() {
                submission_id = row.get(6);
                miner_hotkey = row.get(7);
            }
        }

        // Protect against division by zero
        if count == 0.0 {
            transaction.rollback().await?;
            return Err(anyhow::anyhow!("No valid evaluations for consensus"));
        }

        let final_score = (total_score / count).clamp(0.0, 1.0);
        let avg_passed = (total_tasks_passed as f64 / count).round() as i32;
        let avg_total = (total_tasks_total as f64 / count).round() as i32;
        let avg_failed = (total_tasks_failed as f64 / count).round() as i32;
        let avg_cost = total_cost / count;
        let avg_time = (total_time as f64 / count).round() as i64;

        // Store final consensus result
        // Cast f64 to f32 for PostgreSQL REAL columns
        let score_f32 = final_score as f32;
        let cost_f32 = avg_cost as f32;
        let eval_id = uuid::Uuid::new_v4().to_string();
        transaction
            .execute(
                "INSERT INTO evaluations 
             (id, submission_id, agent_hash, miner_hotkey, score, tasks_passed, tasks_total, 
              tasks_failed, total_cost_usd, execution_time_ms)
             VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
             ON CONFLICT(id) DO NOTHING",
                &[
                    &eval_id,
                    &submission_id,
                    &agent_hash,
                    &miner_hotkey,
                    &score_f32,
                    &avg_passed,
                    &avg_total,
                    &avg_failed,
                    &cost_f32,
                    &avg_time,
                ],
            )
            .await?;

        // Update pending_evaluations status
        transaction
            .execute(
                "UPDATE pending_evaluations SET status = 'completed' WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await?;

        // Commit transaction
        transaction.commit().await?;

        // Update leaderboard (separate operation, can fail independently)
        if let Err(e) = self
            .update_leaderboard(agent_hash, &miner_hotkey, None, final_score, avg_cost)
            .await
        {
            warn!(
                "Failed to update leaderboard for {}: {:?}",
                &agent_hash[..16],
                e
            );
        }

        info!(
            "Consensus reached for agent {}: score={:.4} from {} validators",
            &agent_hash[..16],
            final_score,
            rows.len()
        );

        Ok(final_score)
    }

    /// Get all validator evaluations for an agent
    pub async fn get_validator_evaluations(
        &self,
        agent_hash: &str,
    ) -> Result<Vec<ValidatorEvaluation>> {
        let client = self.pool.get().await?;
        let rows = client
            .query(
                "SELECT id, agent_hash, validator_hotkey, submission_id, miner_hotkey,
                    score::FLOAT8, tasks_passed, tasks_total, tasks_failed, total_cost_usd::FLOAT8,
                    execution_time_ms, task_results, epoch, 
                    EXTRACT(EPOCH FROM created_at)::BIGINT
             FROM validator_evaluations WHERE agent_hash = $1
             ORDER BY created_at ASC",
                &[&agent_hash],
            )
            .await?;

        Ok(rows
            .iter()
            .map(|r| ValidatorEvaluation {
                id: r.get(0),
                agent_hash: r.get(1),
                validator_hotkey: r.get(2),
                submission_id: r.get(3),
                miner_hotkey: r.get(4),
                score: r.get(5),
                tasks_passed: r.get(6),
                tasks_total: r.get(7),
                tasks_failed: r.get(8),
                total_cost_usd: r.get(9),
                execution_time_ms: r.get(10),
                task_results: r.get(11),
                epoch: r.get(12),
                created_at: r.get(13),
            })
            .collect())
    }

    /// Get pending evaluation status for an agent
    pub async fn get_pending_status(&self, agent_hash: &str) -> Result<Option<PendingEvaluation>> {
        let client = self.pool.get().await?;
        let row = client
            .query_opt(
                "SELECT id, submission_id, agent_hash, miner_hotkey, epoch, status,
                    validators_completed, total_validators,
                    EXTRACT(EPOCH FROM window_started_at)::BIGINT,
                    EXTRACT(EPOCH FROM window_expires_at)::BIGINT,
                    EXTRACT(EPOCH FROM created_at)::BIGINT
             FROM pending_evaluations WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await?;

        Ok(row.map(|r| PendingEvaluation {
            id: r.get(0),
            submission_id: r.get(1),
            agent_hash: r.get(2),
            miner_hotkey: r.get(3),
            epoch: r.get(4),
            status: r.get(5),
            validators_completed: r.get(6),
            total_validators: r.get(7),
            window_started_at: r.get(8),
            window_expires_at: r.get(9),
            created_at: r.get(10),
        }))
    }

    /// Expire old evaluation windows and calculate consensus for partial results
    pub async fn expire_old_windows(&self) -> Result<u64> {
        let client = self.pool.get().await?;

        // Get agents with expired windows that haven't been completed
        let rows = client
            .query(
                "SELECT agent_hash FROM pending_evaluations 
             WHERE status != 'completed' AND window_expires_at < NOW()",
                &[],
            )
            .await?;

        let mut expired_count = 0u64;
        for row in rows {
            let agent_hash: String = row.get(0);

            // Calculate consensus with whatever evaluations we have
            match self.calculate_and_store_consensus(&agent_hash).await {
                Ok(score) => {
                    info!(
                        "Expired window for agent {} - consensus score: {:.4}",
                        &agent_hash[..16],
                        score
                    );
                    expired_count += 1;
                }
                Err(e) => {
                    // No evaluations yet - mark as failed
                    debug!(
                        "No evaluations for expired agent {}: {}",
                        &agent_hash[..16],
                        e
                    );
                    client.execute(
                        "UPDATE pending_evaluations SET status = 'expired' WHERE agent_hash = $1",
                        &[&agent_hash],
                    ).await?;
                    expired_count += 1;
                }
            }
        }

        if expired_count > 0 {
            info!("Expired {} evaluation windows", expired_count);
        }

        Ok(expired_count)
    }

    /// Get validator's active claims
    pub async fn get_validator_claims(
        &self,
        validator_hotkey: &str,
    ) -> Result<Vec<ValidatorClaim>> {
        let client = self.pool.get().await?;
        let rows = client
            .query(
                "SELECT id, agent_hash, validator_hotkey, 
                    EXTRACT(EPOCH FROM claimed_at)::BIGINT, status
             FROM validator_claims 
             WHERE validator_hotkey = $1 AND status = 'claimed'
             ORDER BY claimed_at ASC",
                &[&validator_hotkey],
            )
            .await?;

        Ok(rows
            .iter()
            .map(|r| ValidatorClaim {
                id: r.get(0),
                agent_hash: r.get(1),
                validator_hotkey: r.get(2),
                claimed_at: r.get(3),
                status: r.get(4),
            })
            .collect())
    }

    /// Release a claim (validator giving up)
    pub async fn release_claim(&self, agent_hash: &str, validator_hotkey: &str) -> Result<()> {
        let client = self.pool.get().await?;
        client
            .execute(
                "DELETE FROM validator_claims WHERE agent_hash = $1 AND validator_hotkey = $2",
                &[&agent_hash, &validator_hotkey],
            )
            .await?;
        Ok(())
    }

    /// Cleanup stale claims older than timeout_minutes
    /// Should be called periodically (e.g., every 10 minutes)
    pub async fn cleanup_stale_claims(&self, timeout_minutes: i64) -> Result<u64> {
        let client = self.pool.get().await?;

        let result = client
            .execute(
                "DELETE FROM validator_claims 
                 WHERE status = 'claimed' 
                 AND claimed_at < NOW() - INTERVAL '1 minute' * $1",
                &[&timeout_minutes],
            )
            .await?;

        if result > 0 {
            info!(
                "Cleaned up {} stale claims (older than {} minutes)",
                result, timeout_minutes
            );
        }

        Ok(result)
    }

    /// Run all periodic maintenance tasks
    /// - Expire old evaluation windows
    /// - Cleanup stale claims (1 hour timeout)
    pub async fn run_maintenance(&self) -> Result<()> {
        // Cleanup stale claims (1 hour timeout)
        if let Err(e) = self.cleanup_stale_claims(60).await {
            warn!("Failed to cleanup stale claims: {:?}", e);
        }

        // Expire old evaluation windows
        if let Err(e) = self.expire_old_windows().await {
            warn!("Failed to expire old windows: {:?}", e);
        }

        Ok(())
    }

    /// Get all pending evaluations (for status endpoint)
    pub async fn get_all_pending(&self) -> Result<Vec<PendingEvaluation>> {
        let client = self.pool.get().await?;
        let rows = client
            .query(
                "SELECT id, submission_id, agent_hash, miner_hotkey, epoch, status,
                    validators_completed, total_validators,
                    EXTRACT(EPOCH FROM window_started_at)::BIGINT,
                    EXTRACT(EPOCH FROM window_expires_at)::BIGINT,
                    EXTRACT(EPOCH FROM created_at)::BIGINT
             FROM pending_evaluations 
             WHERE status IN ('pending', 'evaluating')
             ORDER BY created_at ASC",
                &[],
            )
            .await?;

        Ok(rows
            .iter()
            .map(|r| PendingEvaluation {
                id: r.get(0),
                submission_id: r.get(1),
                agent_hash: r.get(2),
                miner_hotkey: r.get(3),
                epoch: r.get(4),
                status: r.get(5),
                validators_completed: r.get(6),
                total_validators: r.get(7),
                window_started_at: r.get(8),
                window_expires_at: r.get(9),
                created_at: r.get(10),
            })
            .collect())
    }

    // ========================================================================
    // EPOCH
    // ========================================================================

    /// Get current epoch
    pub async fn get_current_epoch(&self) -> Result<i64> {
        let client = self.pool.get().await?;
        let row = client
            .query_one("SELECT current_epoch FROM epoch_state WHERE id = 1", &[])
            .await?;
        Ok(row.get(0))
    }

    /// Set current epoch
    pub async fn set_current_epoch(&self, epoch: i64) -> Result<()> {
        let client = self.pool.get().await?;
        client
            .execute(
                "UPDATE epoch_state SET current_epoch = $1, last_epoch_change = NOW() WHERE id = 1",
                &[&epoch],
            )
            .await?;
        Ok(())
    }

    /// Calculate epoch from block number using term-challenge epoch formula
    ///
    /// This uses the epoch calculator which defines:
    /// - Epoch 0 starts at block 7,276,080
    /// - Each epoch is `tempo` blocks (default 360)
    pub fn calculate_epoch_from_block(block: u64) -> i64 {
        let calculator = EpochCalculator::new();
        calculator.epoch_from_block(block) as i64
    }

    /// Calculate epoch from block with custom tempo
    pub fn calculate_epoch_from_block_with_tempo(block: u64, tempo: u64) -> i64 {
        let calculator = EpochCalculator::with_tempo(tempo);
        calculator.epoch_from_block(block) as i64
    }

    // ========================================================================
    // CONFIG
    // ========================================================================

    /// Set config value
    pub async fn set_config(&self, key: &str, value: &str) -> Result<()> {
        let client = self.pool.get().await?;
        client
            .execute(
                "INSERT INTO config (key, value, updated_at) VALUES ($1, $2, NOW())
             ON CONFLICT(key) DO UPDATE SET value = EXCLUDED.value, updated_at = NOW()",
                &[&key, &value],
            )
            .await?;
        Ok(())
    }

    /// Get config value
    pub async fn get_config(&self, key: &str) -> Result<Option<String>> {
        let client = self.pool.get().await?;
        let row = client
            .query_opt("SELECT value FROM config WHERE key = $1", &[&key])
            .await?;
        Ok(row.map(|r| r.get(0)))
    }

    // ========================================================================
    // RECOVERY (After restart)
    // ========================================================================

    /// Recover stale claims after server restart
    /// Releases claims that have been "claimed" for too long (> 1 hour)
    pub async fn recover_stale_claims(&self) -> Result<usize> {
        let client = self.pool.get().await?;

        // Release claims older than 1 hour that are still in 'claimed' status
        let result = client
            .execute(
                "UPDATE validator_claims 
             SET status = 'expired'
             WHERE status = 'claimed' 
             AND claimed_at < NOW() - INTERVAL '1 hour'",
                &[],
            )
            .await?;

        if result > 0 {
            info!("Recovery: Released {} stale validator claims", result);
        }

        Ok(result as usize)
    }

    /// Recover expired evaluation windows
    /// Marks pending evaluations as 'expired' if window has passed
    pub async fn recover_expired_evaluations(&self) -> Result<usize> {
        let client = self.pool.get().await?;

        let result = client
            .execute(
                "UPDATE pending_evaluations 
             SET status = 'expired'
             WHERE status IN ('pending', 'evaluating')
             AND window_expires_at < NOW()",
                &[],
            )
            .await?;

        if result > 0 {
            info!(
                "Recovery: Marked {} evaluations as expired (window passed)",
                result
            );
        }

        Ok(result as usize)
    }

    /// Run all recovery tasks (call at server startup)
    pub async fn run_recovery(&self) -> Result<()> {
        info!("Running database recovery tasks...");

        let stale_claims = self.recover_stale_claims().await?;
        let expired_evals = self.recover_expired_evaluations().await?;

        info!(
            "Recovery complete: {} stale claims released, {} expired evaluations marked",
            stale_claims, expired_evals
        );

        Ok(())
    }

    // ========================================================================
    // TASK LOGS (Real-time task tracking)
    // ========================================================================

    /// Assign tasks to an agent (called when submission is queued)
    pub async fn assign_tasks_to_agent(
        &self,
        agent_hash: &str,
        tasks: &[TaskAssignment],
    ) -> Result<()> {
        let client = self.pool.get().await?;

        for task in tasks {
            let id = uuid::Uuid::new_v4().to_string();
            client
                .execute(
                    "INSERT INTO evaluation_tasks (id, agent_hash, task_id, task_name)
                 VALUES ($1, $2, $3, $4)
                 ON CONFLICT(agent_hash, task_id) DO NOTHING",
                    &[&id, &agent_hash, &task.task_id, &task.task_name],
                )
                .await?;
        }

        debug!(
            "Assigned {} tasks to agent {}",
            tasks.len(),
            &agent_hash[..16.min(agent_hash.len())]
        );
        Ok(())
    }

    /// Get assigned tasks for an agent
    pub async fn get_assigned_tasks(&self, agent_hash: &str) -> Result<Vec<TaskAssignment>> {
        let client = self.pool.get().await?;
        let rows = client
            .query(
                "SELECT task_id, task_name FROM evaluation_tasks WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await?;

        Ok(rows
            .iter()
            .map(|r| TaskAssignment {
                task_id: r.get(0),
                task_name: r.get(1),
            })
            .collect())
    }

    /// Store a task log (real-time reporting from validator)
    pub async fn store_task_log(&self, log: &TaskLog) -> Result<()> {
        let client = self.pool.get().await?;

        // Cast f64 to f32 for PostgreSQL REAL columns
        let score_f32 = log.score as f32;
        let cost_f32 = log.cost_usd as f32;

        // Truncate large log fields to prevent database bloat
        let agent_stderr = truncate_log(log.agent_stderr.clone());
        let agent_stdout = truncate_log(log.agent_stdout.clone());
        let test_output = truncate_log(log.test_output.clone());
        let execution_log = truncate_log(log.execution_log.clone());

        client
            .execute(
                "INSERT INTO task_logs (id, agent_hash, validator_hotkey, task_id, task_name,
                passed, score, execution_time_ms, steps, cost_usd, error, execution_log, 
                trajectory, started_at, completed_at,
                agent_stderr, agent_stdout, test_output, steps_executed, failure_stage)
             VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, 
                     TO_TIMESTAMP($14), TO_TIMESTAMP($15), $16, $17, $18, $19, $20)
             ON CONFLICT(agent_hash, validator_hotkey, task_id) DO UPDATE SET
                passed = EXCLUDED.passed,
                score = EXCLUDED.score,
                execution_time_ms = EXCLUDED.execution_time_ms,
                steps = EXCLUDED.steps,
                cost_usd = EXCLUDED.cost_usd,
                error = EXCLUDED.error,
                execution_log = EXCLUDED.execution_log,
                trajectory = EXCLUDED.trajectory,
                completed_at = EXCLUDED.completed_at,
                agent_stderr = EXCLUDED.agent_stderr,
                agent_stdout = EXCLUDED.agent_stdout,
                test_output = EXCLUDED.test_output,
                steps_executed = EXCLUDED.steps_executed,
                failure_stage = EXCLUDED.failure_stage",
                &[
                    &log.id,
                    &log.agent_hash,
                    &log.validator_hotkey,
                    &log.task_id,
                    &log.task_name,
                    &log.passed,
                    &score_f32,
                    &log.execution_time_ms,
                    &log.steps,
                    &cost_f32,
                    &log.error,
                    &execution_log,
                    &log.trajectory,
                    &(log.started_at as f64),
                    &(log.completed_at as f64),
                    &agent_stderr,
                    &agent_stdout,
                    &test_output,
                    &log.steps_executed,
                    &log.failure_stage,
                ],
            )
            .await?;

        // Enhanced logging for failures
        if !log.passed {
            // Helper to truncate long strings for log output
            let truncate = |s: &str, max: usize| -> String {
                if s.len() > max {
                    format!("{}...(truncated {} chars)", &s[..max], s.len() - max)
                } else {
                    s.to_string()
                }
            };

            warn!(
                "Task FAILED: {} {} task={} steps={:?} error={:?} stage={:?} stderr={:?} test_output={:?}",
                &log.validator_hotkey[..16.min(log.validator_hotkey.len())],
                &log.agent_hash[..16.min(log.agent_hash.len())],
                log.task_name,
                log.steps_executed,
                log.error.as_ref().map(|s| truncate(s, 200)),
                log.failure_stage,
                log.agent_stderr.as_ref().map(|s| truncate(s, 300)),
                log.test_output.as_ref().map(|s| truncate(s, 300)),
            );
        } else {
            info!(
                "Task log stored: {} {} task={} passed={} score={:.2}",
                &log.validator_hotkey[..16.min(log.validator_hotkey.len())],
                &log.agent_hash[..16.min(log.agent_hash.len())],
                log.task_name,
                log.passed,
                log.score
            );
        }

        Ok(())
    }

    /// Get task logs for a validator's evaluation of an agent
    pub async fn get_task_logs(
        &self,
        agent_hash: &str,
        validator_hotkey: &str,
    ) -> Result<Vec<TaskLog>> {
        let client = self.pool.get().await?;
        let rows = client
            .query(
                "SELECT id, agent_hash, validator_hotkey, task_id, task_name,
                    passed, score::FLOAT8, execution_time_ms, steps, cost_usd::FLOAT8,
                    error, execution_log, trajectory,
                    EXTRACT(EPOCH FROM started_at)::BIGINT,
                    EXTRACT(EPOCH FROM completed_at)::BIGINT,
                    agent_stderr, agent_stdout, test_output, steps_executed, failure_stage
             FROM task_logs 
             WHERE agent_hash = $1 AND validator_hotkey = $2
             ORDER BY completed_at ASC",
                &[&agent_hash, &validator_hotkey],
            )
            .await?;

        Ok(rows
            .iter()
            .map(|r| TaskLog {
                id: r.get(0),
                agent_hash: r.get(1),
                validator_hotkey: r.get(2),
                task_id: r.get(3),
                task_name: r.get(4),
                passed: r.get(5),
                score: r.get(6),
                execution_time_ms: r.get(7),
                steps: r.get(8),
                cost_usd: r.get(9),
                error: r.get(10),
                execution_log: r.get(11),
                trajectory: r.get(12),
                started_at: r.get(13),
                completed_at: r.get(14),
                agent_stderr: r.get(15),
                agent_stdout: r.get(16),
                test_output: r.get(17),
                steps_executed: r.get(18),
                failure_stage: r.get(19),
            })
            .collect())
    }

    /// Get summary of task logs for verification before final submission
    pub async fn get_task_log_summary(
        &self,
        agent_hash: &str,
        validator_hotkey: &str,
    ) -> Result<TaskLogSummary> {
        let client = self.pool.get().await?;

        // Fixed task count - validators always evaluate 30 tasks from terminal-bench@2.0
        // Note: evaluation_tasks table uses placeholder IDs (task_01, task_02, etc.)
        // while actual task_logs use real terminal-bench task IDs, so we use a constant here.
        const TASKS_PER_EVALUATION: i64 = 30;
        let total_tasks: i64 = TASKS_PER_EVALUATION;

        // Get completed task summary
        let summary_row = client
            .query_one(
                "SELECT 
                COUNT(*)::BIGINT,
                COALESCE(SUM(CASE WHEN passed THEN 1 ELSE 0 END), 0)::BIGINT,
                COALESCE(SUM(CASE WHEN NOT passed THEN 1 ELSE 0 END), 0)::BIGINT,
                COALESCE(SUM(score::FLOAT8), 0.0)::FLOAT8,
                COALESCE(SUM(cost_usd::FLOAT8), 0.0)::FLOAT8,
                COALESCE(SUM(execution_time_ms), 0)::BIGINT
             FROM task_logs 
             WHERE agent_hash = $1 AND validator_hotkey = $2",
                &[&agent_hash, &validator_hotkey],
            )
            .await?;

        Ok(TaskLogSummary {
            total_tasks: total_tasks as i32,
            completed_tasks: summary_row.get::<_, i64>(0) as i32,
            passed_tasks: summary_row.get::<_, i64>(1) as i32,
            failed_tasks: summary_row.get::<_, i64>(2) as i32,
            total_score: summary_row.get::<_, f64>(3),
            total_cost_usd: summary_row.get::<_, f64>(4),
            total_execution_time_ms: summary_row.get::<_, i64>(5),
        })
    }

    /// Verify all tasks are logged before accepting final submission
    pub async fn verify_task_logs_complete(
        &self,
        agent_hash: &str,
        validator_hotkey: &str,
    ) -> Result<(bool, String)> {
        let summary = self
            .get_task_log_summary(agent_hash, validator_hotkey)
            .await?;

        if summary.total_tasks == 0 {
            return Ok((false, "No tasks assigned to this agent".to_string()));
        }

        if summary.completed_tasks < summary.total_tasks {
            return Ok((
                false,
                format!(
                    "Incomplete: {}/{} tasks logged",
                    summary.completed_tasks, summary.total_tasks
                ),
            ));
        }

        // All tasks logged
        Ok((
            true,
            format!(
                "Complete: {}/{} tasks, {}/{} passed",
                summary.completed_tasks,
                summary.total_tasks,
                summary.passed_tasks,
                summary.completed_tasks
            ),
        ))
    }

    /// Get evaluation progress for resuming interrupted evaluations
    /// Returns which tasks have been completed and which remain
    pub async fn get_evaluation_progress(
        &self,
        agent_hash: &str,
        validator_hotkey: &str,
    ) -> Result<EvaluationProgress> {
        let client = self.pool.get().await?;

        // Get all assigned tasks for this agent
        let assigned_rows = client
            .query(
                "SELECT task_id, task_name FROM evaluation_tasks WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await?;

        let assigned_task_ids: Vec<String> = assigned_rows
            .iter()
            .map(|r| r.get::<_, String>(0))
            .collect();

        // Get completed tasks from task_logs (excluding special failure markers)
        let completed_rows = client
            .query(
                "SELECT task_id, passed, score::FLOAT8 
                 FROM task_logs 
                 WHERE agent_hash = $1 AND validator_hotkey = $2 
                   AND task_id NOT LIKE '__%%'
                 ORDER BY completed_at ASC",
                &[&agent_hash, &validator_hotkey],
            )
            .await?;

        let completed_tasks: Vec<crate::api::CompletedTaskInfo> = completed_rows
            .iter()
            .map(|r| crate::api::CompletedTaskInfo {
                task_id: r.get(0),
                passed: r.get(1),
                score: r.get(2),
            })
            .collect();

        let completed_ids: std::collections::HashSet<String> =
            completed_tasks.iter().map(|t| t.task_id.clone()).collect();

        // Calculate remaining tasks
        let remaining_task_ids: Vec<String> = assigned_task_ids
            .iter()
            .filter(|id| !completed_ids.contains(*id))
            .cloned()
            .collect();

        // Calculate partial score
        let total_tasks = assigned_task_ids.len() as i32;
        let partial_score = if !completed_tasks.is_empty() {
            let passed = completed_tasks.iter().filter(|t| t.passed).count() as f64;
            passed / total_tasks as f64
        } else {
            0.0
        };

        Ok(EvaluationProgress {
            total_tasks,
            completed_tasks,
            remaining_task_ids,
            partial_score,
        })
    }

    /// Get all task logs for an agent across all validators
    pub async fn get_agent_task_logs(&self, agent_hash: &str) -> Result<Vec<TaskLog>> {
        let client = self.pool.get().await?;

        let rows = client
            .query(
                "SELECT id, agent_hash, validator_hotkey, task_id, task_name, passed, score::FLOAT8,
                        execution_time_ms, steps, cost_usd::FLOAT8, error, execution_log, trajectory,
                        EXTRACT(EPOCH FROM started_at)::BIGINT as started_at,
                        EXTRACT(EPOCH FROM completed_at)::BIGINT as completed_at,
                        agent_stderr, agent_stdout, test_output, steps_executed, failure_stage
                 FROM task_logs 
                 WHERE agent_hash = $1
                 ORDER BY validator_hotkey, completed_at DESC",
                &[&agent_hash],
            )
            .await?;

        Ok(rows
            .iter()
            .map(|row| TaskLog {
                id: row.get("id"),
                agent_hash: row.get("agent_hash"),
                validator_hotkey: row.get("validator_hotkey"),
                task_id: row.get("task_id"),
                task_name: row.get("task_name"),
                passed: row.get("passed"),
                score: row.get("score"),
                execution_time_ms: row.get("execution_time_ms"),
                steps: row.get("steps"),
                cost_usd: row.get("cost_usd"),
                error: row.get("error"),
                execution_log: row.get("execution_log"),
                trajectory: row.get("trajectory"),
                started_at: row.get("started_at"),
                completed_at: row.get("completed_at"),
                agent_stderr: row.get("agent_stderr"),
                agent_stdout: row.get("agent_stdout"),
                test_output: row.get("test_output"),
                steps_executed: row.get("steps_executed"),
                failure_stage: row.get("failure_stage"),
            })
            .collect())
    }

    /// Get task logs for an agent by a specific validator
    pub async fn get_agent_task_logs_by_validator(
        &self,
        agent_hash: &str,
        validator_hotkey: &str,
    ) -> Result<Vec<TaskLog>> {
        let client = self.pool.get().await?;

        let rows = client
            .query(
                "SELECT id, agent_hash, validator_hotkey, task_id, task_name, passed, score::FLOAT8,
                        execution_time_ms, steps, cost_usd::FLOAT8, error, execution_log, trajectory,
                        EXTRACT(EPOCH FROM started_at)::BIGINT as started_at,
                        EXTRACT(EPOCH FROM completed_at)::BIGINT as completed_at,
                        agent_stderr, agent_stdout, test_output, steps_executed, failure_stage
                 FROM task_logs 
                 WHERE agent_hash = $1 AND validator_hotkey = $2
                 ORDER BY completed_at DESC",
                &[&agent_hash, &validator_hotkey],
            )
            .await?;

        Ok(rows
            .iter()
            .map(|row| TaskLog {
                id: row.get("id"),
                agent_hash: row.get("agent_hash"),
                validator_hotkey: row.get("validator_hotkey"),
                task_id: row.get("task_id"),
                task_name: row.get("task_name"),
                passed: row.get("passed"),
                score: row.get("score"),
                execution_time_ms: row.get("execution_time_ms"),
                steps: row.get("steps"),
                cost_usd: row.get("cost_usd"),
                error: row.get("error"),
                execution_log: row.get("execution_log"),
                trajectory: row.get("trajectory"),
                started_at: row.get("started_at"),
                completed_at: row.get("completed_at"),
                agent_stderr: row.get("agent_stderr"),
                agent_stdout: row.get("agent_stdout"),
                test_output: row.get("test_output"),
                steps_executed: row.get("steps_executed"),
                failure_stage: row.get("failure_stage"),
            })
            .collect())
    }

    /// Get evaluation progress for an agent across all validators
    pub async fn get_agent_evaluation_progress_all_validators(
        &self,
        agent_hash: &str,
    ) -> Result<Vec<ValidatorEvaluationProgress>> {
        let client = self.pool.get().await?;

        // Get all validator assignments for this agent
        let assignments = client
            .query(
                "SELECT validator_hotkey, status, 
                        EXTRACT(EPOCH FROM assigned_at)::BIGINT as assigned_at
                 FROM validator_assignments 
                 WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await?;

        // Get assigned tasks count
        // Fixed task count - validators always evaluate 30 tasks from terminal-bench@2.0
        const TASKS_PER_EVALUATION: i64 = 30;
        let total_tasks: i64 = TASKS_PER_EVALUATION;

        let mut results = Vec::new();

        for assignment in assignments {
            let validator_hotkey: String = assignment.get("validator_hotkey");
            let assignment_status: String = assignment.get("status");
            let assigned_at: Option<i64> = assignment.try_get("assigned_at").ok();

            // Get task log summary for this validator
            let summary = client
                .query_one(
                    "SELECT 
                        COUNT(*) as completed,
                        COUNT(*) FILTER (WHERE passed = true) as passed,
                        COUNT(*) FILTER (WHERE passed = false) as failed,
                        MAX(EXTRACT(EPOCH FROM completed_at)::BIGINT) as last_update
                     FROM task_logs 
                     WHERE agent_hash = $1 AND validator_hotkey = $2",
                    &[&agent_hash, &validator_hotkey],
                )
                .await?;

            let completed: i64 = summary.get("completed");
            let passed: i64 = summary.get("passed");
            let failed: i64 = summary.get("failed");
            let last_update: Option<i64> = summary.try_get("last_update").ok().flatten();

            // Calculate remaining based on completed count vs total (30)
            // Note: We don't track individual task IDs for remaining since evaluation_tasks
            // uses placeholder IDs while task_logs use real terminal-bench IDs
            let remaining = (total_tasks - completed).max(0);
            let remaining_task_ids: Vec<String> = Vec::new(); // Not tracking individual IDs

            // Determine status based on completed count
            let status = if completed == 0 {
                if assignment_status == "pending" {
                    "pending"
                } else {
                    "in_progress"
                }
            } else if completed >= total_tasks {
                "completed"
            } else {
                "in_progress"
            };

            // No current task tracking since we don't have individual remaining IDs
            let current_task: Option<String> = None;
            let _ = remaining; // Used for status calculation above

            results.push(ValidatorEvaluationProgress {
                validator_hotkey,
                status: status.to_string(),
                total_tasks: total_tasks as i32,
                completed_tasks: completed as i32,
                passed_tasks: passed as i32,
                failed_tasks: failed as i32,
                remaining_task_ids,
                current_task,
                started_at: assigned_at,
                last_update,
            });
        }

        Ok(results)
    }

    /// Get recent evaluations by a specific validator
    pub async fn get_validator_recent_evaluations(
        &self,
        validator_hotkey: &str,
        limit: i32,
    ) -> Result<Vec<ValidatorEvaluation>> {
        let client = self.pool.get().await?;

        let rows = client
            .query(
                "SELECT id, agent_hash, validator_hotkey, submission_id, miner_hotkey,
                        score::FLOAT8, tasks_passed, tasks_total, tasks_failed, total_cost_usd::FLOAT8,
                        execution_time_ms, task_results, epoch,
                        EXTRACT(EPOCH FROM created_at)::BIGINT as created_at
                 FROM validator_evaluations 
                 WHERE validator_hotkey = $1
                 ORDER BY created_at DESC
                 LIMIT $2",
                &[&validator_hotkey, &(limit as i64)],
            )
            .await?;

        Ok(rows
            .iter()
            .map(|row| ValidatorEvaluation {
                id: row.get("id"),
                agent_hash: row.get("agent_hash"),
                validator_hotkey: row.get("validator_hotkey"),
                submission_id: row.get("submission_id"),
                miner_hotkey: row.get("miner_hotkey"),
                score: row.get("score"),
                tasks_passed: row.get("tasks_passed"),
                tasks_total: row.get("tasks_total"),
                tasks_failed: row.get("tasks_failed"),
                total_cost_usd: row.get("total_cost_usd"),
                execution_time_ms: row.get("execution_time_ms"),
                task_results: row.get("task_results"),
                epoch: row.get("epoch"),
                created_at: row.get("created_at"),
            })
            .collect())
    }

    // ========================================================================
    // AGENT COMPILATION METHODS
    // ========================================================================

    /// Update compilation status to 'compiling'
    pub async fn set_compiling(&self, agent_hash: &str) -> Result<()> {
        let client = self.pool.get().await?;
        client
            .execute(
                "UPDATE submissions SET compile_status = 'compiling' WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await?;
        Ok(())
    }

    /// Store compiled binary and mark as success
    pub async fn store_binary(
        &self,
        agent_hash: &str,
        binary: &[u8],
        compile_time_ms: i32,
    ) -> Result<()> {
        let client = self.pool.get().await?;
        let binary_size = binary.len() as i32;

        client
            .execute(
                "UPDATE submissions SET 
                    agent_binary = $1,
                    binary_size = $2,
                    compile_status = 'success',
                    compile_time_ms = $3,
                    compile_error = NULL
                 WHERE agent_hash = $4",
                &[&binary, &binary_size, &compile_time_ms, &agent_hash],
            )
            .await?;

        info!(
            "Stored binary for agent {}: {} bytes, compiled in {}ms",
            &agent_hash[..16.min(agent_hash.len())],
            binary_size,
            compile_time_ms
        );

        Ok(())
    }

    /// Mark compilation as failed
    pub async fn set_compile_failed(&self, agent_hash: &str, error: &str) -> Result<()> {
        let client = self.pool.get().await?;
        client
            .execute(
                "UPDATE submissions SET 
                    compile_status = 'failed',
                    compile_error = $1
                 WHERE agent_hash = $2",
                &[&error, &agent_hash],
            )
            .await?;
        Ok(())
    }

    /// Update LLM review status
    pub async fn set_llm_review_result(
        &self,
        agent_hash: &str,
        approved: bool,
        flagged: bool,
        reason: Option<&str>,
    ) -> Result<()> {
        let client = self.pool.get().await?;
        client
            .execute(
                "UPDATE submissions SET 
                    llm_approved = $1,
                    flagged = $2,
                    flag_reason = $3
                 WHERE agent_hash = $4",
                &[&approved, &flagged, &reason, &agent_hash],
            )
            .await?;
        Ok(())
    }

    /// Get binary for an agent (used by validators when claiming jobs)
    pub async fn get_binary(&self, agent_hash: &str) -> Result<Option<Vec<u8>>> {
        let client = self.pool.get().await?;
        let row = client
            .query_opt(
                "SELECT agent_binary FROM submissions 
                 WHERE agent_hash = $1 AND compile_status = 'success'",
                &[&agent_hash],
            )
            .await?;

        Ok(row.and_then(|r| r.get::<_, Option<Vec<u8>>>(0)))
    }

    /// Check if agent is ready for evaluation (compiled + approved or flagged for manual review)
    pub async fn is_agent_ready(&self, agent_hash: &str) -> Result<(bool, String)> {
        let client = self.pool.get().await?;
        let row = client
            .query_opt(
                "SELECT compile_status, llm_approved, flagged, compile_error
                 FROM submissions WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await?;

        match row {
            None => Ok((false, "Agent not found".to_string())),
            Some(r) => {
                let compile_status: String = r.get(0);
                let llm_approved: bool = r.get(1);
                let flagged: bool = r.get(2);
                let compile_error: Option<String> = r.get(3);

                if compile_status == "pending" {
                    return Ok((false, "Compilation pending".to_string()));
                }
                if compile_status == "compiling" {
                    return Ok((false, "Compilation in progress".to_string()));
                }
                if compile_status == "failed" {
                    return Ok((
                        false,
                        format!("Compilation failed: {}", compile_error.unwrap_or_default()),
                    ));
                }
                if !llm_approved && !flagged {
                    return Ok((false, "LLM review pending".to_string()));
                }

                // Ready if compiled successfully AND (approved OR flagged for manual review)
                Ok((true, "Ready for evaluation".to_string()))
            }
        }
    }

    /// Get agents pending compilation
    pub async fn get_pending_compilations(&self, limit: i32) -> Result<Vec<(String, String)>> {
        let client = self.pool.get().await?;
        let rows = client
            .query(
                "SELECT agent_hash, source_code FROM submissions 
                 WHERE compile_status = 'pending'
                 ORDER BY created_at ASC
                 LIMIT $1",
                &[&(limit as i64)],
            )
            .await
            .map_err(|e| {
                error!("Failed to get pending compilations: {}. Make sure migration 006_agent_binary.sql has been applied.", e);
                e
            })?;

        Ok(rows.into_iter().map(|r| (r.get(0), r.get(1))).collect())
    }

    /// Approve flagged agent manually (subnet owner only)
    pub async fn approve_flagged_agent(&self, agent_hash: &str) -> Result<()> {
        let client = self.pool.get().await?;
        client
            .execute(
                "UPDATE submissions SET 
                    llm_approved = TRUE,
                    flagged = FALSE
                 WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await?;
        info!(
            "Manually approved agent {}",
            &agent_hash[..16.min(agent_hash.len())]
        );
        Ok(())
    }

    /// Reject flagged agent manually (subnet owner only)
    pub async fn reject_flagged_agent(&self, agent_hash: &str, reason: &str) -> Result<()> {
        let client = self.pool.get().await?;
        client
            .execute(
                "UPDATE submissions SET 
                    status = 'rejected',
                    flag_reason = $1
                 WHERE agent_hash = $2",
                &[&reason, &agent_hash],
            )
            .await?;
        info!(
            "Rejected agent {}: {}",
            &agent_hash[..16.min(agent_hash.len())],
            reason
        );
        Ok(())
    }

    // ========================================================================
    // PUBLIC API METHODS (No sensitive data exposed)
    // ========================================================================

    /// Get all pending submissions (public view - no source code, no API key, no binary)
    pub async fn get_pending_submissions_public(
        &self,
        limit: i64,
    ) -> Result<Vec<PublicSubmissionInfo>> {
        let client = self.pool.get().await?;
        let rows = client
            .query(
                "SELECT s.agent_hash, s.miner_hotkey, s.name, s.version, s.epoch, s.status,
                        s.compile_status, s.llm_approved, s.flagged,
                        EXTRACT(EPOCH FROM s.created_at)::BIGINT,
                        p.validators_completed, p.total_validators,
                        EXTRACT(EPOCH FROM p.window_expires_at)::BIGINT
                 FROM submissions s
                 LEFT JOIN pending_evaluations p ON p.agent_hash = s.agent_hash
                 WHERE s.status IN ('pending', 'evaluating') 
                    OR p.status IN ('pending', 'evaluating')
                 ORDER BY s.created_at DESC
                 LIMIT $1",
                &[&limit],
            )
            .await?;

        Ok(rows
            .iter()
            .map(|r| PublicSubmissionInfo {
                agent_hash: r.get(0),
                miner_hotkey: r.get(1),
                name: r.get(2),
                version: r.get(3),
                epoch: r.get(4),
                status: r.get(5),
                compile_status: r.get(6),
                llm_approved: r.get(7),
                flagged: r.get(8),
                created_at: r.get(9),
                validators_completed: r.get::<_, Option<i32>>(10).unwrap_or(0),
                total_validators: r.get::<_, Option<i32>>(11).unwrap_or(0),
                window_expires_at: r.get(12),
            })
            .collect())
    }

    /// Get validator assignments for an agent (public)
    pub async fn get_agent_assignments_public(
        &self,
        agent_hash: &str,
    ) -> Result<Vec<PublicAssignment>> {
        let client = self.pool.get().await?;
        let rows = client
            .query(
                "SELECT va.validator_hotkey, 
                        CASE WHEN ve.id IS NOT NULL THEN 'completed'
                             WHEN vc.status = 'claimed' THEN 'in_progress'
                             ELSE 'pending' END as eval_status,
                        ve.score::FLOAT8,
                        ve.tasks_passed,
                        ve.tasks_total,
                        EXTRACT(EPOCH FROM va.assigned_at)::BIGINT,
                        EXTRACT(EPOCH FROM ve.created_at)::BIGINT
                 FROM validator_assignments va
                 LEFT JOIN validator_evaluations ve 
                    ON ve.agent_hash = va.agent_hash AND ve.validator_hotkey = va.validator_hotkey
                 LEFT JOIN validator_claims vc 
                    ON vc.agent_hash = va.agent_hash AND vc.validator_hotkey = va.validator_hotkey
                 WHERE va.agent_hash = $1
                 ORDER BY va.assigned_at ASC",
                &[&agent_hash],
            )
            .await?;

        Ok(rows
            .iter()
            .map(|r| PublicAssignment {
                validator_hotkey: r.get(0),
                status: r.get(1),
                score: r.get(2),
                tasks_passed: r.get(3),
                tasks_total: r.get(4),
                assigned_at: r.get(5),
                completed_at: r.get(6),
            })
            .collect())
    }

    /// Get all assignments across all pending agents (public dashboard view)
    pub async fn get_all_assignments_public(
        &self,
        limit: i64,
    ) -> Result<Vec<PublicAgentAssignments>> {
        let client = self.pool.get().await?;

        // Get pending agents first
        let pending = client
            .query(
                "SELECT p.agent_hash, p.miner_hotkey, s.name, p.status,
                        p.validators_completed, p.total_validators,
                        EXTRACT(EPOCH FROM p.window_expires_at)::BIGINT,
                        EXTRACT(EPOCH FROM p.created_at)::BIGINT
                 FROM pending_evaluations p
                 JOIN submissions s ON s.agent_hash = p.agent_hash
                 WHERE p.status IN ('pending', 'evaluating')
                 ORDER BY p.created_at DESC
                 LIMIT $1",
                &[&limit],
            )
            .await?;

        let mut results = Vec::new();
        for row in pending {
            let agent_hash: String = row.get(0);
            let assignments = self
                .get_agent_assignments_public(&agent_hash)
                .await
                .unwrap_or_default();

            results.push(PublicAgentAssignments {
                agent_hash,
                miner_hotkey: row.get(1),
                name: row.get(2),
                status: row.get(3),
                validators_completed: row.get(4),
                total_validators: row.get(5),
                window_expires_at: row.get(6),
                created_at: row.get(7),
                assignments,
            });
        }

        Ok(results)
    }
}

/// Public submission info (no sensitive data)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PublicSubmissionInfo {
    pub agent_hash: String,
    pub miner_hotkey: String,
    pub name: Option<String>,
    pub version: i32,
    pub epoch: i64,
    pub status: String,
    pub compile_status: String,
    pub llm_approved: bool,
    pub flagged: bool,
    pub created_at: i64,
    pub validators_completed: i32,
    pub total_validators: i32,
    pub window_expires_at: Option<i64>,
}

/// Public assignment info (no sensitive data)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PublicAssignment {
    pub validator_hotkey: String,
    pub status: String,
    pub score: Option<f64>,
    pub tasks_passed: Option<i32>,
    pub tasks_total: Option<i32>,
    pub assigned_at: Option<i64>,
    pub completed_at: Option<i64>,
}

/// Public agent with all assignments
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PublicAgentAssignments {
    pub agent_hash: String,
    pub miner_hotkey: String,
    pub name: Option<String>,
    pub status: String,
    pub validators_completed: i32,
    pub total_validators: i32,
    pub window_expires_at: Option<i64>,
    pub created_at: i64,
    pub assignments: Vec<PublicAssignment>,
}

// =============================================================================
// SUDO Operations
// =============================================================================

impl PgStorage {
    /// Reset validator assignments for an agent (SUDO: relaunch evaluation)
    pub async fn reset_agent_assignments(&self, agent_hash: &str) -> Result<()> {
        let client = self
            .pool
            .get()
            .await
            .map_err(|e| anyhow::anyhow!("Failed to get db connection: {}", e))?;

        // Delete existing evaluations first (foreign key constraint)
        client
            .execute(
                "DELETE FROM validator_evaluations WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await
            .map_err(|e| anyhow::anyhow!("Failed to delete evaluations: {}", e))?;

        // Delete existing assignments
        client
            .execute(
                "DELETE FROM validator_assignments WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await
            .map_err(|e| anyhow::anyhow!("Failed to delete assignments: {}", e))?;

        // Reset submission status to pending and clear pending_evaluations
        client
            .execute(
                "UPDATE submissions SET status = 'pending' WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await
            .map_err(|e| anyhow::anyhow!("Failed to update submission status: {}", e))?;

        client
            .execute(
                "UPDATE pending_evaluations SET status = 'pending', validators_completed = 0 WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await
            .map_err(|e| anyhow::anyhow!("Failed to reset pending_evaluations: {}", e))?;

        // Re-assign validators (get from default selection)
        let validators = self
            .get_active_validators(3)
            .await
            .map_err(|e| anyhow::anyhow!("Failed to get validators: {}", e))?;

        if validators.is_empty() {
            warn!(
                "No validators available for assignment, agent {} will wait for validators",
                agent_hash
            );
        }

        for validator in validators {
            client
                .execute(
                    "INSERT INTO validator_assignments (agent_hash, validator_hotkey, status, assigned_at)
                     VALUES ($1, $2, 'pending', NOW())",
                    &[&agent_hash, &validator],
                )
                .await
                .map_err(|e| anyhow::anyhow!("Failed to insert assignment for {}: {}", validator, e))?;
        }

        info!("Reset assignments for agent {}", agent_hash);
        Ok(())
    }

    /// Approve a flagged agent (SUDO)
    pub async fn sudo_approve_agent(&self, agent_hash: &str) -> Result<()> {
        let client = self.pool.get().await?;

        client
            .execute(
                "UPDATE submissions SET llm_approved = true, flagged = false, status = 'approved' 
                 WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await?;

        // Assign validators if not already assigned
        let existing: i64 = client
            .query_one(
                "SELECT COUNT(*) FROM validator_assignments WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await?
            .get(0);

        if existing == 0 {
            let validators = self.get_active_validators(3).await?;
            for validator in validators {
                client
                    .execute(
                        "INSERT INTO validator_assignments (agent_hash, validator_hotkey, status, assigned_at)
                         VALUES ($1, $2, 'pending', NOW())",
                        &[&agent_hash, &validator],
                    )
                    .await?;
            }
        }

        info!("SUDO approved agent {}", agent_hash);
        Ok(())
    }

    /// Reject an agent (SUDO)
    pub async fn sudo_reject_agent(&self, agent_hash: &str) -> Result<()> {
        let client = self.pool.get().await?;

        client
            .execute(
                "UPDATE submissions SET status = 'rejected', flagged = true, flag_reason = 'Rejected by subnet owner'
                 WHERE agent_hash = $1",
                &[&agent_hash],
            )
            .await?;

        // Remove any pending assignments
        client
            .execute(
                "DELETE FROM validator_assignments WHERE agent_hash = $1 AND status = 'pending'",
                &[&agent_hash],
            )
            .await?;

        info!("SUDO rejected agent {}", agent_hash);
        Ok(())
    }

    /// Set agent status (SUDO)
    pub async fn sudo_set_status(
        &self,
        agent_hash: &str,
        status: &str,
        reason: Option<&str>,
    ) -> Result<()> {
        let client = self.pool.get().await?;

        if let Some(reason) = reason {
            client
                .execute(
                    "UPDATE submissions SET status = $1, flag_reason = $2 WHERE agent_hash = $3",
                    &[&status, &reason, &agent_hash],
                )
                .await?;
        } else {
            client
                .execute(
                    "UPDATE submissions SET status = $1 WHERE agent_hash = $2",
                    &[&status, &agent_hash],
                )
                .await?;
        }

        info!("SUDO set agent {} status to {}", agent_hash, status);
        Ok(())
    }

    /// Get active validators (for assignment)
    async fn get_active_validators(&self, count: usize) -> Result<Vec<String>> {
        // In production, this would query metagraph for active validators
        // For now, return validators from existing assignments or env
        let validators_env = std::env::var("VALIDATOR_WHITELIST").unwrap_or_default();
        let validators: Vec<String> = validators_env
            .split(',')
            .map(|s| s.trim().to_string())
            .filter(|s| !s.is_empty())
            .take(count)
            .collect();

        if validators.is_empty() {
            // Fallback: get from existing assignments
            let client = self.pool.get().await?;
            let rows = client
                .query(
                    "SELECT DISTINCT validator_hotkey FROM validator_assignments LIMIT $1",
                    &[&(count as i64)],
                )
                .await?;

            return Ok(rows.iter().map(|r| r.get(0)).collect());
        }

        Ok(validators)
    }
}
