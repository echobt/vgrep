<div align="center">

# Î½grÎµp

**Local semantic code search**

[![CI](https://github.com/CortexLM/vgrep/actions/workflows/ci.yml/badge.svg)](https://github.com/CortexLM/vgrep/actions/workflows/ci.yml)
[![License](https://img.shields.io/github/license/CortexLM/vgrep)](https://github.com/CortexLM/vgrep/blob/main/LICENSE)
[![GitHub stars](https://img.shields.io/github/stars/CortexLM/vgrep)](https://github.com/CortexLM/vgrep/stargazers)
[![Rust](https://img.shields.io/badge/rust-1.75+-orange.svg)](https://www.rust-lang.org/)

<pre>
â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— 
â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â• â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—
â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
â•šâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â•â• 
 â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘     
  â•šâ•â•â•â•   â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•     
</pre>

**Search code by meaning, not just keywords. 100% offline. Zero cloud dependencies.**

</div>

---

## Installation

```bash
curl -fsSL https://vgrep.dev/install.sh | sh
```

Or with wget:

```bash
wget -qO- https://vgrep.dev/install.sh | sh
```

After installation, initialize vgrep:

```bash
vgrep init
vgrep models download
```

---

## Introduction

**Î½grÎµp** is a semantic code search tool that uses local LLM embeddings to find code by intent rather than exact text matches. Unlike traditional grep which searches for literal strings, Î½grÎµp understands the *meaning* behind your query and finds semantically related code across your entire codebase.

> **Quick Start**: `vgrep init && vgrep serve` then `vgrep "where is authentication handled?"`

### Key Features

- **Semantic Search**: Find code by intent - search "error handling" to find try/catch blocks, Result types, and exception handlers
- **100% Local**: All processing happens on your machine using llama.cpp - no API keys, no cloud, your code stays private
- **Server Mode**: Keep models loaded in memory for instant sub-100ms searches
- **File Watcher**: Automatically re-index files as they change
- **Cross-Platform**: Native binaries for Windows, Linux, and macOS
- **GPU Acceleration**: Optional CUDA, Metal, and Vulkan support for faster embeddings

---

## System Overview

Î½grÎµp uses a client-server architecture optimized for fast repeated searches:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              USER QUERIES                                    â”‚
â”‚                        "where is auth handled?"                              â”‚
â”‚                        "database connection logic"                           â”‚
â”‚                        "error handling patterns"                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            Î½grÎµp CLIENT                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   Search    â”‚  â”‚    Index    â”‚  â”‚    Watch    â”‚  â”‚   Config    â”‚        â”‚
â”‚  â”‚  Command    â”‚  â”‚   Command   â”‚  â”‚   Command   â”‚  â”‚   Editor    â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚ HTTP API
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            Î½grÎµp SERVER                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    Embedding Engine (llama.cpp)                       â”‚  â”‚
â”‚  â”‚              Qwen3-Embedding-0.6B â€¢ Always Loaded â€¢ Fast              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                     SQLite Vector Database                            â”‚  â”‚
â”‚  â”‚         File Hashes â€¢ Code Chunks â€¢ Embeddings â€¢ Metadata             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Processing Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Source  â”‚â”€â”€â”€â–¶â”‚  Chunk   â”‚â”€â”€â”€â–¶â”‚  Embed   â”‚â”€â”€â”€â–¶â”‚  Store   â”‚â”€â”€â”€â–¶â”‚  Search  â”‚
â”‚  Files   â”‚    â”‚  (512b)  â”‚    â”‚  (LLM)   â”‚    â”‚ (SQLite) â”‚    â”‚ (Cosine) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚               â”‚               â”‚               â”‚               â”‚
     â–¼               â–¼               â–¼               â–¼               â–¼
  .rs .py        Split into      Generate       Vector DB       Similarity
  .js .ts        overlapping     768-dim        with fast       ranking +
  .go .c         text chunks     vectors        retrieval       results
```

---

## Installation

### From Source

```bash
# Prerequisites: Rust 1.75+, LLVM/Clang, CMake
git clone https://github.com/CortexLM/vgrep.git
cd vgrep
cargo build --release

# Binary at target/release/vgrep
```

### GPU Acceleration

```bash
cargo build --release --features cuda    # NVIDIA GPUs
cargo build --release --features metal   # Apple Silicon
cargo build --release --features vulkan  # Cross-platform GPU
```

### System Requirements

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| RAM | 2 GB | 4+ GB |
| Disk | 1 GB (models) | 2+ GB |
| CPU | 4 cores | 8+ cores |
| GPU | Optional | CUDA/Metal for 10x speedup |

---

## Quick Start

### 1. Initialize

```bash
# Download models and create config (~1GB download)
vgrep init
vgrep models download
```

### 2. Start Server

```bash
# Keep this running - loads model once for fast searches
vgrep serve
```

Output:
```
  >>> vgrep server
  Server: http://127.0.0.1:7777
  
  Loading embedding model...
  Model loaded successfully!
  
  Endpoints:
    â€¢ GET  /health   - Health check
    â€¢ GET  /status   - Index status
    â€¢ POST /search   - Semantic search
    â€¢ POST /embed    - Generate embeddings
  
  â†’ Press Ctrl+C to stop
```

### 3. Index & Watch

```bash
# In another terminal - index and auto-update on changes
vgrep watch
```

Output:
```
  >>> vgrep watcher
  Path: /home/user/myproject
  Mode: server

  Ctrl+C to stop

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  >> Initial indexing...
  Phase 1: Reading files...
    Read 45 files, 312 chunks
  Phase 2: Generating embeddings via server...
    Generated 312 embeddings
  Phase 3: Storing in database...
    Stored 45 files

  Indexing complete!
    Files: 45 indexed, 12 skipped
    Chunks: 312

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  [~] Watching for changes...

  [+] indexed auth.rs
  [+] indexed db.rs
```

### 4. Search

```bash
# Semantic search - finds by meaning
vgrep "where is authentication handled?"
vgrep "database connection pooling"
vgrep "error handling for network requests"
```

Output:
```
  Searching for: where is authentication handled?

  1. ./src/auth/middleware.rs (87.3%)
  2. ./src/handlers/login.rs (82.1%)
  3. ./src/utils/jwt.rs (76.8%)
  4. ./src/config/security.rs (71.2%)

  â†’ Found 4 results in 45ms
```

---

## Commands

### Search

| Command | Description |
|---------|-------------|
| `vgrep "query"` | Quick semantic search |
| `vgrep search "query" -m 20` | Search with max 20 results |
| `vgrep search "query" -c` | Show code snippets in results |
| `vgrep search "query" --sync` | Re-index before searching |

### Server & Indexing

| Command | Description |
|---------|-------------|
| `vgrep serve` | Start server (keeps model loaded) |
| `vgrep serve -p 8080` | Custom port |
| `vgrep index` | Manual one-time index |
| `vgrep index --force` | Force re-index all files |
| `vgrep watch` | Watch and auto-index on changes |
| `vgrep status` | Show index statistics |

### Configuration

| Command | Description |
|---------|-------------|
| `vgrep config` | Interactive configuration editor |
| `vgrep config show` | Display all settings |
| `vgrep config set mode local` | Set config value |
| `vgrep config reset` | Reset to defaults |

### Models

| Command | Description |
|---------|-------------|
| `vgrep init` | Initialize vgrep |
| `vgrep models download` | Download embedding models |
| `vgrep models list` | Show configured models |

---

## Agent Integrations

Î½grÎµp supports assisted installation for popular coding agents:

```bash
vgrep install <agent>     # Install integration
vgrep uninstall <agent>   # Remove integration
```

| Agent | Command |
|-------|---------|
| Claude Code | `vgrep install claude-code` |
| OpenCode | `vgrep install opencode` |
| Codex | `vgrep install codex` |
| Factory Droid | `vgrep install droid` |

### Usage with Claude Code

```bash
vgrep install claude-code
vgrep serve   # Start server
vgrep watch   # Index your project
# Claude Code can now use vgrep for semantic search
```

### Usage with Factory Droid

```bash
vgrep install droid
# vgrep auto-starts when you begin a Droid session
```

To uninstall: `vgrep uninstall <agent>` (e.g., `vgrep uninstall droid`).

---

## How It Works

### Embedding Generation

Î½grÎµp converts code into high-dimensional vectors that capture semantic meaning:

```
Input:  "fn authenticate(user: &str, pass: &str) -> Result<Token>"
        â†“
        Tokenize â†’ Qwen3-Embedding â†’ Normalize
        â†“
Output: [0.023, -0.156, 0.891, ..., 0.045]  (768 dimensions)
```

### Similarity Search

Queries are embedded and compared using cosine similarity:

$$\text{similarity}(q, d) = \frac{q \cdot d}{\|q\| \|d\|} = \frac{\sum_{i=1}^{n} q_i d_i}{\sqrt{\sum_{i=1}^{n} q_i^2} \sqrt{\sum_{i=1}^{n} d_i^2}}$$

Where:
- $q$ = query embedding vector
- $d$ = document (code chunk) embedding vector
- Result in range $[-1, 1]$, higher = more similar

### Chunking Strategy

Files are split into overlapping chunks for granular search:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Source File                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Chunk 1 (512 chars)                                 â”‚
â”‚          â”œâ”€â”€ Overlap (64 chars) â”€â”€â”¤                â”‚
â”‚                    Chunk 2 (512 chars)              â”‚
â”‚                             â”œâ”€â”€ Overlap â”€â”€â”¤        â”‚
â”‚                                      Chunk 3 ...    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **Chunk Size**: 512 characters (configurable)
- **Overlap**: 64 characters to preserve context at boundaries
- **Deduplication**: Results grouped by file, best chunk shown

---

## Configuration

### Config Location

| Platform | Path |
|----------|------|
| Linux | `~/.vgrep/config.json` |
| macOS | `~/.vgrep/config.json` |
| Windows | `C:\Users\<user>\.vgrep\config.json` |

### Settings

| Setting | Default | Description |
|---------|---------|-------------|
| `mode` | `server` | `server` (recommended) or `local` |
| `server_host` | `127.0.0.1` | Server bind address |
| `server_port` | `7777` | Server port |
| `max_results` | `10` | Default search results |
| `max_file_size` | `524288` | Max file size to index (512KB) |
| `chunk_size` | `512` | Characters per chunk |
| `chunk_overlap` | `64` | Overlap between chunks |
| `n_threads` | `0` | CPU threads (0 = auto) |
| `use_reranker` | `true` | Enable result reranking |

### Environment Variables

All settings can be overridden via environment:

```bash
VGREP_HOST=0.0.0.0      # Bind to all interfaces
VGREP_PORT=8080         # Custom port
VGREP_MAX_RESULTS=20    # More results
VGREP_CONTENT=true      # Always show snippets
```

---

## Server API

Î½grÎµp server exposes a REST API for programmatic access:

### Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | Health check |
| `/status` | GET | Index statistics |
| `/search` | POST | Semantic search |
| `/embed` | POST | Generate single embedding |
| `/embed_batch` | POST | Batch embeddings |

### Search Example

```bash
curl -X POST http://127.0.0.1:7777/search \
  -H 'Content-Type: application/json' \
  -d '{
    "query": "authentication middleware",
    "max_results": 5
  }'
```

Response:
```json
{
  "results": [
    {
      "path": "/project/src/auth/middleware.rs",
      "score": 0.873,
      "score_percent": "87.3%",
      "preview": "pub async fn auth_middleware...",
      "start_line": 15,
      "end_line": 45
    }
  ],
  "query": "authentication middleware",
  "total": 1
}
```

---

## Project Structure

```
vgrep/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cli/              # Command-line interface
â”‚   â”‚   â”œâ”€â”€ commands.rs   # CLI argument handling
â”‚   â”‚   â””â”€â”€ interactive.rs # Config editor
â”‚   â”œâ”€â”€ core/             # Core functionality
â”‚   â”‚   â”œâ”€â”€ db.rs         # SQLite vector storage
â”‚   â”‚   â”œâ”€â”€ embeddings.rs # llama.cpp integration
â”‚   â”‚   â”œâ”€â”€ indexer.rs    # File chunking & indexing
â”‚   â”‚   â””â”€â”€ search.rs     # Similarity search
â”‚   â”œâ”€â”€ server/           # HTTP server
â”‚   â”‚   â”œâ”€â”€ api.rs        # Axum endpoints
â”‚   â”‚   â””â”€â”€ client.rs     # HTTP client
â”‚   â”œâ”€â”€ ui/               # User interface
â”‚   â”‚   â”œâ”€â”€ console.rs    # Colored output
â”‚   â”‚   â””â”€â”€ search_tui.rs # Interactive TUI
â”‚   â”œâ”€â”€ config.rs         # Configuration
â”‚   â”œâ”€â”€ watcher.rs        # File system watcher
â”‚   â”œâ”€â”€ lib.rs            # Library root
â”‚   â””â”€â”€ main.rs           # Entry point
â”œâ”€â”€ tests/                # Integration tests
â”œâ”€â”€ .github/
â”‚   â”œâ”€â”€ workflows/        # CI/CD (test, build, release)
â”‚   â””â”€â”€ hooks/            # Git hooks (pre-commit, pre-push)
â””â”€â”€ scripts/              # Development utilities
```

---

## Models

Î½grÎµp uses quantized models from HuggingFace for efficient local inference:

| Model | Size | Purpose |
|-------|------|---------|
| Qwen3-Embedding-0.6B-Q8_0 | ~600 MB | Text â†’ Vector embeddings |
| Qwen3-Reranker-0.6B-Q4_K_M | ~400 MB | Result reranking (optional) |

Models are downloaded to `~/.cache/huggingface/` and cached automatically.

---

## Performance


### Optimization Tips

1. **Use Server Mode**: 10-50x faster than local mode for repeated searches
2. **Enable GPU**: CUDA/Metal provides 5-10x speedup for embedding generation
3. **Watch Mode**: Auto-indexes only changed files, not entire codebase
4. **Tune Chunk Size**: Larger chunks = fewer embeddings but less granular results

---

## Development

### Setup

```bash
# Clone with submodules (llama.cpp)
git clone https://github.com/CortexLM/vgrep.git
cd vgrep

# Setup git hooks
./scripts/setup-hooks.sh   # Unix
./scripts/setup-hooks.ps1  # Windows

# Build
cargo build

# Test
cargo test

# Lint
cargo clippy --all-targets --all-features
cargo fmt --check
```

### Git Hooks

Pre-commit and pre-push hooks ensure code quality:

| Hook | Checks |
|------|--------|
| `pre-commit` | Format, Clippy, Tests |
| `pre-push` | Full test suite, Release build |

Enable with: `git config core.hooksPath .github/hooks`

---

## Comparison

### vs Traditional Grep

| Feature | grep/ripgrep | Î½grÎµp |
|---------|-------------|-------|
| Search type | Exact text / regex | Semantic meaning |
| "auth" finds "authentication" | âŒ | âœ… |
| "error handling" finds try/catch | âŒ | âœ… |
| Speed | Instant | 30-100ms |
| Setup | None | Model download |

### vs Cloud Semantic Search (mgrep, etc.)

| Feature | Cloud Tools | Î½grÎµp |
|---------|-------------|-------|
| Privacy | Code sent to servers | 100% local |
| Cost | API fees | Free |
| Offline | âŒ | âœ… |
| Latency | 200-500ms | 30-100ms |
| Rate limits | Yes | None |

---

## Troubleshooting

### Server won't start

```bash
# Check if port is in use
netstat -an | grep 7777

# Try different port
vgrep serve -p 8080
```

### Slow indexing

```bash
# Use server mode for batch embeddings
vgrep serve &
vgrep index
```

### Model download fails

```bash
# Manual download
vgrep models download --force

# Check disk space
df -h ~/.cache/huggingface
```

### Out of memory

```bash
# Reduce threads
vgrep config set n-threads 2

# Use quantized model (default)
```

---

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md) for development guidelines.

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing`)
3. Run tests (`cargo test`)
4. Run lints (`cargo fmt && cargo clippy`)
5. Submit Pull Request

---

## License

Apache 2.0 - see [LICENSE](LICENSE)

---

<div align="center">

**Î½grÎµp** - *Search code by meaning*

Built with ğŸ¦€ Rust and powered by [llama.cpp](https://github.com/ggerganov/llama.cpp)

[Report Bug](https://github.com/CortexLM/vgrep/issues) Â· [Request Feature](https://github.com/CortexLM/vgrep/issues)

</div>
