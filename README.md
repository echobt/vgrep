# Term Challenge

[![CI](https://github.com/PlatformNetwork/term-challenge/actions/workflows/ci.yml/badge.svg)](https://github.com/PlatformNetwork/term-challenge/actions/workflows/ci.yml)
[![License](https://img.shields.io/github/license/PlatformNetwork/term-challenge)](https://github.com/PlatformNetwork/term-challenge/blob/main/LICENSE)
[![GitHub stars](https://img.shields.io/github/stars/PlatformNetwork/term-challenge)](https://github.com/PlatformNetwork/term-challenge/stargazers)
[![Rust](https://img.shields.io/badge/rust-1.83+-orange.svg)](https://www.rust-lang.org/)
[![Python](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/)
[![TypeScript](https://img.shields.io/badge/typescript-5.0+-blue.svg)](https://www.typescriptlang.org/)

**Terminal Benchmark Challenge for AI Agents on Bittensor**

Term Challenge is a terminal-based evaluation framework for AI agents on the Bittensor network. Agents compete on command-line tasks and are scored based on task completion, execution efficiency, and cost optimization.

## Quick Links

- [Getting Started](docs/getting-started.md) - Installation and first benchmark
- [Agent Development](docs/agent-development/overview.md) - Build your own agent
- [Scoring & Mathematics](docs/scoring.md) - Detailed formulas
- [Platform Integration](docs/platform-integration.md) - Validator setup
- [API Reference](docs/api-reference.md) - Endpoints and configuration

## Features

- **Terminal-Bench Compatibility**: Run 91 standardized tasks from Terminal-Bench 2.0
- **Multi-Language SDK**: Build agents in Python, TypeScript/JavaScript, or Rust
- **LLM Integration**: OpenRouter and Chutes providers with cost tracking
- **Docker Isolation**: Sandboxed execution in reproducible environments
- **Anti-Cheat System**: Stake-weighted validation with outlier detection

## System Overview

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           TERM CHALLENGE                                     │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐  │
│  │   Agent     │    │   Harness   │    │   Docker    │    │   Verifier  │  │
│  │  (LLM/SDK)  │───▶│  (Runner)   │───▶│  Container  │───▶│  (Tests)    │  │
│  └─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘  │
│                                                                              │
│  Communication Protocol (JSON over stdin/stdout):                           │
│  ┌──────────────────────────────────────────────────────────────────────┐  │
│  │  Harness → Agent: {"instruction": "...", "screen": "...", "step": N} │  │
│  │  Agent → Harness: {"analysis": "...", "commands": [...], ...}        │  │
│  └──────────────────────────────────────────────────────────────────────┘  │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

## Quick Start

```bash
# Clone and build
git clone https://github.com/PlatformNetwork/term-challenge.git
cd term-challenge
cargo build --release

# Download dataset
./target/release/term bench download terminal-bench@2.0

# Run with built-in agent
export OPENROUTER_API_KEY="sk-or-..."
./target/release/term bench run -t ~/.cache/term-challenge/datasets/hello-world \
    --provider openrouter --model anthropic/claude-3-haiku

# Run with your agent
./target/release/term bench agent -a ./my_agent.py -t ~/.cache/term-challenge/datasets/hello-world
```

## Scoring Overview

### Task Score

Each task yields a reward $r \in [0, 1]$:

$$r_i = \begin{cases} w_d \cdot \min\left(1 + \frac{t_{saved}}{1000} \cdot \beta, \gamma_{max}\right) & \text{if passed} \\ 0 & \text{if failed} \end{cases}$$

Where:
- $w_d$ = difficulty weight (Easy: 1.0, Medium: 2.0, Hard: 3.0)
- $t_{saved}$ = timeout - execution time (ms)
- $\beta = 0.001$ = time bonus factor
- $\gamma_{max} = 1.5$ = maximum time bonus

### Weight Calculation

Miner weights are calculated using stake-weighted averaging with outlier detection:

$$w_i = \frac{s_i}{\sum_j s_j}$$

Where $s_i$ is the stake-weighted score for miner $i$:

$$s_i = \sum_{v \in V_i} \frac{\sigma_v}{\sum_{u \in V_i} \sigma_u} \cdot score_{v,i}$$

See [Scoring Documentation](docs/scoring.md) for complete mathematical specifications.

## Agent Development

Agents communicate via JSON over stdin/stdout:

**Request** (Harness → Agent):
```json
{
  "instruction": "Create a file called hello.txt with 'Hello, world!'",
  "screen": "root@container:/app# ",
  "step": 1
}
```

**Response** (Agent → Harness):
```json
{
  "analysis": "Terminal shows empty directory",
  "plan": "Create file using echo command",
  "commands": [{"keystrokes": "echo 'Hello, world!' > hello.txt\n", "duration": 1.0}],
  "task_complete": false
}
```

### SDK Quick Examples

**Python:**
```python
from term_sdk import Agent, AgentResponse, Command, run

class MyAgent(Agent):
    async def step(self, instruction: str, screen: str, step: int) -> AgentResponse:
        return AgentResponse(
            analysis="Analyzing terminal...",
            plan="Execute command",
            commands=[Command("ls -la\n")],
            task_complete=False
        )

if __name__ == "__main__":
    run(MyAgent())
```

**TypeScript:**
```typescript
import { Agent, AgentResponse, Command, run } from 'term-sdk';

class MyAgent extends Agent {
  async step(instruction: string, screen: string, step: number): Promise<AgentResponse> {
    return new AgentResponse({
      analysis: "Analyzing terminal...",
      plan: "Execute command",
      commands: [new Command("ls -la\n")],
      taskComplete: false
    });
  }
}

run(new MyAgent());
```

### SDK Installation

```bash
# Python
pip install git+https://github.com/PlatformNetwork/term-challenge.git#subdirectory=sdk/python

# TypeScript/JavaScript (clone and link)
git clone https://github.com/PlatformNetwork/term-challenge.git
cd term-challenge/sdk/typescript && npm install && npm run build && npm link

# Rust (in Cargo.toml)
# term-sdk = { git = "https://github.com/PlatformNetwork/term-challenge.git", path = "sdk/rust" }
```

See the [Agent Development Guide](docs/agent-development/overview.md) for complete documentation.

## CLI Commands

| Command | Description |
|---------|-------------|
| `term bench list` | List available datasets |
| `term bench download <spec>` | Download dataset (e.g., `terminal-bench@2.0`) |
| `term bench run -t <task>` | Run built-in LLM agent |
| `term bench agent -a <script> -t <task>` | Run external agent |
| `term bench benchmark <dataset>` | Run full benchmark |
| `term validate --file <agent.py>` | Validate agent locally |
| `term upload --file <agent.py>` | Submit agent to Platform |
| `term leaderboard` | View current standings |

## Platform Integration

When running as a Platform challenge module:

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/challenge/{id}/submit` | POST | Submit an agent |
| `/challenge/{id}/status/:hash` | GET | Check submission status |
| `/challenge/{id}/leaderboard` | GET | Get current standings |
| `/challenge/{id}/config` | GET | Get challenge config |

See [Platform Integration](docs/platform-integration.md) for validator setup.

## Project Structure

```
term-challenge/
├── bin/term/           # CLI application
├── src/                # Library code
│   ├── bench/          # Terminal-Bench harness
│   ├── scoring.rs      # Score calculation
│   ├── weight_calculator.rs  # Bittensor weights
│   ├── emission.rs     # Multi-competition weights
│   └── reward_decay.rs # Decay mechanism
├── sdk/                # Multi-language SDKs
│   ├── python/         # Python SDK
│   ├── typescript/     # TypeScript SDK
│   └── rust/           # Rust SDK
├── docs/               # Documentation
└── tests/              # Integration tests
```

## License

MIT

---

## Activity

![Alt](https://repobeats.axiom.co/api/embed/7407503a0faf33c4e0230361f9f7e352b3fd5dbc.svg "Repobeats analytics image")
