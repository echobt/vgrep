#!/usr/bin/env python3
"""
Advanced Term Challenge Agent Example

Features:
- Multi-step planning with memory
- Streaming LLM responses
- Error recovery
- Cost tracking
"""

import sys
import json
import re
from dataclasses import dataclass, field

from term_sdk import Agent, Request, Response, LLM, LLMError, run


def log(msg: str):
    """Log to stderr (stdout is reserved for protocol)."""
    print(f"[agent] {msg}", file=sys.stderr)


@dataclass
class Memory:
    """Agent memory for tracking state."""
    plan: list = field(default_factory=list)
    completed_steps: list = field(default_factory=list)
    errors: list = field(default_factory=list)
    files_created: list = field(default_factory=list)


class AdvancedAgent(Agent):
    """
    Advanced agent with planning, memory, and error recovery.
    """
    
    PLANNER_PROMPT = """You are a planning AI for terminal tasks.
Given a task, create a step-by-step plan.
Output a JSON array of steps, each step being a string description.

Example:
["List current directory", "Create file hello.py", "Write Python code", "Run the script", "Verify output"]

Task: {task}

Output ONLY the JSON array, nothing else."""

    EXECUTOR_PROMPT = """You are an expert Linux terminal user.
Execute the next step of the plan.

Task: {task}
Plan: {plan}
Completed: {completed}
Current step: {current_step}
Last command: {last_command}
Exit code: {exit_code}
Output:
```
{output}
```

Respond with JSON:
{{"command": "your command here", "task_complete": false}}

If all steps are done:
{{"command": null, "task_complete": true}}

JSON response:"""

    def setup(self):
        """Initialize agent."""
        self.llm = LLM()
        self.memory = Memory()
        self.planning_done = False
        log("Advanced agent initialized")
    
    def _create_plan(self, task: str) -> list:
        """Create a plan for the task."""
        log("Creating plan...")
        
        try:
            response = self.llm.ask(
                self.PLANNER_PROMPT.format(task=task),
                model="z-ai/glm-4.5",
                temperature=0.3
            )
            
            # Parse JSON plan
            match = re.search(r'\[.*\]', response.text, re.DOTALL)
            if match:
                plan = json.loads(match.group())
                log(f"Plan created: {len(plan)} steps")
                return plan
        except (json.JSONDecodeError, LLMError) as e:
            log(f"Planning error: {e}")
        
        # Fallback: simple plan
        return ["Explore directory", "Execute task", "Verify result"]
    
    def _get_next_command(self, req: Request, current_step: str) -> Response:
        """Get command for the current step using streaming."""
        log(f"Executing step: {current_step}")
        
        prompt = self.EXECUTOR_PROMPT.format(
            task=req.instruction,
            plan=json.dumps(self.memory.plan),
            completed=json.dumps(self.memory.completed_steps),
            current_step=current_step,
            last_command=req.last_command or "None",
            exit_code=req.exit_code if req.exit_code is not None else "N/A",
            output=req.get_output(2000)  # Safe truncated access
        )
        
        try:
            # Stream response for real-time feedback
            full_text = ""
            for chunk in self.llm.stream(prompt, model="z-ai/glm-4.5"):
                full_text += chunk
                # Show progress in logs
                if len(full_text) % 50 == 0:
                    log(f"Thinking... ({len(full_text)} chars)")
            
            log(f"LLM response: {full_text[:100]}...")
            return Response.from_llm(full_text)
            
        except LLMError as e:
            log(f"LLM error: {e.code} - {e.message}")
            self.memory.errors.append(str(e))
            return Response.done()
    
    def solve(self, req: Request) -> Response:
        """Execute one step of the agent."""
        log(f"Step {req.step}: cwd={req.cwd}")
        
        # Handle errors from previous command
        if req.failed:
            log(f"Previous command failed (exit {req.exit_code})")
            self.memory.errors.append(f"Step {req.step}: {req.last_command}")
            # Try to recover
            if len(self.memory.errors) > 3:
                log("Too many errors, giving up")
                return Response.done()
        
        # First step: create plan
        if not self.planning_done:
            self.memory.plan = self._create_plan(req.instruction)
            self.planning_done = True
            # Start with exploration
            return Response.cmd("ls -la").with_text("Exploring directory...")
        
        # Check budget
        stats = self.llm.get_stats()
        if stats["total_cost"] > 1.0:
            log(f"Budget limit reached: ${stats['total_cost']:.2f}")
            return Response.done()
        
        # Get current step
        step_idx = len(self.memory.completed_steps)
        if step_idx >= len(self.memory.plan):
            log("All planned steps completed!")
            return Response.done()
        
        current_step = self.memory.plan[step_idx]
        
        # Get command for this step
        response = self._get_next_command(req, current_step)
        
        # Track completed step
        if response.command:
            self.memory.completed_steps.append(current_step)
            
            # Track file creation
            if '>' in response.command:
                match = re.search(r'>\s*(\S+)', response.command)
                if match:
                    self.memory.files_created.append(match.group(1))
        
        return response
    
    def cleanup(self):
        """Report stats."""
        stats = self.llm.get_stats()
        log("=== Agent Report ===")
        log(f"Steps: {len(self.memory.completed_steps)}/{len(self.memory.plan)}")
        log(f"Files created: {self.memory.files_created}")
        log(f"Errors: {len(self.memory.errors)}")
        log(f"Total cost: ${stats['total_cost']:.4f}")
        log(f"Total tokens: {stats['total_tokens']}")


if __name__ == "__main__":
    run(AdvancedAgent())
