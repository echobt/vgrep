//! Live Evaluation Test - Actually calls OpenRouter API
//!
//! This test makes real LLM calls to evaluate agent responses

use std::time::Instant;

fn get_api_key() -> String {
    std::env::var("OPENROUTER_API_KEY").unwrap_or_else(|_| "test-key-not-set".to_string())
}
const OPENROUTER_URL: &str = "https://openrouter.ai/api/v1/chat/completions";

/// Make a real LLM call to OpenRouter
fn call_openrouter(messages: &[serde_json::Value], model: &str) -> Result<String, String> {
    let client = reqwest::blocking::Client::new();

    let payload = serde_json::json!({
        "model": model,
        "messages": messages,
        "temperature": 0.7,
        "max_tokens": 1000
    });

    let response = client
        .post(OPENROUTER_URL)
        .header("Authorization", format!("Bearer {}", get_api_key()))
        .header("Content-Type", "application/json")
        .header("HTTP-Referer", "https://term-challenge.test")
        .json(&payload)
        .send()
        .map_err(|e| format!("Request failed: {}", e))?;

    if !response.status().is_success() {
        return Err(format!(
            "API error: {} - {}",
            response.status(),
            response.text().unwrap_or_default()
        ));
    }

    let result: serde_json::Value = response.json().map_err(|e| format!("Parse error: {}", e))?;

    let content = result["choices"][0]["message"]["content"]
        .as_str()
        .ok_or("No content in response")?
        .to_string();

    Ok(content)
}

/// Parse JSON from LLM response
fn parse_agent_response(response: &str) -> Result<serde_json::Value, String> {
    // Try to find JSON in the response
    let json_start = response.find('{').ok_or("No JSON found")?;
    let mut brace_count = 0;
    let mut json_end = json_start;

    for (i, c) in response[json_start..].chars().enumerate() {
        match c {
            '{' => brace_count += 1,
            '}' => {
                brace_count -= 1;
                if brace_count == 0 {
                    json_end = json_start + i + 1;
                    break;
                }
            }
            _ => {}
        }
    }

    let json_str = &response[json_start..json_end];
    serde_json::from_str(json_str).map_err(|e| format!("JSON parse error: {}", e))
}

/// Evaluate agent response for a task
fn evaluate_response(response: &serde_json::Value, task_type: &str) -> (bool, f64, String) {
    // Check required fields
    let has_analysis = response.get("analysis").is_some();
    let has_plan = response.get("plan").is_some();
    let has_commands = response
        .get("commands")
        .map(|c| c.is_array())
        .unwrap_or(false);

    if !has_analysis || !has_plan || !has_commands {
        return (
            false,
            0.0,
            "Missing required fields (analysis, plan, commands)".to_string(),
        );
    }

    let commands = response["commands"].as_array().unwrap();

    // Evaluate based on task type
    match task_type {
        "file_creation" => {
            // Check if commands create a file
            let creates_file = commands.iter().any(|cmd| {
                let ks = cmd["keystrokes"].as_str().unwrap_or("");
                ks.contains("touch")
                    || ks.contains("echo")
                    || ks.contains(">")
                    || ks.contains("cat")
            });
            if creates_file {
                (true, 1.0, "Correct: Commands create a file".to_string())
            } else {
                (
                    false,
                    0.3,
                    "Partial: No file creation command found".to_string(),
                )
            }
        }
        "directory_listing" => {
            let lists_dir = commands.iter().any(|cmd| {
                let ks = cmd["keystrokes"].as_str().unwrap_or("");
                ks.contains("ls") || ks.contains("find") || ks.contains("tree")
            });
            if lists_dir {
                (true, 1.0, "Correct: Commands list directory".to_string())
            } else {
                (false, 0.3, "Partial: No listing command found".to_string())
            }
        }
        "text_search" => {
            let searches = commands.iter().any(|cmd| {
                let ks = cmd["keystrokes"].as_str().unwrap_or("");
                ks.contains("grep")
                    || ks.contains("find")
                    || ks.contains("awk")
                    || ks.contains("sed")
            });
            if searches {
                (true, 1.0, "Correct: Commands search text".to_string())
            } else {
                (false, 0.3, "Partial: No search command found".to_string())
            }
        }
        _ => (true, 0.5, "Unknown task type - partial score".to_string()),
    }
}

#[test]
#[ignore] // Run with: cargo test --test live_evaluation_test -- --ignored --nocapture
fn test_live_evaluation_file_creation() {
    println!("\n========================================");
    println!("LIVE EVALUATION TEST - File Creation");
    println!("========================================\n");

    let task = "Create a file called 'hello.txt' containing the text 'Hello World'";

    let messages = vec![
        serde_json::json!({
            "role": "system",
            "content": "You are a terminal command expert. Respond ONLY with valid JSON containing: 'analysis' (string), 'plan' (string), 'commands' (array of objects with 'keystrokes' and 'duration'), and 'task_complete' (boolean)."
        }),
        serde_json::json!({
            "role": "user",
            "content": format!("Task: {}\n\nProvide commands to complete this task.", task)
        }),
    ];

    println!("[1] Task: {}", task);
    println!("[2] Calling OpenRouter (gpt-4o-mini)...");

    let start = Instant::now();
    let response = call_openrouter(&messages, "openai/gpt-4o-mini").expect("LLM call failed");
    let elapsed = start.elapsed();

    println!("[3] Response received in {:.2}s", elapsed.as_secs_f64());
    println!(
        "[4] Raw response:\n{}\n",
        &response[..response.len().min(500)]
    );

    let parsed = parse_agent_response(&response).expect("Failed to parse response");
    println!("[5] Parsed JSON successfully");

    let (passed, score, reason) = evaluate_response(&parsed, "file_creation");

    println!("\n========================================");
    println!("EVALUATION RESULT");
    println!("========================================");
    println!("  Passed: {}", passed);
    println!("  Score: {:.2}", score);
    println!("  Reason: {}", reason);
    println!("  Commands: {:?}", parsed["commands"]);
    println!("========================================\n");

    assert!(score > 0.0, "Score should be positive");
}

#[test]
#[ignore]
fn test_live_evaluation_directory_listing() {
    println!("\n========================================");
    println!("LIVE EVALUATION TEST - Directory Listing");
    println!("========================================\n");

    let task =
        "List all files in the /tmp directory including hidden files, sorted by modification time";

    let messages = vec![
        serde_json::json!({
            "role": "system",
            "content": "You are a terminal command expert. Respond ONLY with valid JSON containing: 'analysis' (string), 'plan' (string), 'commands' (array of objects with 'keystrokes' and 'duration'), and 'task_complete' (boolean)."
        }),
        serde_json::json!({
            "role": "user",
            "content": format!("Task: {}\n\nProvide commands to complete this task.", task)
        }),
    ];

    println!("[1] Task: {}", task);
    println!("[2] Calling OpenRouter...");

    let start = Instant::now();
    let response = call_openrouter(&messages, "openai/gpt-4o-mini").expect("LLM call failed");
    let elapsed = start.elapsed();

    println!("[3] Response received in {:.2}s", elapsed.as_secs_f64());

    let parsed = parse_agent_response(&response).expect("Failed to parse response");
    let (passed, score, reason) = evaluate_response(&parsed, "directory_listing");

    println!("\n========================================");
    println!("EVALUATION RESULT");
    println!("========================================");
    println!("  Passed: {}", passed);
    println!("  Score: {:.2}", score);
    println!("  Reason: {}", reason);
    println!("  Commands: {:?}", parsed["commands"]);
    println!("========================================\n");

    assert!(score > 0.0);
}

#[test]
#[ignore]
fn test_live_evaluation_text_search() {
    println!("\n========================================");
    println!("LIVE EVALUATION TEST - Text Search");
    println!("========================================\n");

    let task = "Search for all lines containing 'error' in all .log files in /var/log";

    let messages = vec![
        serde_json::json!({
            "role": "system",
            "content": "You are a terminal command expert. Respond ONLY with valid JSON containing: 'analysis' (string), 'plan' (string), 'commands' (array of objects with 'keystrokes' and 'duration'), and 'task_complete' (boolean)."
        }),
        serde_json::json!({
            "role": "user",
            "content": format!("Task: {}\n\nProvide commands to complete this task.", task)
        }),
    ];

    println!("[1] Task: {}", task);
    println!("[2] Calling OpenRouter...");

    let start = Instant::now();
    let response = call_openrouter(&messages, "openai/gpt-4o-mini").expect("LLM call failed");
    let elapsed = start.elapsed();

    println!("[3] Response received in {:.2}s", elapsed.as_secs_f64());

    let parsed = parse_agent_response(&response).expect("Failed to parse response");
    let (passed, score, reason) = evaluate_response(&parsed, "text_search");

    println!("\n========================================");
    println!("EVALUATION RESULT");
    println!("========================================");
    println!("  Passed: {}", passed);
    println!("  Score: {:.2}", score);
    println!("  Reason: {}", reason);
    println!("  Commands: {:?}", parsed["commands"]);
    println!("========================================\n");

    assert!(score > 0.0);
}

#[test]
#[ignore]
fn test_full_evaluation_pipeline() {
    println!("\n================================================================");
    println!("FULL EVALUATION PIPELINE - Multiple Tasks");
    println!("================================================================\n");

    let tasks = [
        (
            "file_creation",
            "Create a Python script called 'hello.py' that prints 'Hello World'",
        ),
        (
            "directory_listing",
            "Show the contents of the home directory with file sizes",
        ),
        (
            "text_search",
            "Find all Python files in the current directory containing 'import'",
        ),
    ];

    let mut total_score = 0.0;
    let mut total_cost = 0.0;
    let mut results = Vec::new();

    for (i, (task_type, task_desc)) in tasks.iter().enumerate() {
        println!("----------------------------------------");
        println!("Task {}: {} ", i + 1, task_type);
        println!("----------------------------------------");
        println!("Description: {}\n", task_desc);

        let messages = vec![
            serde_json::json!({
                "role": "system",
                "content": "You are a terminal command expert. Respond ONLY with valid JSON containing: 'analysis' (string), 'plan' (string), 'commands' (array of objects with 'keystrokes' and 'duration'), and 'task_complete' (boolean)."
            }),
            serde_json::json!({
                "role": "user",
                "content": format!("Task: {}\n\nProvide commands to complete this task.", task_desc)
            }),
        ];

        let start = Instant::now();
        let response = match call_openrouter(&messages, "openai/gpt-4o-mini") {
            Ok(r) => r,
            Err(e) => {
                println!("  ERROR: {}", e);
                results.push((task_type.to_string(), false, 0.0, e));
                continue;
            }
        };
        let elapsed = start.elapsed();

        // Estimate cost (gpt-4o-mini: ~$0.00015/1K input, ~$0.0006/1K output)
        let est_cost = 0.001; // rough estimate per call
        total_cost += est_cost;

        let parsed = match parse_agent_response(&response) {
            Ok(p) => p,
            Err(e) => {
                println!("  PARSE ERROR: {}", e);
                println!("  Response: {}", &response[..response.len().min(200)]);
                results.push((task_type.to_string(), false, 0.0, e));
                continue;
            }
        };

        let (passed, score, reason) = evaluate_response(&parsed, task_type);
        total_score += score;

        println!("  Time: {:.2}s", elapsed.as_secs_f64());
        println!("  Passed: {}", passed);
        println!("  Score: {:.2}", score);
        println!("  Reason: {}", reason);

        if let Some(commands) = parsed["commands"].as_array() {
            println!("  Commands:");
            for cmd in commands {
                println!("    - {}", cmd["keystrokes"].as_str().unwrap_or("?").trim());
            }
        }
        println!();

        results.push((task_type.to_string(), passed, score, reason));
    }

    let avg_score = total_score / tasks.len() as f64;

    println!("\n================================================================");
    println!("FINAL RESULTS");
    println!("================================================================");
    println!("Tasks completed: {}", results.len());
    println!(
        "Tasks passed: {}",
        results.iter().filter(|(_, p, _, _)| *p).count()
    );
    println!(
        "Average score: {:.2} ({:.0}%)",
        avg_score,
        avg_score * 100.0
    );
    println!("Estimated cost: ${:.4}", total_cost);
    println!();

    println!("Per-task breakdown:");
    for (task_type, passed, score, reason) in &results {
        let status = if *passed { "PASS" } else { "FAIL" };
        println!("  [{}] {}: {:.2} - {}", status, task_type, score, reason);
    }
    println!("================================================================\n");

    assert!(avg_score > 0.5, "Average score should be > 50%");
}
