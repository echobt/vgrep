//! Integration test for Terminus2 agent with OpenRouter
//!
//! This test runs the complete evaluation pipeline with the terminus2 agent

#[allow(unused_imports)]
use std::collections::HashSet;
use term_challenge::{
    ChallengeConfig, DistributionConfig, PackageType, PipelineAgentSubmission,
    PipelineEvaluationResult, PythonWhitelist, ReceiveResult, ReceiveStatus, TaskEvalResult,
    ValidatorDistributor, ValidatorInfo, WhitelistConfig,
};

#[allow(dead_code)]
fn get_api_key() -> String {
    std::env::var("OPENROUTER_API_KEY").unwrap_or_else(|_| "test-key-not-set".to_string())
}

/// Simple terminus2-like agent code for testing
/// Note: Does NOT use 'os' module as it's forbidden by default whitelist
const TEST_AGENT_CODE: &str = r#"
"""Simple test agent for term-challenge evaluation."""
import json

class TestAgent:
    """Minimal agent that responds with a simple command."""
    
    @staticmethod
    def name():
        return "test-agent"
    
    def __init__(self, agent_id="test", challenge_id="term-challenge", **kwargs):
        self.agent_id = agent_id
        self.challenge_id = challenge_id
    
    def solve(self, task_description):
        """Return a simple solution."""
        return {
            "success": True,
            "output": "echo 'Hello from test agent'",
            "commands": [
                {"keystrokes": "echo 'test'\n", "duration": 0.1}
            ]
        }
"#;

/// Full terminus2 agent code (simplified version for testing)
/// Note: Does NOT use 'os' module as it's forbidden by default whitelist
const TERMINUS2_AGENT_CODE: &str = r#"
"""Terminus2 Agent - Simplified for integration testing."""
import json
import re
import requests

class Terminus2Agent:
    """Terminus2 agent using OpenRouter for LLM calls."""
    
    OPENROUTER_API_KEY = os.environ.get("OPENROUTER_API_KEY", "")
    OPENROUTER_URL = "https://openrouter.ai/api/v1/chat/completions"
    
    @staticmethod
    def name():
        return "terminus2"
    
    def __init__(self, agent_id="terminus2", challenge_id="term-challenge", **kwargs):
        self.agent_id = agent_id
        self.challenge_id = challenge_id
        self.model = kwargs.get("model_name", "openai/gpt-4o-mini")
    
    def call_llm(self, messages, temperature=0.7):
        """Call OpenRouter API."""
        headers = {
            "Authorization": f"Bearer {self.OPENROUTER_API_KEY}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://term-challenge.test",
        }
        payload = {
            "model": self.model,
            "messages": messages,
            "temperature": temperature,
        }
        response = requests.post(self.OPENROUTER_URL, headers=headers, json=payload, timeout=60)
        if response.status_code == 200:
            return response.json()
        else:
            raise Exception(f"LLM call failed: {response.status_code} - {response.text}")
    
    def solve(self, task_description):
        """Solve task using LLM."""
        messages = [
            {"role": "system", "content": "You are a terminal command expert. Respond with JSON containing 'analysis', 'plan', 'commands' array, and 'task_complete' boolean."},
            {"role": "user", "content": f"Task: {task_description}\n\nProvide a JSON response with commands to solve this task."}
        ]
        
        try:
            response = self.call_llm(messages)
            content = response["choices"][0]["message"]["content"]
            
            # Parse JSON from response
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())
                return {
                    "success": True,
                    "output": content,
                    "commands": result.get("commands", []),
                    "task_complete": result.get("task_complete", False),
                }
            else:
                return {
                    "success": True,
                    "output": content,
                    "commands": [],
                    "task_complete": False,
                }
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "output": "",
                "commands": [],
            }
"#;

#[test]
fn test_whitelist_simple_agent() {
    let config = WhitelistConfig {
        allowed_stdlib: ["json", "re"].iter().map(|s| s.to_string()).collect(),
        allowed_third_party: ["requests"].iter().map(|s| s.to_string()).collect(),
        forbidden_builtins: ["exec", "eval"].iter().map(|s| s.to_string()).collect(),
        max_code_size: 1024 * 1024,
        allow_subprocess: false,
        allow_network: true,
        allow_filesystem: false,
    };

    let whitelist = PythonWhitelist::new(config);
    let result = whitelist.verify(TEST_AGENT_CODE);

    println!("Whitelist verification result:");
    println!("  Valid: {}", result.valid);
    println!("  Errors: {:?}", result.errors);
    println!("  Warnings: {:?}", result.warnings);
    println!("  Imported modules: {:?}", result.imported_modules);

    assert!(result.valid, "Simple agent should pass whitelist");
}

#[test]
fn test_whitelist_terminus2_agent() {
    let config = WhitelistConfig {
        allowed_stdlib: ["json", "re"].iter().map(|s| s.to_string()).collect(),
        allowed_third_party: ["requests"].iter().map(|s| s.to_string()).collect(),
        forbidden_builtins: ["exec", "eval", "compile"]
            .iter()
            .map(|s| s.to_string())
            .collect(),
        max_code_size: 1024 * 1024,
        allow_subprocess: false,
        allow_network: true,
        allow_filesystem: false,
    };

    let whitelist = PythonWhitelist::new(config);
    let result = whitelist.verify(TERMINUS2_AGENT_CODE);

    println!("Terminus2 whitelist verification:");
    println!("  Valid: {}", result.valid);
    println!("  Errors: {:?}", result.errors);
    println!("  Warnings: {:?}", result.warnings);
    println!("  Imported modules: {:?}", result.imported_modules);

    assert!(result.valid, "Terminus2 agent should pass whitelist");
}

#[test]
fn test_validator_distribution() {
    let config = DistributionConfig::default();
    let distributor = ValidatorDistributor::new(config);

    // Create test validators
    let validators = vec![
        ValidatorInfo {
            hotkey: "root_validator".to_string(),
            stake: 100_000_000_000_000, // 100K TAO
            is_root: true,
        },
        ValidatorInfo {
            hotkey: "validator_1".to_string(),
            stake: 50_000_000_000_000, // 50K TAO
            is_root: false,
        },
        ValidatorInfo {
            hotkey: "validator_2".to_string(),
            stake: 30_000_000_000_000, // 30K TAO
            is_root: false,
        },
        ValidatorInfo {
            hotkey: "validator_3".to_string(),
            stake: 20_000_000_000_000, // 20K TAO
            is_root: false,
        },
        ValidatorInfo {
            hotkey: "validator_4".to_string(),
            stake: 10_000_000_000_000, // 10K TAO
            is_root: false,
        },
    ];

    let (source_receivers, obfuscated_receivers) = distributor.classify_validators(&validators);

    println!("Source receivers (top validators): {:?}", source_receivers);
    println!("Obfuscated receivers: {:?}", obfuscated_receivers);

    // Root + top 3 should receive source
    assert!(
        source_receivers.len() <= 4,
        "At most 4 validators receive source"
    );
    assert!(!obfuscated_receivers.is_empty() || validators.len() <= 4);
}

#[test]
fn test_agent_submission_flow() {
    let submission = PipelineAgentSubmission {
        code: TEST_AGENT_CODE.as_bytes().to_vec(),
        miner_hotkey: "test_miner_hotkey".to_string(),
        miner_uid: 42,
        miner_stake: 2_000_000_000_000, // 2000 TAO (above 1000 minimum)
        epoch: 100,
        submitted_at: chrono::Utc::now().timestamp_millis() as u64,
    };

    println!("Agent submission created:");
    println!(
        "  Miner: {} (UID {})",
        submission.miner_hotkey, submission.miner_uid
    );
    println!("  Stake: {} TAO", submission.miner_stake / 1_000_000_000);
    println!("  Epoch: {}", submission.epoch);
    println!("  Code size: {} bytes", submission.code.len());

    // Verify stake is sufficient
    let min_stake = 1000 * 1_000_000_000u64; // 1000 TAO in rao
    assert!(
        submission.miner_stake >= min_stake,
        "Stake should be sufficient"
    );
}

#[test]
fn test_receive_status_variants() {
    // Test all status variants
    let accepted = ReceiveStatus::Accepted;
    assert!(matches!(accepted, ReceiveStatus::Accepted));

    let rejected_whitelist = ReceiveStatus::RejectedWhitelist {
        violations: vec!["subprocess".to_string()],
    };
    assert!(matches!(
        rejected_whitelist,
        ReceiveStatus::RejectedWhitelist { .. }
    ));

    let rejected_stake = ReceiveStatus::RejectedInsufficientStake {
        stake: 500_000_000_000,
        required: 1_000_000_000_000,
    };
    assert!(matches!(
        rejected_stake,
        ReceiveStatus::RejectedInsufficientStake { .. }
    ));

    let error = ReceiveStatus::Error {
        reason: "Test error".to_string(),
    };
    assert!(matches!(error, ReceiveStatus::Error { .. }));

    println!("All ReceiveStatus variants work correctly");
}

#[test]
fn test_config_defaults() {
    let config = ChallengeConfig::default();

    println!("Default ChallengeConfig:");
    println!("  Min stake: {} TAO", config.min_stake_tao);
    println!(
        "  Max cost per task: ${}",
        config.pricing.max_cost_per_task_usd
    );
    println!("  Max total cost: ${}", config.pricing.max_total_cost_usd);
    println!(
        "  Task timeout: {}s",
        config.execution.max_task_timeout_secs
    );
    println!("  Max memory: {} MB", config.execution.max_memory_mb);

    assert_eq!(config.min_stake_tao, 1000);
    assert!(config.pricing.max_cost_per_task_usd > 0.0);
    assert!(config.execution.max_task_timeout_secs > 0);
}

#[test]
fn test_task_eval_result() {
    let result = TaskEvalResult {
        task_id: "task_001".to_string(),
        passed: true,
        score: 1.0,
        execution_time_ms: 1500,
        cost_usd: 0.05,
        error: None,
    };

    println!("Task evaluation result:");
    println!("  Task: {}", result.task_id);
    println!("  Passed: {}", result.passed);
    println!("  Score: {:.2}", result.score);
    println!("  Time: {}ms", result.execution_time_ms);
    println!("  Cost: ${:.4}", result.cost_usd);

    assert!(result.passed);
    assert_eq!(result.score, 1.0);
}

#[test]
fn test_package_types() {
    let source = PackageType::Source;
    let obfuscated = PackageType::Obfuscated;

    // Test serialization
    let source_json = serde_json::to_string(&source).unwrap();
    let obfuscated_json = serde_json::to_string(&obfuscated).unwrap();

    println!("Package types:");
    println!("  Source: {}", source_json);
    println!("  Obfuscated: {}", obfuscated_json);

    assert!(source_json.contains("Source"));
    assert!(obfuscated_json.contains("Obfuscated"));
}

/// Integration test that verifies the complete flow
#[test]
fn test_complete_evaluation_flow() {
    println!("\n========================================");
    println!("COMPLETE EVALUATION FLOW TEST");
    println!("========================================\n");

    // Step 1: Create config
    let config = ChallengeConfig::default();
    println!("[1] Config created: min_stake={} TAO", config.min_stake_tao);

    // Step 2: Create submission
    let submission = PipelineAgentSubmission {
        code: TERMINUS2_AGENT_CODE.as_bytes().to_vec(),
        miner_hotkey: "5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY".to_string(),
        miner_uid: 1,
        miner_stake: 5_000_000_000_000, // 5000 TAO
        epoch: 100,
        submitted_at: chrono::Utc::now().timestamp_millis() as u64,
    };
    println!(
        "[2] Submission created: {} bytes from miner {}",
        submission.code.len(),
        &submission.miner_hotkey[..20]
    );

    // Step 3: Verify whitelist
    let whitelist_config = WhitelistConfig {
        allowed_stdlib: config.module_whitelist.allowed_stdlib.clone(),
        allowed_third_party: config.module_whitelist.allowed_third_party.clone(),
        forbidden_builtins: ["exec", "eval"].iter().map(|s| s.to_string()).collect(),
        max_code_size: 1024 * 1024,
        allow_subprocess: false,
        allow_network: true,
        allow_filesystem: false,
    };
    let whitelist = PythonWhitelist::new(whitelist_config);
    let code_str = String::from_utf8(submission.code.clone()).unwrap();
    let verification = whitelist.verify(&code_str);
    println!("[3] Whitelist verification: valid={}", verification.valid);

    // Step 4: Check stake
    let min_stake_rao = config.min_stake_tao * 1_000_000_000;
    let stake_ok = submission.miner_stake >= min_stake_rao;
    println!(
        "[4] Stake check: {} >= {} = {}",
        submission.miner_stake / 1_000_000_000,
        config.min_stake_tao,
        stake_ok
    );

    // Step 5: Create validators
    let validators = vec![
        ValidatorInfo {
            hotkey: "root_validator".to_string(),
            stake: 100_000_000_000_000,
            is_root: true,
        },
        ValidatorInfo {
            hotkey: "our_validator".to_string(),
            stake: 50_000_000_000_000,
            is_root: false,
        },
    ];
    let dist_config = DistributionConfig::default();
    let distributor = ValidatorDistributor::new(dist_config);
    let (source_receivers, _) = distributor.classify_validators(&validators);
    let is_top_validator = source_receivers.contains(&"our_validator".to_string());
    println!("[5] Validator classification: is_top={}", is_top_validator);

    // Step 6: Determine package type
    let package_type = if is_top_validator {
        PackageType::Source
    } else {
        PackageType::Obfuscated
    };
    println!("[6] Package type: {:?}", package_type);

    // Step 7: Create receive result
    let hash = {
        use sha2::{Digest, Sha256};
        let mut hasher = Sha256::new();
        hasher.update(&submission.code);
        hex::encode(hasher.finalize())
    };

    let receive_result = ReceiveResult {
        agent_hash: hash.clone(),
        status: ReceiveStatus::Accepted,
        message: "Agent accepted for evaluation".to_string(),
        package_type,
    };
    println!(
        "[7] Receive result: hash={}...",
        &receive_result.agent_hash[..16]
    );

    // Step 8: Create mock evaluation result
    let eval_result = PipelineEvaluationResult {
        agent_hash: hash.clone(),
        miner_hotkey: submission.miner_hotkey.clone(),
        miner_uid: submission.miner_uid,
        final_score: 0.85,
        tasks_completed: 8,
        tasks_total: 10,
        task_results: vec![
            TaskEvalResult {
                task_id: "task_001".to_string(),
                passed: true,
                score: 1.0,
                execution_time_ms: 1200,
                cost_usd: 0.02,
                error: None,
            },
            TaskEvalResult {
                task_id: "task_002".to_string(),
                passed: true,
                score: 1.0,
                execution_time_ms: 800,
                cost_usd: 0.01,
                error: None,
            },
            TaskEvalResult {
                task_id: "task_003".to_string(),
                passed: false,
                score: 0.0,
                execution_time_ms: 5000,
                cost_usd: 0.05,
                error: Some("Timeout".to_string()),
            },
        ],
        total_cost_usd: 0.45,
        execution_time_ms: 45000,
        validator_hotkey: "our_validator".to_string(),
        epoch: 100,
        timestamp: chrono::Utc::now().timestamp_millis() as u64,
        result_hash: "result_hash_placeholder".to_string(),
    };

    println!("[8] Evaluation result:");
    println!("    Score: {:.2}", eval_result.final_score);
    println!(
        "    Tasks: {}/{}",
        eval_result.tasks_completed, eval_result.tasks_total
    );
    println!("    Cost: ${:.4}", eval_result.total_cost_usd);
    println!("    Time: {}ms", eval_result.execution_time_ms);

    println!("\n========================================");
    println!("EVALUATION FLOW COMPLETE");
    println!("========================================");

    // Assertions
    assert!(verification.valid);
    assert!(stake_ok);
    assert!(matches!(receive_result.status, ReceiveStatus::Accepted));
    assert!(eval_result.final_score > 0.0);
    assert!(eval_result.tasks_completed > 0);
}
