//! Terminal Benchmark Challenge implementation for platform

use crate::core::compat::prelude::*;
use crate::core::compat::{
    AgentInfo as SdkAgentInfo, ChallengeConfigMeta, ChallengeEvaluationResult, ChallengeMetadata,
    Hotkey,
};
use crate::evaluation::evaluator::{AgentInfo, TaskEvaluator};
use crate::task::{Task, TaskRegistry, TaskResult};
use crate::weights::scoring::{Leaderboard, ScoreCalculator};
use async_trait::async_trait;
use std::collections::HashMap;
use std::path::PathBuf;
use std::sync::Arc;
use tokio::sync::RwLock;
use tracing::info;

/// Terminal Benchmark Challenge
///
/// This challenge evaluates AI agents on terminal-based tasks.
/// Agents compete by solving tasks in isolated Docker containers.
/// Scores are based on task completion rate and execution time.
pub struct TerminalBenchChallenge {
    /// Challenge ID
    id: ChallengeId,
    /// Challenge name
    name: String,
    /// Mechanism ID on Bittensor
    mechanism_id: u8,
    /// Emission weight
    emission_weight: f64,
    /// Task registry
    task_registry: Arc<RwLock<Option<TaskRegistry>>>,
    /// Score calculator
    score_calculator: ScoreCalculator,
    /// Leaderboard
    leaderboard: Arc<RwLock<Leaderboard>>,
    /// Tasks directory
    tasks_dir: PathBuf,
    /// Results cache (agent_hash -> results)
    results_cache: Arc<RwLock<HashMap<String, Vec<TaskResult>>>>,
    /// Number of tasks per evaluation
    tasks_per_evaluation: usize,
    /// Max concurrent evaluations
    max_concurrent: usize,
}

impl TerminalBenchChallenge {
    /// Get default routes (static method for registration without instance)
    pub fn default_routes() -> Vec<ChallengeRoute> {
        vec![
            // Agent submission
            ChallengeRoute::post("/submit", "Submit an agent (Python source code)"),
            ChallengeRoute::get("/can_submit", "Check if miner can submit"),
            // Agent status
            ChallengeRoute::get("/status/:hash", "Get agent submission status"),
            ChallengeRoute::get("/agent/:hash", "Get agent details"),
            ChallengeRoute::get("/agents/miner/:hotkey", "List agents for a miner"),
            ChallengeRoute::get("/agents/pending", "List pending agents"),
            ChallengeRoute::get("/agents/active", "List active agents"),
            // Configuration
            ChallengeRoute::get("/config", "Get challenge configuration"),
            ChallengeRoute::get("/whitelist", "Get module whitelist"),
            ChallengeRoute::get("/whitelist/modules", "Get allowed modules"),
            ChallengeRoute::get("/whitelist/models", "Get allowed LLM models"),
            ChallengeRoute::get("/pricing", "Get pricing limits"),
            // Stats and leaderboard
            ChallengeRoute::get("/stats", "Get submission statistics"),
            ChallengeRoute::get("/leaderboard", "Get current leaderboard"),
            // Progress tracking
            ChallengeRoute::get("/progress/:evaluation_id", "Get evaluation progress"),
            ChallengeRoute::get("/progress/agent/:hash", "Get agent's evaluation history"),
        ]
    }

    /// Create a new Terminal Benchmark Challenge
    pub fn new(
        name: impl Into<String>,
        mechanism_id: u8,
        emission_weight: f64,
        tasks_dir: PathBuf,
    ) -> Self {
        // Use a deterministic ID for development/testing
        // In production this might come from configuration or be randomized
        let id_str = "00000000-0000-0000-0000-000000000001";
        let id = ChallengeId::new(id_str);

        Self {
            id,
            name: name.into(),
            mechanism_id,
            emission_weight,
            task_registry: Arc::new(RwLock::new(None)),
            score_calculator: ScoreCalculator,
            leaderboard: Arc::new(RwLock::new(Leaderboard::default())),
            tasks_dir,
            results_cache: Arc::new(RwLock::new(HashMap::new())),
            tasks_per_evaluation: 30, // Evaluate on all 30 tasks by default
            max_concurrent: 4,
        }
    }

    /// Set the number of tasks per evaluation
    pub fn with_tasks_per_evaluation(mut self, n: usize) -> Self {
        self.tasks_per_evaluation = n;
        self
    }

    /// Set max concurrent evaluations
    pub fn with_max_concurrent(mut self, n: usize) -> Self {
        self.max_concurrent = n;
        self
    }

    /// Get the task registry
    async fn registry(
        &self,
    ) -> anyhow::Result<tokio::sync::RwLockReadGuard<'_, Option<TaskRegistry>>> {
        let guard = self.task_registry.read().await;
        if guard.is_none() {
            drop(guard);
            self.load_tasks().await?;
            return Ok(self.task_registry.read().await);
        }
        Ok(guard)
    }

    /// Load tasks from directory
    async fn load_tasks(&self) -> anyhow::Result<()> {
        let registry = TaskRegistry::new(self.tasks_dir.clone())?;
        info!("Loaded {} tasks for Terminal Benchmark", registry.count());

        let mut guard = self.task_registry.write().await;
        *guard = Some(registry);
        Ok(())
    }

    /// Record evaluation results from external source
    pub async fn record_evaluation_result(
        &self,
        agent_hash: String,
        miner_hotkey: String,
        results: Vec<TaskResult>,
    ) {
        // Cache results
        {
            let mut cache = self.results_cache.write().await;
            cache.insert(agent_hash.clone(), results.clone());
        }

        // Update leaderboard
        // We need to fetch tasks to calculate aggregate
        if let Ok(registry_guard) = self.registry().await {
            if let Some(registry) = registry_guard.as_ref() {
                let tasks: Vec<&Task> = results
                    .iter()
                    .filter_map(|r| registry.get(&r.task_id))
                    .collect();

                let aggregate = self.score_calculator.calculate_aggregate(&tasks, &results);
                {
                    let mut lb = self.leaderboard.write().await;
                    lb.update(agent_hash, miner_hotkey, aggregate);
                }
            }
        }
    }

    /// Run evaluation for an agent
    async fn run_evaluation(&self, agent: &AgentInfo) -> anyhow::Result<Vec<TaskResult>> {
        let registry_guard = self.registry().await?;
        let registry = registry_guard
            .as_ref()
            .ok_or_else(|| anyhow::anyhow!("Task registry not loaded"))?;

        // Get random tasks for evaluation
        let tasks = registry.random_tasks(self.tasks_per_evaluation);

        if tasks.is_empty() {
            return Err(anyhow::anyhow!("No tasks available for evaluation"));
        }

        info!(
            "Running evaluation on {} tasks for agent {}",
            tasks.len(),
            agent.hash
        );

        // Create evaluator
        let evaluator = TaskEvaluator::new(self.max_concurrent).await?;

        // Run evaluation
        let results = evaluator.evaluate_tasks(&tasks, agent).await;

        // Cache results
        {
            let mut cache = self.results_cache.write().await;
            cache.insert(agent.hash.clone(), results.clone());
        }

        // Update leaderboard
        let aggregate = self.score_calculator.calculate_aggregate(&tasks, &results);
        {
            let mut lb = self.leaderboard.write().await;
            lb.update(agent.hash.clone(), agent.miner_hotkey.clone(), aggregate);
        }

        Ok(results)
    }

    /// Get cached results for an agent (for future use in weight calculations)
    #[allow(dead_code)]
    async fn get_cached_results(&self, agent_hash: &str) -> Option<Vec<TaskResult>> {
        let cache = self.results_cache.read().await;
        cache.get(agent_hash).cloned()
    }

    /// Calculate weights from leaderboard
    async fn calculate_weights_from_leaderboard(&self) -> Vec<WeightAssignment> {
        let leaderboard = self.leaderboard.read().await;
        let entries = leaderboard.all();

        if entries.is_empty() {
            return Vec::new();
        }

        // Calculate total normalized score
        let total_score: f64 = entries.iter().map(|e| e.score.normalized_score).sum();

        if total_score == 0.0 {
            return Vec::new();
        }

        // Assign weights proportional to normalized scores
        // Use miner_hotkey (SS58 address) for weight assignment
        entries
            .iter()
            .map(|entry| {
                let weight = (entry.score.normalized_score / total_score * 65535.0) as u16;
                WeightAssignment::new(entry.miner_hotkey.clone(), weight)
            })
            .collect()
    }
}

#[async_trait]
impl Challenge for TerminalBenchChallenge {
    fn id(&self) -> ChallengeId {
        self.id
    }

    fn name(&self) -> &str {
        &self.name
    }

    fn description(&self) -> &str {
        "Terminal Benchmark Challenge - AI agents compete on terminal-based tasks"
    }

    fn version(&self) -> &str {
        env!("CARGO_PKG_VERSION")
    }

    fn emission_weight(&self) -> f64 {
        self.emission_weight
    }

    async fn on_startup(&self, _ctx: &ChallengeContext) -> Result<()> {
        info!("Terminal Benchmark Challenge starting up");
        self.load_tasks()
            .await
            .map_err(|e| ChallengeError::Internal(e.to_string()))?;
        Ok(())
    }

    async fn evaluate(
        &self,
        ctx: &ChallengeContext,
        agent: &SdkAgentInfo,
        payload: serde_json::Value,
    ) -> Result<ChallengeEvaluationResult> {
        info!(
            "Evaluating agent {} for Terminal Benchmark",
            agent.agent_hash
        );

        // Extract agent image from payload or metadata
        let agent_image = payload
            .get("image")
            .and_then(|v| v.as_str())
            .unwrap_or(&agent.agent_hash);

        // Get miner hotkey from agent
        let miner_hotkey = agent.miner_hotkey.clone();

        let agent_info = AgentInfo {
            hash: agent.agent_hash.clone(),
            miner_hotkey: miner_hotkey.clone(),
            image: agent_image.to_string(),
            endpoint: payload
                .get("endpoint")
                .and_then(|v| v.as_str())
                .map(String::from),
            source_code: None,
            language: None,
            env_vars: Vec::new(),
        };

        // Run evaluation
        let results = self
            .run_evaluation(&agent_info)
            .await
            .map_err(|e| ChallengeError::Evaluation(e.to_string()))?;

        // Calculate aggregate score
        let registry_guard = self
            .registry()
            .await
            .map_err(|e| ChallengeError::Internal(e.to_string()))?;
        let registry = registry_guard
            .as_ref()
            .ok_or_else(|| ChallengeError::Internal("Registry not loaded".to_string()))?;

        let tasks: Vec<&Task> = results
            .iter()
            .filter_map(|r| registry.get(&r.task_id))
            .collect();

        let aggregate = self.score_calculator.calculate_aggregate(&tasks, &results);
        let score = self.score_calculator.to_weight(&aggregate);

        // Build metrics
        let mut metrics = HashMap::new();
        metrics.insert("tasks_passed".to_string(), aggregate.tasks_passed as f64);
        metrics.insert("tasks_failed".to_string(), aggregate.tasks_failed as f64);
        metrics.insert("pass_rate".to_string(), aggregate.pass_rate);
        metrics.insert("normalized_score".to_string(), aggregate.normalized_score);

        // Calculate total execution time from task results
        let total_execution_time_ms: u64 = results.iter().map(|r| r.execution_time_ms).sum();

        // Add execution time to metrics
        metrics.insert(
            "execution_time_ms".to_string(),
            total_execution_time_ms as f64,
        );

        info!(
            "Agent {} evaluation complete: score={:.4}, passed={}/{}, time={}ms",
            agent.agent_hash,
            score,
            aggregate.tasks_passed,
            aggregate.total_tasks(),
            total_execution_time_ms
        );

        Ok(ChallengeEvaluationResult {
            score,
            tasks_passed: aggregate.tasks_passed as u32,
            tasks_total: aggregate.total_tasks() as u32,
            tasks_failed: aggregate.tasks_failed as u32,
            total_cost_usd: aggregate.total_cost_usd.unwrap_or(0.0),
            execution_time_ms: total_execution_time_ms as i64,
            details: Some(serde_json::to_value(&metrics).unwrap_or_default()),
        })
    }

    async fn calculate_weights(&self, _ctx: &ChallengeContext) -> Result<Vec<WeightAssignment>> {
        info!("Calculating weights for Terminal Benchmark");

        let weights = self.calculate_weights_from_leaderboard().await;

        info!("Calculated {} weight assignments", weights.len());
        Ok(weights)
    }

    async fn validate_agent(&self, _ctx: &ChallengeContext, agent: &SdkAgentInfo) -> Result<bool> {
        // Basic validation: agent hash should be valid
        if agent.agent_hash.is_empty() {
            return Ok(false);
        }

        // Check if agent has required metadata (optional)
        // In production, you might validate the Docker image exists, etc.
        Ok(true)
    }

    fn metadata(&self) -> ChallengeMetadata {
        ChallengeMetadata {
            id: self.id,
            name: self.name.clone(),
            description: self.description().to_string(),
            version: self.version().to_string(),
            owner: Hotkey([0u8; 32]), // Will be set by runtime
            emission_weight: self.emission_weight,
            config: ChallengeConfigMeta::with_mechanism(self.mechanism_id),
            created_at: chrono::Utc::now(),
            updated_at: chrono::Utc::now(),
            is_active: true,
        }
    }

    /// Custom routes for agent submission and status
    fn routes(&self) -> Vec<ChallengeRoute> {
        vec![
            // Agent submission
            ChallengeRoute::post("/submit", "Submit an agent (Python source code)"),
            ChallengeRoute::get("/can_submit", "Check if miner can submit"),
            // Agent status
            ChallengeRoute::get("/status/:hash", "Get agent submission status"),
            ChallengeRoute::get("/agent/:hash", "Get agent details"),
            ChallengeRoute::get("/agents/miner/:hotkey", "List agents for a miner"),
            ChallengeRoute::get("/agents/pending", "List pending agents"),
            ChallengeRoute::get("/agents/active", "List active agents"),
            // Configuration
            ChallengeRoute::get("/config", "Get challenge configuration"),
            ChallengeRoute::get("/whitelist", "Get module whitelist"),
            ChallengeRoute::get("/whitelist/modules", "Get allowed modules"),
            ChallengeRoute::get("/whitelist/models", "Get allowed LLM models"),
            ChallengeRoute::get("/pricing", "Get pricing limits"),
            // Stats and leaderboard
            ChallengeRoute::get("/stats", "Get submission statistics"),
            ChallengeRoute::get("/leaderboard", "Get current leaderboard"),
            // Progress tracking
            ChallengeRoute::get("/progress/:evaluation_id", "Get evaluation progress"),
            ChallengeRoute::get("/progress/agent/:hash", "Get agent's evaluation history"),
        ]
    }

    /// Handle incoming requests to custom routes
    async fn handle_route(&self, _ctx: &ChallengeContext, req: RouteRequest) -> RouteResponse {
        match (req.method.as_str(), req.path.as_str()) {
            // Leaderboard
            ("GET", "/leaderboard") => {
                let leaderboard = self.leaderboard.read().await;
                let entries = leaderboard.all();
                RouteResponse::json(entries)
            }

            // Stats
            ("GET", "/stats") => {
                let leaderboard = self.leaderboard.read().await;
                let entries = leaderboard.all();
                RouteResponse::json(serde_json::json!({
                    "total_agents": entries.len(),
                    "active_agents": entries.iter().filter(|e| e.score.pass_rate > 0.0).count(),
                    "tasks_available": self.tasks_per_evaluation,
                }))
            }

            // Configuration
            ("GET", "/config") => RouteResponse::json(serde_json::json!({
                "name": self.name,
                "mechanism_id": self.mechanism_id,
                "emission_weight": self.emission_weight,
                "tasks_per_evaluation": self.tasks_per_evaluation,
                "max_concurrent": self.max_concurrent,
            })),

            // Whitelist
            ("GET", "/whitelist") | ("GET", "/whitelist/modules") => {
                let config = crate::ChallengeConfig::default();
                RouteResponse::json(config.module_whitelist)
            }

            ("GET", "/whitelist/models") => {
                let config = crate::ChallengeConfig::default();
                RouteResponse::json(config.model_whitelist)
            }

            ("GET", "/pricing") => {
                let config = crate::ChallengeConfig::default();
                RouteResponse::json(config.pricing)
            }

            // Agent details by hash
            ("GET", path) if path.starts_with("/agent/") => {
                let hash = req.param("hash").unwrap_or_default();
                let leaderboard = self.leaderboard.read().await;
                if let Some(entry) = leaderboard.get(hash) {
                    RouteResponse::json(entry)
                } else {
                    RouteResponse::not_found("Agent not found")
                }
            }

            // Pending/active agents (simplified - would use registry in production)
            ("GET", "/agents/pending") | ("GET", "/agents/active") => {
                let leaderboard = self.leaderboard.read().await;
                RouteResponse::json(leaderboard.all())
            }

            // Submit agent - delegates to AgentSubmissionHandler in production
            ("POST", "/submit") => {
                // In production, this would validate and register the agent
                // For now, return instructions
                RouteResponse::json(serde_json::json!({
                    "message": "Agent submission endpoint",
                    "required_fields": {
                        "source_code": "Python source code",
                        "miner_hotkey": "Hex-encoded miner hotkey",
                        "signature": "Hex-encoded signature",
                        "stake": "Stake in RAO"
                    }
                }))
            }

            // Can submit check
            ("GET", "/can_submit") => {
                let hotkey = req.query_param("miner_hotkey").unwrap_or_default();
                let stake: u64 = req
                    .query_param("stake")
                    .and_then(|s| s.parse().ok())
                    .unwrap_or(0);

                let min_stake = 1000 * 1_000_000_000u64; // 1000 TAO
                let allowed = stake >= min_stake;

                RouteResponse::json(serde_json::json!({
                    "allowed": allowed,
                    "reason": if allowed { None } else { Some("Insufficient stake") },
                    "min_stake_tao": 1000,
                    "your_stake_tao": stake as f64 / 1_000_000_000.0,
                }))
            }

            _ => RouteResponse::not_found("Route not found"),
        }
    }
}

/// Create the Terminal Benchmark challenge with default settings
pub fn create_terminal_bench_challenge(
    mechanism_id: u8,
    emission_weight: f64,
    tasks_dir: PathBuf,
) -> TerminalBenchChallenge {
    TerminalBenchChallenge::new(
        "Terminal Benchmark",
        mechanism_id,
        emission_weight,
        tasks_dir,
    )
    .with_tasks_per_evaluation(30) // All 30 tasks
    .with_max_concurrent(4)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_challenge_creation() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));

        assert_eq!(challenge.name(), "Terminal Benchmark");
        assert_eq!(challenge.emission_weight(), 0.5);
    }

    #[test]
    fn test_challenge_with_custom_settings() {
        let challenge = TerminalBenchChallenge::new(
            "Custom Challenge",
            42,
            0.75,
            PathBuf::from("./custom_tasks"),
        )
        .with_tasks_per_evaluation(10)
        .with_max_concurrent(8);

        assert_eq!(challenge.name(), "Custom Challenge");
        assert_eq!(challenge.emission_weight(), 0.75);
        assert_eq!(challenge.tasks_per_evaluation, 10);
        assert_eq!(challenge.max_concurrent, 8);
    }

    #[test]
    fn test_challenge_id() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let id = challenge.id();
        assert_eq!(id.as_str(), "00000000-0000-00"); // Truncated to 16 bytes
    }

    #[test]
    fn test_challenge_description() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        assert!(challenge.description().contains("Terminal Benchmark"));
    }

    #[test]
    fn test_challenge_version() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let version = challenge.version();
        // Version should be the CARGO_PKG_VERSION
        assert!(!version.is_empty());
    }

    #[test]
    fn test_default_routes() {
        let routes = TerminalBenchChallenge::default_routes();
        assert!(!routes.is_empty());

        // Check for expected routes
        let paths: Vec<&str> = routes.iter().map(|r| r.path.as_str()).collect();
        assert!(paths.contains(&"/submit"));
        assert!(paths.contains(&"/leaderboard"));
        assert!(paths.contains(&"/config"));
        assert!(paths.contains(&"/stats"));
    }

    #[test]
    fn test_challenge_routes() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let routes = challenge.routes();

        assert!(!routes.is_empty());

        // Should have POST /submit
        let submit_route = routes.iter().find(|r| r.path == "/submit");
        assert!(submit_route.is_some());
        assert_eq!(submit_route.unwrap().method, "POST");
    }

    #[test]
    fn test_challenge_metadata() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let metadata = challenge.metadata();

        assert_eq!(metadata.name, "Terminal Benchmark");
        assert_eq!(metadata.emission_weight, 0.5);
        assert!(metadata.is_active);
    }

    #[tokio::test]
    async fn test_validate_agent_empty_hash() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        let agent = SdkAgentInfo {
            agent_hash: "".to_string(),
            miner_hotkey: "5Grwva...".to_string(),
            name: None,
            source_code: None,
            api_key_encrypted: None,
            submitted_at: 0,
        };

        let result = challenge.validate_agent(&ctx, &agent).await;
        assert!(result.is_ok());
        assert!(!result.unwrap()); // Empty hash should be invalid
    }

    #[tokio::test]
    async fn test_validate_agent_valid() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        let agent = SdkAgentInfo {
            agent_hash: "abc123".to_string(),
            miner_hotkey: "5Grwva...".to_string(),
            name: Some("Test Agent".to_string()),
            source_code: None,
            api_key_encrypted: None,
            submitted_at: chrono::Utc::now().timestamp(),
        };

        let result = challenge.validate_agent(&ctx, &agent).await;
        assert!(result.is_ok());
        assert!(result.unwrap()); // Valid hash should be valid
    }

    #[tokio::test]
    async fn test_handle_route_leaderboard() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        let req = RouteRequest {
            path: "/leaderboard".to_string(),
            method: "GET".to_string(),
            body: None,
            headers: HashMap::new(),
            params: HashMap::new(),
            query: HashMap::new(),
        };

        let response = challenge.handle_route(&ctx, req).await;
        assert_eq!(response.status, 200);
    }

    #[tokio::test]
    async fn test_handle_route_stats() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        let req = RouteRequest {
            path: "/stats".to_string(),
            method: "GET".to_string(),
            body: None,
            headers: HashMap::new(),
            params: HashMap::new(),
            query: HashMap::new(),
        };

        let response = challenge.handle_route(&ctx, req).await;
        assert_eq!(response.status, 200);
        assert!(response.body.get("total_agents").is_some());
    }

    #[tokio::test]
    async fn test_handle_route_config() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        let req = RouteRequest {
            path: "/config".to_string(),
            method: "GET".to_string(),
            body: None,
            headers: HashMap::new(),
            params: HashMap::new(),
            query: HashMap::new(),
        };

        let response = challenge.handle_route(&ctx, req).await;
        assert_eq!(response.status, 200);
        assert_eq!(response.body["name"], "Terminal Benchmark");
    }

    #[tokio::test]
    async fn test_handle_route_not_found() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        let req = RouteRequest {
            path: "/nonexistent".to_string(),
            method: "GET".to_string(),
            body: None,
            headers: HashMap::new(),
            params: HashMap::new(),
            query: HashMap::new(),
        };

        let response = challenge.handle_route(&ctx, req).await;
        assert_eq!(response.status, 404);
    }

    #[tokio::test]
    async fn test_handle_route_submit() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        let req = RouteRequest {
            path: "/submit".to_string(),
            method: "POST".to_string(),
            body: None,
            headers: HashMap::new(),
            params: HashMap::new(),
            query: HashMap::new(),
        };

        let response = challenge.handle_route(&ctx, req).await;
        assert_eq!(response.status, 200);
        assert!(response.body.get("required_fields").is_some());
    }

    #[tokio::test]
    async fn test_handle_route_can_submit_insufficient_stake() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        let mut query = HashMap::new();
        query.insert("miner_hotkey".to_string(), "5Grwva...".to_string());
        query.insert("stake".to_string(), "100000000000".to_string()); // 100 TAO (below 1000)

        let req = RouteRequest {
            path: "/can_submit".to_string(),
            method: "GET".to_string(),
            body: None,
            headers: HashMap::new(),
            params: HashMap::new(),
            query,
        };

        let response = challenge.handle_route(&ctx, req).await;
        assert_eq!(response.status, 200);
        assert_eq!(response.body["allowed"], false);
    }

    #[tokio::test]
    async fn test_handle_route_can_submit_sufficient_stake() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        let mut query = HashMap::new();
        query.insert("miner_hotkey".to_string(), "5Grwva...".to_string());
        query.insert("stake".to_string(), "2000000000000".to_string()); // 2000 TAO (above 1000)

        let req = RouteRequest {
            path: "/can_submit".to_string(),
            method: "GET".to_string(),
            body: None,
            headers: HashMap::new(),
            params: HashMap::new(),
            query,
        };

        let response = challenge.handle_route(&ctx, req).await;
        assert_eq!(response.status, 200);
        assert_eq!(response.body["allowed"], true);
    }

    #[tokio::test]
    async fn test_handle_route_whitelist() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        let req = RouteRequest {
            path: "/whitelist".to_string(),
            method: "GET".to_string(),
            body: None,
            headers: HashMap::new(),
            params: HashMap::new(),
            query: HashMap::new(),
        };

        let response = challenge.handle_route(&ctx, req).await;
        assert_eq!(response.status, 200);
    }

    #[tokio::test]
    async fn test_handle_route_agent_not_found() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        let mut params = HashMap::new();
        params.insert("hash".to_string(), "nonexistent".to_string());

        let req = RouteRequest {
            path: "/agent/nonexistent".to_string(),
            method: "GET".to_string(),
            body: None,
            headers: HashMap::new(),
            params,
            query: HashMap::new(),
        };

        let response = challenge.handle_route(&ctx, req).await;
        assert_eq!(response.status, 404);
    }

    #[tokio::test]
    async fn test_calculate_weights_empty() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        let weights = challenge.calculate_weights(&ctx).await;
        assert!(weights.is_ok());
        assert!(weights.unwrap().is_empty()); // Empty leaderboard = no weights
    }

    // ==================== Additional Coverage Tests ====================

    #[test]
    fn test_with_tasks_per_evaluation_chaining() {
        let challenge = TerminalBenchChallenge::new("Test", 1, 0.5, PathBuf::from("./tasks"))
            .with_tasks_per_evaluation(15);

        assert_eq!(challenge.tasks_per_evaluation, 15);
    }

    #[test]
    fn test_with_max_concurrent_chaining() {
        let challenge = TerminalBenchChallenge::new("Test", 1, 0.5, PathBuf::from("./tasks"))
            .with_max_concurrent(16);

        assert_eq!(challenge.max_concurrent, 16);
    }

    #[test]
    fn test_challenge_mechanism_id() {
        let challenge = TerminalBenchChallenge::new("Test", 42, 0.5, PathBuf::from("./tasks"));

        assert_eq!(challenge.mechanism_id, 42);
    }

    #[test]
    fn test_challenge_metadata_mechanism_id() {
        let challenge = TerminalBenchChallenge::new("Test", 99, 0.75, PathBuf::from("./tasks"));
        let metadata = challenge.metadata();

        assert_eq!(metadata.config.mechanism_id, 99);
    }

    #[tokio::test]
    async fn test_handle_route_whitelist_modules() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        let req = RouteRequest {
            path: "/whitelist/modules".to_string(),
            method: "GET".to_string(),
            body: None,
            headers: HashMap::new(),
            params: HashMap::new(),
            query: HashMap::new(),
        };

        let response = challenge.handle_route(&ctx, req).await;
        assert_eq!(response.status, 200);
    }

    #[tokio::test]
    async fn test_handle_route_whitelist_models() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        let req = RouteRequest {
            path: "/whitelist/models".to_string(),
            method: "GET".to_string(),
            body: None,
            headers: HashMap::new(),
            params: HashMap::new(),
            query: HashMap::new(),
        };

        let response = challenge.handle_route(&ctx, req).await;
        assert_eq!(response.status, 200);
    }

    #[tokio::test]
    async fn test_handle_route_pricing() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        let req = RouteRequest {
            path: "/pricing".to_string(),
            method: "GET".to_string(),
            body: None,
            headers: HashMap::new(),
            params: HashMap::new(),
            query: HashMap::new(),
        };

        let response = challenge.handle_route(&ctx, req).await;
        assert_eq!(response.status, 200);
    }

    #[tokio::test]
    async fn test_handle_route_agents_pending() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        let req = RouteRequest {
            path: "/agents/pending".to_string(),
            method: "GET".to_string(),
            body: None,
            headers: HashMap::new(),
            params: HashMap::new(),
            query: HashMap::new(),
        };

        let response = challenge.handle_route(&ctx, req).await;
        assert_eq!(response.status, 200);
    }

    #[tokio::test]
    async fn test_handle_route_agents_active() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        let req = RouteRequest {
            path: "/agents/active".to_string(),
            method: "GET".to_string(),
            body: None,
            headers: HashMap::new(),
            params: HashMap::new(),
            query: HashMap::new(),
        };

        let response = challenge.handle_route(&ctx, req).await;
        assert_eq!(response.status, 200);
    }

    #[tokio::test]
    async fn test_handle_route_can_submit_no_stake() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        let req = RouteRequest {
            path: "/can_submit".to_string(),
            method: "GET".to_string(),
            body: None,
            headers: HashMap::new(),
            params: HashMap::new(),
            query: HashMap::new(), // No stake parameter
        };

        let response = challenge.handle_route(&ctx, req).await;
        assert_eq!(response.status, 200);
        assert_eq!(response.body["allowed"], false); // Default stake=0 should fail
    }

    #[tokio::test]
    async fn test_handle_route_can_submit_invalid_stake() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        let mut query = HashMap::new();
        query.insert("stake".to_string(), "not_a_number".to_string());

        let req = RouteRequest {
            path: "/can_submit".to_string(),
            method: "GET".to_string(),
            body: None,
            headers: HashMap::new(),
            params: HashMap::new(),
            query,
        };

        let response = challenge.handle_route(&ctx, req).await;
        assert_eq!(response.status, 200);
        assert_eq!(response.body["allowed"], false); // Invalid stake parses as 0
    }

    #[tokio::test]
    async fn test_handle_route_can_submit_exact_minimum() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        let mut query = HashMap::new();
        query.insert("stake".to_string(), "1000000000000".to_string()); // Exactly 1000 TAO

        let req = RouteRequest {
            path: "/can_submit".to_string(),
            method: "GET".to_string(),
            body: None,
            headers: HashMap::new(),
            params: HashMap::new(),
            query,
        };

        let response = challenge.handle_route(&ctx, req).await;
        assert_eq!(response.status, 200);
        assert_eq!(response.body["allowed"], true); // Exactly minimum should be allowed
    }

    #[tokio::test]
    async fn test_record_evaluation_result_updates_cache() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));

        let results = vec![TaskResult {
            task_id: "task1".to_string(),
            agent_hash: "agent123".to_string(),
            passed: true,
            score: 1.0,
            execution_time_ms: 1000,
            test_output: "PASS".to_string(),
            agent_output: "Success".to_string(),
            error: None,
            timestamp: chrono::Utc::now(),
        }];

        challenge
            .record_evaluation_result(
                "agent123".to_string(),
                "miner123".to_string(),
                results.clone(),
            )
            .await;

        // Check cache
        let cache = challenge.results_cache.read().await;
        assert!(cache.contains_key("agent123"));
        assert_eq!(cache.get("agent123").unwrap().len(), 1);
    }

    #[tokio::test]
    async fn test_get_cached_results() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));

        // Initially empty
        let result = challenge.get_cached_results("nonexistent").await;
        assert!(result.is_none());

        // Add to cache directly
        {
            let mut cache = challenge.results_cache.write().await;
            cache.insert(
                "agent1".to_string(),
                vec![TaskResult {
                    task_id: "task1".to_string(),
                    agent_hash: "agent1".to_string(),
                    passed: true,
                    score: 0.9,
                    execution_time_ms: 500,
                    test_output: "OK".to_string(),
                    agent_output: "Done".to_string(),
                    error: None,
                    timestamp: chrono::Utc::now(),
                }],
            );
        }

        // Now should find it
        let result = challenge.get_cached_results("agent1").await;
        assert!(result.is_some());
        assert_eq!(result.unwrap().len(), 1);
    }

    #[tokio::test]
    async fn test_calculate_weights_with_entries() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));

        // Add entries to leaderboard directly
        {
            let mut lb = challenge.leaderboard.write().await;
            lb.update(
                "agent1".to_string(),
                "miner1".to_string(),
                crate::weights::scoring::AggregateScore {
                    total_score: 8.0,
                    normalized_score: 0.8,
                    max_possible: 10.0,
                    tasks_passed: 8,
                    tasks_failed: 2,
                    pass_rate: 0.8,
                    by_difficulty: std::collections::HashMap::new(),
                    total_cost_usd: Some(0.5),
                    total_execution_time_ms: Some(5000),
                },
            );
            lb.update(
                "agent2".to_string(),
                "miner2".to_string(),
                crate::weights::scoring::AggregateScore {
                    total_score: 6.0,
                    normalized_score: 0.6,
                    max_possible: 10.0,
                    tasks_passed: 6,
                    tasks_failed: 4,
                    pass_rate: 0.6,
                    by_difficulty: std::collections::HashMap::new(),
                    total_cost_usd: Some(0.3),
                    total_execution_time_ms: Some(8000),
                },
            );
        }

        let ctx = ChallengeContext::default();
        let weights = challenge.calculate_weights(&ctx).await;
        assert!(weights.is_ok());
        let weights = weights.unwrap();
        assert_eq!(weights.len(), 2);

        // Weights should be proportional: 0.8/(0.8+0.6) and 0.6/(0.8+0.6)
        // Total = 1.4, so agent1 gets 0.8/1.4 ≈ 0.571 * 65535 ≈ 37448
        // and agent2 gets 0.6/1.4 ≈ 0.429 * 65535 ≈ 28087
        let total_weight: u32 = weights.iter().map(|w| w.weight as u32).sum();
        assert!(total_weight > 60000); // Should be close to 65535
    }

    #[tokio::test]
    async fn test_calculate_weights_zero_scores() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));

        // Add entries with zero scores
        {
            let mut lb = challenge.leaderboard.write().await;
            lb.update(
                "agent1".to_string(),
                "miner1".to_string(),
                crate::weights::scoring::AggregateScore {
                    total_score: 0.0,
                    normalized_score: 0.0,
                    max_possible: 10.0,
                    tasks_passed: 0,
                    tasks_failed: 10,
                    pass_rate: 0.0,
                    by_difficulty: std::collections::HashMap::new(),
                    total_cost_usd: None,
                    total_execution_time_ms: Some(1000),
                },
            );
        }

        let ctx = ChallengeContext::default();
        let weights = challenge.calculate_weights(&ctx).await;
        assert!(weights.is_ok());
        // With total_score = 0, should return empty weights
        assert!(weights.unwrap().is_empty());
    }

    #[tokio::test]
    async fn test_handle_route_agent_found() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        // Add an agent to leaderboard
        {
            let mut lb = challenge.leaderboard.write().await;
            lb.update(
                "found_agent".to_string(),
                "miner1".to_string(),
                crate::weights::scoring::AggregateScore {
                    total_score: 5.0,
                    normalized_score: 0.5,
                    max_possible: 10.0,
                    tasks_passed: 5,
                    tasks_failed: 5,
                    pass_rate: 0.5,
                    by_difficulty: std::collections::HashMap::new(),
                    total_cost_usd: Some(0.1),
                    total_execution_time_ms: Some(2000),
                },
            );
        }

        let mut params = HashMap::new();
        params.insert("hash".to_string(), "found_agent".to_string());

        let req = RouteRequest {
            path: "/agent/found_agent".to_string(),
            method: "GET".to_string(),
            body: None,
            headers: HashMap::new(),
            params,
            query: HashMap::new(),
        };

        let response = challenge.handle_route(&ctx, req).await;
        assert_eq!(response.status, 200);
    }

    #[tokio::test]
    async fn test_handle_route_method_mismatch() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        // POST to a GET-only endpoint
        let req = RouteRequest {
            path: "/leaderboard".to_string(),
            method: "POST".to_string(), // Should be GET
            body: None,
            headers: HashMap::new(),
            params: HashMap::new(),
            query: HashMap::new(),
        };

        let response = challenge.handle_route(&ctx, req).await;
        assert_eq!(response.status, 404); // Falls through to not_found
    }

    #[tokio::test]
    async fn test_handle_route_status_hash() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        let req = RouteRequest {
            path: "/status/some_hash".to_string(),
            method: "GET".to_string(),
            body: None,
            headers: HashMap::new(),
            params: HashMap::new(),
            query: HashMap::new(),
        };

        let response = challenge.handle_route(&ctx, req).await;
        // This route is not implemented - falls through to not_found
        assert_eq!(response.status, 404);
    }

    #[tokio::test]
    async fn test_default_routes_completeness() {
        let routes = TerminalBenchChallenge::default_routes();

        // Verify all expected paths are present
        let paths: Vec<&str> = routes.iter().map(|r| r.path.as_str()).collect();

        assert!(paths.contains(&"/submit"));
        assert!(paths.contains(&"/can_submit"));
        assert!(paths.contains(&"/status/:hash"));
        assert!(paths.contains(&"/agent/:hash"));
        assert!(paths.contains(&"/agents/miner/:hotkey"));
        assert!(paths.contains(&"/agents/pending"));
        assert!(paths.contains(&"/agents/active"));
        assert!(paths.contains(&"/config"));
        assert!(paths.contains(&"/whitelist"));
        assert!(paths.contains(&"/whitelist/modules"));
        assert!(paths.contains(&"/whitelist/models"));
        assert!(paths.contains(&"/pricing"));
        assert!(paths.contains(&"/stats"));
        assert!(paths.contains(&"/leaderboard"));
        assert!(paths.contains(&"/progress/:evaluation_id"));
        assert!(paths.contains(&"/progress/agent/:hash"));
    }

    #[test]
    fn test_routes_method_types() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let routes = challenge.routes();

        // Check POST routes
        let post_routes: Vec<&ChallengeRoute> =
            routes.iter().filter(|r| r.method == "POST").collect();
        assert!(!post_routes.is_empty());

        // Check GET routes
        let get_routes: Vec<&ChallengeRoute> =
            routes.iter().filter(|r| r.method == "GET").collect();
        assert!(get_routes.len() > post_routes.len()); // More GET than POST
    }

    #[test]
    fn test_emission_weight_accessor() {
        let challenge = TerminalBenchChallenge::new("Test", 1, 0.333, PathBuf::from("./tasks"));
        assert!((challenge.emission_weight() - 0.333).abs() < 0.001);
    }

    #[test]
    fn test_challenge_name_accessor() {
        let challenge =
            TerminalBenchChallenge::new("My Custom Name", 1, 0.5, PathBuf::from("./tasks"));
        assert_eq!(challenge.name(), "My Custom Name");
    }

    #[tokio::test]
    async fn test_validate_agent_with_metadata() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        let agent = SdkAgentInfo {
            agent_hash: "hash_with_meta".to_string(),
            miner_hotkey: "5Grwva...".to_string(),
            name: Some("Named Agent".to_string()),
            source_code: Some("print('hello')".to_string()),
            api_key_encrypted: Some("encrypted_key".to_string()),
            submitted_at: chrono::Utc::now().timestamp(),
        };

        let result = challenge.validate_agent(&ctx, &agent).await;
        assert!(result.is_ok());
        assert!(result.unwrap());
    }

    #[tokio::test]
    async fn test_stats_with_entries() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        // Add entries with different pass rates
        {
            let mut lb = challenge.leaderboard.write().await;
            lb.update(
                "active_agent".to_string(),
                "miner1".to_string(),
                crate::weights::scoring::AggregateScore {
                    total_score: 5.0,
                    normalized_score: 0.5,
                    max_possible: 10.0,
                    tasks_passed: 5,
                    tasks_failed: 5,
                    pass_rate: 0.5, // > 0.0, so active
                    by_difficulty: std::collections::HashMap::new(),
                    total_cost_usd: None,
                    total_execution_time_ms: Some(1000),
                },
            );
            lb.update(
                "inactive_agent".to_string(),
                "miner2".to_string(),
                crate::weights::scoring::AggregateScore {
                    total_score: 0.0,
                    normalized_score: 0.0,
                    max_possible: 10.0,
                    tasks_passed: 0,
                    tasks_failed: 10,
                    pass_rate: 0.0, // = 0.0, so inactive
                    by_difficulty: std::collections::HashMap::new(),
                    total_cost_usd: None,
                    total_execution_time_ms: Some(500),
                },
            );
        }

        let req = RouteRequest {
            path: "/stats".to_string(),
            method: "GET".to_string(),
            body: None,
            headers: HashMap::new(),
            params: HashMap::new(),
            query: HashMap::new(),
        };

        let response = challenge.handle_route(&ctx, req).await;
        assert_eq!(response.status, 200);
        assert_eq!(response.body["total_agents"], 2);
        assert_eq!(response.body["active_agents"], 1); // Only one with pass_rate > 0
    }

    // ==================== Line 125: Registry lazy loading path ====================

    #[tokio::test]
    async fn test_registry_lazy_loading_with_invalid_path() {
        // This tests line 125 - the path where registry is None and load_tasks is called
        // Using an invalid path that exists but contains invalid task configs should work gracefully
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("/nonexistent/path"));

        // Registry should be None initially
        {
            let guard = challenge.task_registry.read().await;
            assert!(guard.is_none());
        }

        // Calling registry() when it's None will try to load_tasks()
        // which executes line 125 (lazy load path)
        // TaskRegistry::new gracefully handles missing directories by returning empty registry
        let result = challenge.registry().await;
        // The registry should now be loaded (even if empty for non-existent path)
        assert!(
            result.is_ok(),
            "Expected successful registry load (empty), got Err: {:?}",
            result.err()
        );
        // Verify registry was actually loaded (not None anymore)
        let guard = challenge.task_registry.read().await;
        assert!(guard.is_some(), "Registry should be loaded after lazy load");
    }

    #[tokio::test]
    async fn test_registry_returns_existing() {
        // Test the path where registry is already loaded (line 126 - Ok(guard))
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./data/tasks"));

        // Pre-load the registry
        {
            let mut guard = challenge.task_registry.write().await;
            // Create a mock registry if we can, or just mark as Some
            if let Ok(registry) = TaskRegistry::new(PathBuf::from("./data/tasks")) {
                *guard = Some(registry);
            }
        }

        // Now registry() should return the existing guard without calling load_tasks
        let result = challenge.registry().await;
        // Should succeed if tasks dir exists
        if let Ok(guard) = result {
            assert!(guard.is_some());
        }
    }

    // ==================== run_evaluation tests ====================

    #[tokio::test]
    async fn test_run_evaluation_registry_not_loaded_error() {
        // This tests the error path when registry is None after load attempt
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("/invalid/path"));

        let agent = AgentInfo {
            hash: "test_hash".to_string(),
            miner_hotkey: "miner1".to_string(),
            image: "test-image:latest".to_string(),
            endpoint: None,
            source_code: None,
            language: None,
            env_vars: Vec::new(),
        };

        let result = challenge.run_evaluation(&agent).await;
        // Should fail because registry can't be loaded from invalid path
        assert!(result.is_err());
    }

    // ==================== on_startup tests ====================

    #[tokio::test]
    async fn test_on_startup_with_invalid_tasks_dir() {
        // Test on_startup with a path that exists but has no tasks
        // TaskRegistry::new doesn't fail on missing dirs, it creates an empty registry
        let challenge =
            create_terminal_bench_challenge(1, 0.5, PathBuf::from("/nonexistent/tasks/dir"));
        let ctx = ChallengeContext::default();

        let result = challenge.on_startup(&ctx).await;
        // TaskRegistry::new succeeds even with invalid path (returns empty registry)
        // So on_startup should succeed
        assert!(result.is_ok());

        // Registry should be set but empty
        let guard = challenge.task_registry.read().await;
        assert!(guard.is_some());
        assert_eq!(guard.as_ref().unwrap().count(), 0);
    }

    #[tokio::test]
    async fn test_on_startup_with_valid_tasks_dir() {
        // Test on_startup success path (if data/tasks exists)
        let tasks_dir = PathBuf::from("./data/tasks");

        if tasks_dir.exists() {
            let challenge = create_terminal_bench_challenge(1, 0.5, tasks_dir);
            let ctx = ChallengeContext::default();

            let result = challenge.on_startup(&ctx).await;
            assert!(result.is_ok());

            // Registry should now be loaded
            let guard = challenge.task_registry.read().await;
            assert!(guard.is_some());
        }
    }

    // ==================== evaluate tests ====================

    #[tokio::test]
    async fn test_evaluate_with_image_in_payload() {
        // Test evaluate extracts image from payload
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("/invalid/path"));
        let ctx = ChallengeContext::default();

        let agent = SdkAgentInfo {
            agent_hash: "agent123".to_string(),
            miner_hotkey: "miner456".to_string(),
            name: Some("Test Agent".to_string()),
            source_code: None,
            api_key_encrypted: None,
            submitted_at: chrono::Utc::now().timestamp(),
        };

        let payload = serde_json::json!({
            "image": "custom-image:v1",
            "endpoint": "http://localhost:8080"
        });

        // This will fail because registry can't be loaded, but it exercises the
        // payload extraction code paths
        let result = challenge.evaluate(&ctx, &agent, payload).await;
        assert!(result.is_err());
    }

    #[tokio::test]
    async fn test_evaluate_without_image_uses_hash() {
        // Test evaluate uses agent_hash when no image in payload
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("/invalid/path"));
        let ctx = ChallengeContext::default();

        let agent = SdkAgentInfo {
            agent_hash: "fallback_hash".to_string(),
            miner_hotkey: "miner789".to_string(),
            name: None,
            source_code: None,
            api_key_encrypted: None,
            submitted_at: 0,
        };

        let payload = serde_json::json!({}); // No image field

        // This will fail, but exercises the code path where image defaults to hash
        let result = challenge.evaluate(&ctx, &agent, payload).await;
        assert!(result.is_err());
    }

    #[tokio::test]
    async fn test_evaluate_error_from_run_evaluation() {
        // Test that run_evaluation errors are properly converted to ChallengeError::Evaluation
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("/invalid"));
        let ctx = ChallengeContext::default();

        let agent = SdkAgentInfo {
            agent_hash: "test".to_string(),
            miner_hotkey: "miner".to_string(),
            name: None,
            source_code: None,
            api_key_encrypted: None,
            submitted_at: 0,
        };

        let result = challenge
            .evaluate(&ctx, &agent, serde_json::json!({}))
            .await;
        assert!(result.is_err());

        // Should be either Evaluation or Internal error depending on where it fails
        match result.unwrap_err() {
            ChallengeError::Evaluation(_) | ChallengeError::Internal(_) => {}
            other => panic!("Unexpected error type: {:?}", other),
        }
    }

    #[tokio::test]
    async fn test_evaluate_extracts_endpoint_from_payload() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("/invalid"));
        let ctx = ChallengeContext::default();

        let agent = SdkAgentInfo {
            agent_hash: "agent_with_endpoint".to_string(),
            miner_hotkey: "miner".to_string(),
            name: None,
            source_code: None,
            api_key_encrypted: None,
            submitted_at: 0,
        };

        let payload = serde_json::json!({
            "endpoint": "http://agent-server:9000/api"
        });

        // Will fail but exercises endpoint extraction
        let result = challenge.evaluate(&ctx, &agent, payload).await;
        assert!(result.is_err());
    }

    #[tokio::test]
    async fn test_evaluate_with_null_payload_values() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("/invalid"));
        let ctx = ChallengeContext::default();

        let agent = SdkAgentInfo {
            agent_hash: "null_test".to_string(),
            miner_hotkey: "miner".to_string(),
            name: None,
            source_code: None,
            api_key_encrypted: None,
            submitted_at: 0,
        };

        // Payload with null values
        let payload = serde_json::json!({
            "image": null,
            "endpoint": null
        });

        let result = challenge.evaluate(&ctx, &agent, payload).await;
        assert!(result.is_err());
    }

    // ==================== record_evaluation_result additional tests ====================

    #[tokio::test]
    async fn test_record_evaluation_result_updates_leaderboard() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./data/tasks"));

        let results = vec![TaskResult {
            task_id: "task_for_lb".to_string(),
            agent_hash: "lb_agent".to_string(),
            passed: true,
            score: 1.0,
            execution_time_ms: 500,
            test_output: "PASS".to_string(),
            agent_output: "OK".to_string(),
            error: None,
            timestamp: chrono::Utc::now(),
        }];

        challenge
            .record_evaluation_result("lb_agent".to_string(), "lb_miner".to_string(), results)
            .await;

        // Leaderboard may or may not be updated depending on whether tasks can be loaded
        // But the cache should be updated regardless
        let cache = challenge.results_cache.read().await;
        assert!(cache.contains_key("lb_agent"));
    }

    #[tokio::test]
    async fn test_record_evaluation_result_empty_results() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./data/tasks"));

        let results: Vec<TaskResult> = vec![];

        challenge
            .record_evaluation_result(
                "empty_agent".to_string(),
                "empty_miner".to_string(),
                results,
            )
            .await;

        // Cache should have empty vec
        let cache = challenge.results_cache.read().await;
        assert!(cache.contains_key("empty_agent"));
        assert!(cache.get("empty_agent").unwrap().is_empty());
    }

    // ==================== calculate_weights_from_leaderboard tests ====================

    #[tokio::test]
    async fn test_calculate_weights_proportional() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));

        // Add entries with known scores for predictable weight calculation
        {
            let mut lb = challenge.leaderboard.write().await;
            lb.update(
                "agent_a".to_string(),
                "miner_a".to_string(),
                crate::weights::scoring::AggregateScore {
                    total_score: 1.0,
                    normalized_score: 0.25,
                    max_possible: 4.0,
                    tasks_passed: 1,
                    tasks_failed: 3,
                    pass_rate: 0.25,
                    by_difficulty: std::collections::HashMap::new(),
                    total_cost_usd: None,
                    total_execution_time_ms: None,
                },
            );
            lb.update(
                "agent_b".to_string(),
                "miner_b".to_string(),
                crate::weights::scoring::AggregateScore {
                    total_score: 3.0,
                    normalized_score: 0.75,
                    max_possible: 4.0,
                    tasks_passed: 3,
                    tasks_failed: 1,
                    pass_rate: 0.75,
                    by_difficulty: std::collections::HashMap::new(),
                    total_cost_usd: None,
                    total_execution_time_ms: None,
                },
            );
        }

        let weights = challenge.calculate_weights_from_leaderboard().await;
        assert_eq!(weights.len(), 2);

        // Total normalized = 0.25 + 0.75 = 1.0
        // agent_a should get 0.25/1.0 * 65535 ≈ 16383
        // agent_b should get 0.75/1.0 * 65535 ≈ 49151
        let total_weight: u32 = weights.iter().map(|w| w.weight as u32).sum();
        assert!(total_weight > 65000 && total_weight <= 65535);
    }

    // ==================== load_tasks tests ====================

    #[tokio::test]
    async fn test_load_tasks_invalid_directory() {
        // TaskRegistry::new doesn't fail on non-existent directories
        // It returns an empty registry instead
        let challenge =
            create_terminal_bench_challenge(1, 0.5, PathBuf::from("/definitely/not/a/real/path"));

        let result = challenge.load_tasks().await;
        // Should succeed with empty registry
        assert!(result.is_ok());

        // Registry should be empty
        let guard = challenge.task_registry.read().await;
        assert!(guard.is_some());
        assert_eq!(guard.as_ref().unwrap().count(), 0);
    }

    #[tokio::test]
    async fn test_load_tasks_valid_directory() {
        let tasks_dir = PathBuf::from("./data/tasks");

        if tasks_dir.exists() {
            let challenge = create_terminal_bench_challenge(1, 0.5, tasks_dir);

            let result = challenge.load_tasks().await;
            assert!(result.is_ok());

            // Verify registry is populated
            let guard = challenge.task_registry.read().await;
            assert!(guard.is_some());
            assert!(guard.as_ref().unwrap().count() > 0);
        }
    }

    // ==================== Additional edge cases ====================

    #[test]
    fn test_challenge_id_format() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let id = challenge.id();

        // ID should be a valid UUID-like string (first 16 chars)
        let id_str = id.as_str();
        assert_eq!(id_str.len(), 16); // ChallengeId truncates to 16 bytes
        assert!(id_str.chars().all(|c| c.is_ascii_hexdigit() || c == '-'));
    }

    #[test]
    fn test_challenge_builder_pattern() {
        let challenge = TerminalBenchChallenge::new("Builder Test", 5, 0.25, PathBuf::from("./t"))
            .with_tasks_per_evaluation(20)
            .with_max_concurrent(10);

        assert_eq!(challenge.name(), "Builder Test");
        assert_eq!(challenge.mechanism_id, 5);
        assert_eq!(challenge.emission_weight(), 0.25);
        assert_eq!(challenge.tasks_per_evaluation, 20);
        assert_eq!(challenge.max_concurrent, 10);
    }

    #[tokio::test]
    async fn test_multiple_record_evaluation_overwrites() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));

        // First record
        let results1 = vec![TaskResult {
            task_id: "t1".to_string(),
            agent_hash: "overwrite_agent".to_string(),
            passed: true,
            score: 1.0,
            execution_time_ms: 100,
            test_output: "".to_string(),
            agent_output: "".to_string(),
            error: None,
            timestamp: chrono::Utc::now(),
        }];

        challenge
            .record_evaluation_result("overwrite_agent".to_string(), "miner".to_string(), results1)
            .await;

        // Second record with different results - should overwrite
        let results2 = vec![
            TaskResult {
                task_id: "t2".to_string(),
                agent_hash: "overwrite_agent".to_string(),
                passed: false,
                score: 0.0,
                execution_time_ms: 200,
                test_output: "".to_string(),
                agent_output: "".to_string(),
                error: Some("failed".to_string()),
                timestamp: chrono::Utc::now(),
            },
            TaskResult {
                task_id: "t3".to_string(),
                agent_hash: "overwrite_agent".to_string(),
                passed: true,
                score: 0.5,
                execution_time_ms: 300,
                test_output: "".to_string(),
                agent_output: "".to_string(),
                error: None,
                timestamp: chrono::Utc::now(),
            },
        ];

        challenge
            .record_evaluation_result("overwrite_agent".to_string(), "miner".to_string(), results2)
            .await;

        // Cache should have 2 results now (from second record)
        let cache = challenge.results_cache.read().await;
        assert_eq!(cache.get("overwrite_agent").unwrap().len(), 2);
    }

    #[test]
    fn test_default_routes_descriptions() {
        let routes = TerminalBenchChallenge::default_routes();

        for route in routes {
            // Every route should have a non-empty description
            assert!(
                !route.description.is_empty(),
                "Route {} has no description",
                route.path
            );
        }
    }

    #[tokio::test]
    async fn test_handle_route_agents_miner_hotkey() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        let req = RouteRequest {
            path: "/agents/miner/5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY".to_string(),
            method: "GET".to_string(),
            body: None,
            headers: HashMap::new(),
            params: HashMap::new(),
            query: HashMap::new(),
        };

        let response = challenge.handle_route(&ctx, req).await;
        // This path is not specifically handled, falls through to not_found
        assert_eq!(response.status, 404);
    }

    #[tokio::test]
    async fn test_handle_route_progress_evaluation_id() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        let req = RouteRequest {
            path: "/progress/eval_12345".to_string(),
            method: "GET".to_string(),
            body: None,
            headers: HashMap::new(),
            params: HashMap::new(),
            query: HashMap::new(),
        };

        let response = challenge.handle_route(&ctx, req).await;
        // Not implemented, falls through
        assert_eq!(response.status, 404);
    }

    #[tokio::test]
    async fn test_handle_route_progress_agent_hash() {
        let challenge = create_terminal_bench_challenge(1, 0.5, PathBuf::from("./tasks"));
        let ctx = ChallengeContext::default();

        let req = RouteRequest {
            path: "/progress/agent/abc123".to_string(),
            method: "GET".to_string(),
            body: None,
            headers: HashMap::new(),
            params: HashMap::new(),
            query: HashMap::new(),
        };

        let response = challenge.handle_route(&ctx, req).await;
        // Not implemented, falls through
        assert_eq!(response.status, 404);
    }
}
