//! Term-Challenge API Endpoints
//!
//! Provides all REST endpoints for:
//! - Agent submissions (miners)
//! - Leaderboard (public)
//! - Owner endpoints (authenticated)
//! - Validator endpoints (whitelisted)

use crate::auth::{
    create_get_source_message, create_list_agents_message, create_submit_message,
    is_timestamp_valid, is_valid_ss58_hotkey, verify_signature, AuthManager,
};
use crate::storage::pg::{
    AgentLeaderboardEntry, LlmUsageRecord, PgStorage, Submission, SubmissionInfo, TaskAssignment,
    TaskLog, ValidatorJobInfo, ValidatorReadiness, DEFAULT_COST_LIMIT_USD, MAX_COST_LIMIT_USD,
    SUBMISSION_COOLDOWN_SECS,
};
use crate::validation::package::PackageValidator;
use crate::validation::whitelist::{PythonWhitelist, WhitelistConfig};
use axum::{
    body::Body,
    extract::{Path, Query, State},
    http::StatusCode,
    response::{IntoResponse, Response},
    Json,
};
use serde::{Deserialize, Serialize};
use sha2::{Digest, Sha256};
use std::sync::Arc;
use tracing::{debug, error, info, warn};

// Note: Validator selection has been moved to compile_worker.rs
// Validators are assigned after successful compilation for fresh assignment state

// ============================================================================
// UTILITIES
// ============================================================================

/// Truncate a string at a UTF-8 safe boundary.
/// Returns the truncated string with "(truncated)" suffix if the original was longer.
fn truncate_utf8_safe(s: &str, max_chars: usize) -> String {
    if s.chars().count() <= max_chars {
        return s.to_string();
    }
    // Find the byte index at the char boundary
    let truncated: String = s.chars().take(max_chars).collect();
    format!("{}...(truncated)", truncated)
}

/// Redact API keys and sensitive data from source code to prevent accidental exposure.
/// Supports Python, JSON, TOML formats.
/// Matches:
/// - Common API key patterns (OpenAI, Anthropic, OpenRouter, Groq, xAI, Chutes)
/// - Variables starting with PRIVATE_ (any format)
/// - Common secret variable names (*_API_KEY, *_SECRET, *_TOKEN, *_PASSWORD)
fn redact_api_keys(code: &str) -> String {
    use regex::Regex;

    // Order matters: more specific patterns first
    let patterns: &[(&str, &str)] = &[
        // ================================================================
        // API Key Patterns (direct matches)
        // ================================================================
        // Anthropic keys: sk-ant-...
        (r"sk-ant-[a-zA-Z0-9\-_]{20,}", "[REDACTED:sk-ant-***]"),
        // OpenRouter v2 keys: sk-or-...
        (r"sk-or-[a-zA-Z0-9\-_]{20,}", "[REDACTED:sk-or-***]"),
        // OpenAI project keys: sk-proj-...
        (r"sk-proj-[a-zA-Z0-9\-_]{20,}", "[REDACTED:sk-proj-***]"),
        // Generic sk- keys (OpenAI, OpenRouter): sk-...
        (r"sk-[a-zA-Z0-9]{20,}", "[REDACTED:sk-***]"),
        // xAI/Grok keys: xai-...
        (r"xai-[a-zA-Z0-9]{20,}", "[REDACTED:xai-***]"),
        // Groq keys: gsk_...
        (r"gsk_[a-zA-Z0-9]{20,}", "[REDACTED:gsk_***]"),
        // Generic key- prefix
        (r"key-[a-zA-Z0-9]{20,}", "[REDACTED:key-***]"),
        // Chutes keys: cpk_...
        (r"cpk_[a-zA-Z0-9]{20,}", "[REDACTED:cpk_***]"),
        // ================================================================
        // PRIVATE_ variables (Python/TOML: PRIVATE_X = "value")
        // ================================================================
        (
            r#"(PRIVATE_[A-Z0-9_]+\s*=\s*['"])([^'"]+)(['"])"#,
            "$1[REDACTED]$3",
        ),
        // PRIVATE_ in JSON: "PRIVATE_X": "value"
        (
            r#"("PRIVATE_[A-Z0-9_]+"\s*:\s*")([^"]+)(")"#,
            "$1[REDACTED]$3",
        ),
        // ================================================================
        // Common secret variable names (Python/TOML)
        // ================================================================
        (
            r#"(OPENAI_API_KEY\s*=\s*['"])([^'"]{10,})(['"])"#,
            "$1[REDACTED]$3",
        ),
        (
            r#"(ANTHROPIC_API_KEY\s*=\s*['"])([^'"]{10,})(['"])"#,
            "$1[REDACTED]$3",
        ),
        (
            r#"(OPENROUTER_API_KEY\s*=\s*['"])([^'"]{10,})(['"])"#,
            "$1[REDACTED]$3",
        ),
        (
            r#"(GROQ_API_KEY\s*=\s*['"])([^'"]{10,})(['"])"#,
            "$1[REDACTED]$3",
        ),
        (
            r#"(XAI_API_KEY\s*=\s*['"])([^'"]{10,})(['"])"#,
            "$1[REDACTED]$3",
        ),
        (
            r#"(CHUTES_API_KEY\s*=\s*['"])([^'"]{10,})(['"])"#,
            "$1[REDACTED]$3",
        ),
        // Generic *_SECRET, *_TOKEN, *_PASSWORD patterns (Python/TOML)
        (
            r#"([A-Z_]*(?:SECRET|TOKEN|PASSWORD|CREDENTIAL)[A-Z_]*\s*=\s*['"])([^'"]+)(['"])"#,
            "$1[REDACTED]$3",
        ),
        // Generic api_key = "..." pattern (Python/TOML)
        (
            r#"(api[_-]?key['"]*\s*[:=]\s*['"])([^'"]{20,})(['"])"#,
            "$1[REDACTED]$3",
        ),
        // ================================================================
        // JSON format patterns
        // ================================================================
        // JSON: "api_key": "value" or "apiKey": "value"
        (
            r#"("api[_-]?[kK]ey"\s*:\s*")([^"]{20,})(")"#,
            "$1[REDACTED]$3",
        ),
        // JSON: "*_API_KEY": "value"
        (
            r#"("[A-Z_]*API_KEY"\s*:\s*")([^"]{10,})(")"#,
            "$1[REDACTED]$3",
        ),
        // JSON: "*_SECRET": "value", "*_TOKEN": "value", "*_PASSWORD": "value"
        (
            r#"("[A-Z_]*(?:SECRET|TOKEN|PASSWORD|CREDENTIAL)[A-Z_]*"\s*:\s*")([^"]+)(")"#,
            "$1[REDACTED]$3",
        ),
    ];

    let mut result = code.to_string();
    for (pattern, replacement) in patterns {
        if let Ok(re) = Regex::new(pattern) {
            result = re.replace_all(&result, *replacement).to_string();
        }
    }
    result
}

// ============================================================================
// SHARED STATE
// ============================================================================

// Note: Validator selection and fetching has been moved to compile_worker.rs
// Validators are assigned after successful compilation for fresh assignment state

/// API state shared across all handlers
pub struct ApiState {
    pub storage: PgStorage,
    pub auth: AuthManager,
    pub platform_url: String,
    /// URL for internal evaluation calls (e.g., http://localhost:8081)
    pub evaluate_url: Option<String>,
    /// Challenge ID for event broadcasting
    pub challenge_id: String,
    /// WebSocket client for sending targeted notifications to validators
    pub platform_ws_client: Option<Arc<crate::client::websocket::platform::PlatformWsClient>>,
    /// Metagraph cache for stake-based validator verification
    pub metagraph_cache: Option<Arc<crate::cache::metagraph::MetagraphCache>>,
    /// Real-time task progress cache for live streaming
    pub task_stream_cache: Option<Arc<crate::cache::task_stream::TaskStreamCache>>,
}

impl ApiState {
    /// Check if a validator is authorized (has >= 10000 TAO stake or is whitelisted)
    pub async fn is_authorized_validator(&self, hotkey: &str) -> bool {
        // First check metagraph cache for stake-based auth (primary method)
        if let Some(ref cache) = self.metagraph_cache {
            if cache.has_sufficient_stake(hotkey) {
                return true;
            }
        }

        // Fallback to whitelist (for test mode or manual overrides)
        self.auth.is_whitelisted_validator(hotkey).await
    }
}

// ============================================================================
// SUBMISSION ENDPOINTS (Miners)
// ============================================================================

#[derive(Debug, Deserialize)]
pub struct SubmitAgentRequest {
    // ========================================================================
    // Mode 1: Single file submission (existing, backwards compatible)
    // ========================================================================
    /// Python source code (for single-file submissions)
    pub source_code: Option<String>,

    // ========================================================================
    // Mode 2: Package submission (new, multi-file)
    // ========================================================================
    /// Base64-encoded package archive (ZIP or TAR.GZ)
    pub package: Option<String>,
    /// Package format: "zip" or "tar.gz" (default: "zip")
    pub package_format: Option<String>,
    /// Entry point file within the package (default: "agent.py")
    pub entry_point: Option<String>,

    // ========================================================================
    // Common fields
    // ========================================================================
    pub miner_hotkey: String,
    pub signature: String,
    pub name: Option<String>,
    /// User's API key for LLM inferences (optional, serves as bridge for agent requests)
    pub api_key: Option<String>,
    /// API provider: openrouter, chutes, openai, anthropic, grok (default: openrouter)
    pub api_provider: Option<String>,
    /// Cost limit per validator in USD (0-100, default: 10)
    pub cost_limit_usd: Option<f64>,
}

#[derive(Debug, Serialize)]
pub struct SubmitAgentResponse {
    pub success: bool,
    pub submission_id: Option<String>,
    pub agent_hash: Option<String>,
    pub version: Option<i32>,
    pub cost_limit_usd: Option<f64>,
    pub error: Option<String>,
}

/// POST /api/v1/submit - Submit a new agent
///
/// Supports two submission modes:
/// 1. Single file: `source_code` field with Python code
/// 2. Package: `package` field with base64-encoded ZIP/TAR.GZ archive
///
/// Requires:
/// - Valid SS58 miner_hotkey
/// - Valid signature of "submit_agent:<sha256_of_content>"
/// - Rate limit: 1 submission per 3.6 hours per miner
/// - Unique agent name (or auto-version if same miner reuses name)
pub async fn submit_agent(
    State(state): State<Arc<ApiState>>,
    Json(req): Json<SubmitAgentRequest>,
) -> Result<Json<SubmitAgentResponse>, (StatusCode, Json<SubmitAgentResponse>)> {
    // Helper to create error response
    let err_response = |msg: String| SubmitAgentResponse {
        success: false,
        submission_id: None,
        agent_hash: None,
        version: None,
        cost_limit_usd: None,
        error: Some(msg),
    };

    // Validate miner_hotkey is a valid SS58 address
    if !is_valid_ss58_hotkey(&req.miner_hotkey) {
        warn!(
            "Invalid miner_hotkey format: {}",
            &req.miner_hotkey[..32.min(req.miner_hotkey.len())]
        );
        return Err((
            StatusCode::BAD_REQUEST,
            Json(err_response(format!(
                "Invalid miner_hotkey: must be a valid SS58 address. Received: {}",
                &req.miner_hotkey[..32.min(req.miner_hotkey.len())]
            ))),
        ));
    }

    // ========================================================================
    // Determine submission mode and validate content
    // ========================================================================

    let (is_package, source_code, package_data, package_format, entry_point, content_for_hash) =
        match (&req.source_code, &req.package) {
            // Mode 1: Single file submission
            (Some(code), None) => {
                // Validate with Python whitelist
                let whitelist = PythonWhitelist::new(WhitelistConfig::default());
                let validation = whitelist.verify(code);
                if !validation.valid {
                    return Err((
                        StatusCode::BAD_REQUEST,
                        Json(err_response(format!(
                            "Code validation failed: {}",
                            validation.errors.join(", ")
                        ))),
                    ));
                }

                (false, code.clone(), None, None, None, code.clone())
            }

            // Mode 2: Package submission
            (None, Some(pkg_base64)) => {
                // Decode base64
                let pkg_data = match base64::Engine::decode(
                    &base64::engine::general_purpose::STANDARD,
                    pkg_base64,
                ) {
                    Ok(data) => data,
                    Err(e) => {
                        return Err((
                            StatusCode::BAD_REQUEST,
                            Json(err_response(format!("Invalid base64 package: {}", e))),
                        ));
                    }
                };

                let format = req.package_format.as_deref().unwrap_or("zip");
                let entry = req.entry_point.as_deref().unwrap_or("agent.py");

                // Validate package
                let validator = PackageValidator::new();
                let validation = match validator.validate(&pkg_data, format, entry) {
                    Ok(v) => v,
                    Err(e) => {
                        return Err((
                            StatusCode::BAD_REQUEST,
                            Json(err_response(format!("Package validation error: {}", e))),
                        ));
                    }
                };

                if !validation.valid {
                    return Err((
                        StatusCode::BAD_REQUEST,
                        Json(err_response(format!(
                            "Package validation failed: {}",
                            validation.errors.join(", ")
                        ))),
                    ));
                }

                // Log warnings
                for warning in &validation.warnings {
                    warn!("Package warning: {}", warning);
                }

                (
                    true,
                    String::new(), // Empty source_code for packages
                    Some(pkg_data),
                    Some(format.to_string()),
                    Some(entry.to_string()),
                    pkg_base64.clone(), // Hash the base64 for signature
                )
            }

            // Error: Both provided
            (Some(_), Some(_)) => {
                return Err((
                    StatusCode::BAD_REQUEST,
                    Json(err_response(
                        "Cannot provide both source_code and package. Choose one.".to_string(),
                    )),
                ));
            }

            // Error: Neither provided
            (None, None) => {
                return Err((
                    StatusCode::BAD_REQUEST,
                    Json(err_response(
                        "Must provide either source_code (single file) or package (multi-file archive).".to_string(),
                    )),
                ));
            }
        };

    // Verify signature
    let expected_message = create_submit_message(&content_for_hash);
    let skip_auth = std::env::var("SKIP_AUTH")
        .map(|v| v == "1")
        .unwrap_or(false);
    if !skip_auth && !verify_signature(&req.miner_hotkey, &expected_message, &req.signature) {
        warn!(
            "Invalid signature for submission from {}",
            &req.miner_hotkey[..16.min(req.miner_hotkey.len())]
        );
        return Err((
            StatusCode::UNAUTHORIZED,
            Json(err_response(format!(
                "Invalid signature. Message to sign: '{}'. Use sr25519 signature.",
                expected_message
            ))),
        ));
    }

    // Check rate limit: 1 agent per 3.6 hours (skip in test mode)
    if !skip_auth {
        match state.storage.can_miner_submit(&req.miner_hotkey).await {
            Ok((can_submit, reason)) => {
                if !can_submit {
                    warn!(
                        "Rate limit exceeded for miner {}: {:?}",
                        &req.miner_hotkey[..16.min(req.miner_hotkey.len())],
                        reason
                    );
                    return Err((
                        StatusCode::TOO_MANY_REQUESTS,
                        Json(err_response(reason.unwrap_or_else(|| {
                            format!(
                                "Rate limit: 1 submission per {} hours",
                                SUBMISSION_COOLDOWN_SECS / 3600
                            )
                        }))),
                    ));
                }
            }
            Err(e) => {
                warn!("Failed to check rate limit: {:?}", e);
                return Err((
                    StatusCode::SERVICE_UNAVAILABLE,
                    Json(err_response(
                        "Rate limit check unavailable. Please retry later.".to_string(),
                    )),
                ));
            }
        }
    }

    // Get current epoch
    let epoch = state.storage.get_current_epoch().await.unwrap_or(0);

    // Check agent name uniqueness
    if let Some(ref name) = req.name {
        match state
            .storage
            .is_name_taken_by_other(name, &req.miner_hotkey)
            .await
        {
            Ok(taken) => {
                if taken {
                    warn!("Agent name '{}' already taken by another miner", name);
                    return Err((
                        StatusCode::CONFLICT,
                        Json(err_response(format!(
                            "Agent name '{}' is already taken by another miner.",
                            name
                        ))),
                    ));
                }
            }
            Err(e) => {
                warn!("Failed to check name uniqueness: {:?}", e);
            }
        }
    }

    // Get next version
    let version = state
        .storage
        .get_next_version(&req.miner_hotkey, req.name.as_deref())
        .await
        .unwrap_or(1);

    // Validate and clamp cost limit
    let cost_limit = req
        .cost_limit_usd
        .unwrap_or(DEFAULT_COST_LIMIT_USD)
        .clamp(0.0, MAX_COST_LIMIT_USD);

    // Compute hashes
    let source_hash = hex::encode(Sha256::digest(content_for_hash.as_bytes()));
    let agent_hash = format!(
        "{}{}",
        &hex::encode(Sha256::digest(req.miner_hotkey.as_bytes()))[..16],
        &source_hash[..16]
    );

    // Get active checkpoint for this submission
    let checkpoint_id = state
        .storage
        .get_active_checkpoint()
        .await
        .unwrap_or_else(|_| "checkpoint1".to_string());

    // Create submission
    let submission_id = uuid::Uuid::new_v4().to_string();
    let submission = Submission {
        id: submission_id.clone(),
        agent_hash: agent_hash.clone(),
        miner_hotkey: req.miner_hotkey.clone(),
        source_code,
        source_hash,
        name: req.name.clone(),
        version,
        epoch,
        status: "pending".to_string(),
        api_key: req.api_key,
        api_provider: req.api_provider,
        cost_limit_usd: cost_limit,
        total_cost_usd: 0.0,
        created_at: chrono::Utc::now().timestamp(),
        // Compilation fields
        binary: None,
        binary_size: 0,
        compile_status: "pending".to_string(),
        compile_error: None,
        compile_time_ms: 0,
        flagged: false,
        flag_reason: None,
        // Package fields
        is_package,
        package_data,
        package_format,
        entry_point,
        // Code visibility & decay (defaults)
        disable_public_code: false,
        disable_decay: false,
        // Checkpoint assignment
        checkpoint_id,
    };

    // Store submission
    if let Err(e) = state.storage.create_submission(&submission).await {
        warn!("Failed to create submission: {:?}", e);
        tracing::error!(
            "Submission error - id: {}, agent_hash: {}, is_package: {}, error: {:?}",
            submission.id,
            submission.agent_hash,
            submission.is_package,
            e
        );
        return Err((
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(err_response(format!("Failed to store submission: {}", e))),
        ));
    }

    // Add test validators in test mode
    if skip_auth {
        let test_validators = [
            "5FHneW46xGXgs5mUiveU4sbTyGBzmstUspZC92UhjJM694ty",
            "5FLSigC9HGRKVhB9FiEo4Y3koPsNmBmLJbpXg2mp1hXcS59Y",
            "5DAAnrj7VHTznn2AWBemMuyBwZWs6FNFjdyVXUeYum3PTXFy",
            "5HGjWAeFDfFCWPsjFQdVV2Msvz2XtMktvgocEZcCj68kUMaw",
        ];
        for v in test_validators {
            state.auth.add_validator(v).await;
        }
    }

    // Queue submission for evaluation (requires 2 validators)
    if let Err(e) = state
        .storage
        .queue_submission_for_evaluation(&submission_id, &agent_hash, &req.miner_hotkey, 2)
        .await
    {
        warn!("Failed to queue submission for evaluation: {:?}", e);
    }

    let submission_type = if is_package { "package" } else { "single-file" };
    info!(
        "Agent submitted: {} v{} ({}) from {} (epoch {}, cost: ${:.2})",
        &agent_hash[..16],
        version,
        submission_type,
        &req.miner_hotkey[..16.min(req.miner_hotkey.len())],
        epoch,
        cost_limit
    );

    // Broadcast "new_submission" event to validators
    {
        let platform_url = state.platform_url.clone();
        let challenge_id = state.challenge_id.clone();
        let broadcast_submission_id = submission_id.clone();
        let broadcast_agent_hash = agent_hash.clone();
        let broadcast_miner_hotkey = req.miner_hotkey.clone();
        let broadcast_name = req.name.clone();
        let broadcast_epoch = epoch;
        let broadcast_is_package = is_package;

        tokio::spawn(async move {
            let client = reqwest::Client::builder()
                .timeout(std::time::Duration::from_secs(30))
                .build()
                .unwrap_or_default();

            let event_payload = serde_json::json!({
                "submission_id": broadcast_submission_id,
                "agent_hash": broadcast_agent_hash,
                "miner_hotkey": broadcast_miner_hotkey,
                "name": broadcast_name,
                "epoch": broadcast_epoch,
                "is_package": broadcast_is_package,
            });

            let broadcast_request = serde_json::json!({
                "challenge_id": challenge_id,
                "event_name": "new_submission",
                "payload": event_payload,
            });

            let broadcast_secret = std::env::var("BROADCAST_SECRET").unwrap_or_default();

            match client
                .post(format!("{}/api/v1/events/broadcast", platform_url))
                .header("X-Broadcast-Secret", broadcast_secret)
                .json(&broadcast_request)
                .send()
                .await
            {
                Ok(response) => {
                    if response.status().is_success() {
                        info!(
                            "Broadcast new_submission event for agent {}",
                            &broadcast_agent_hash[..16]
                        );
                    } else {
                        warn!("Failed to broadcast event: {}", response.status());
                    }
                }
                Err(e) => {
                    warn!("Failed to broadcast event: {}", e);
                }
            }
        });
    }

    Ok(Json(SubmitAgentResponse {
        success: true,
        submission_id: Some(submission_id),
        agent_hash: Some(agent_hash),
        version: Some(version),
        cost_limit_usd: Some(cost_limit),
        error: None,
    }))
}

// ============================================================================
// LEADERBOARD ENDPOINTS (Public)
// ============================================================================

// ============================================================================
// PUBLIC CODE ENDPOINT
// ============================================================================

#[derive(Debug, Serialize)]
pub struct AgentCodeResponse {
    pub agent_hash: String,
    pub is_package: bool,
    pub package_format: Option<String>,
    pub entry_point: String,
    pub files: Vec<CodeFile>,
    pub total_size: usize,
}

#[derive(Debug, Serialize)]
pub struct CodeFile {
    pub path: String,
    pub content: String,
    pub size: usize,
}

#[derive(Debug, Serialize)]
pub struct CodeVisibilityError {
    pub error: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub hours_remaining: Option<f64>,
}

/// GET /api/v1/agent/{hash}/code - Get public agent code
///
/// Code is public if:
/// - 48+ hours since submission AND disable_public_code = false
///
/// Note: manually_validated does NOT affect code visibility (only leaderboard eligibility)
pub async fn get_agent_code(
    State(state): State<Arc<ApiState>>,
    Path(agent_hash): Path<String>,
) -> Result<Json<AgentCodeResponse>, (StatusCode, Json<CodeVisibilityError>)> {
    // 1. Fetch submission
    let submission = state
        .storage
        .get_submission(&agent_hash)
        .await
        .map_err(|e| {
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(CodeVisibilityError {
                    error: format!("Database error: {}", e),
                    hours_remaining: None,
                }),
            )
        })?
        .ok_or_else(|| {
            (
                StatusCode::NOT_FOUND,
                Json(CodeVisibilityError {
                    error: "Agent not found".to_string(),
                    hours_remaining: None,
                }),
            )
        })?;

    // 2. Check visibility - disabled by admin
    if submission.disable_public_code {
        return Err((
            StatusCode::FORBIDDEN,
            Json(CodeVisibilityError {
                error: "Code visibility disabled by owner".to_string(),
                hours_remaining: None,
            }),
        ));
    }

    // 3. Check visibility - time-based (24h)
    // Note: manually_validated does NOT bypass this - it only affects leaderboard eligibility
    let now = chrono::Utc::now().timestamp();
    let hours_since = (now - submission.created_at) as f64 / 3600.0;
    const VISIBILITY_HOURS: f64 = 24.0;

    if hours_since < VISIBILITY_HOURS {
        let hours_remaining = VISIBILITY_HOURS - hours_since;
        return Err((
            StatusCode::FORBIDDEN,
            Json(CodeVisibilityError {
                error: "Code not yet public".to_string(),
                hours_remaining: Some(hours_remaining),
            }),
        ));
    }

    // 4. Build response
    let (files, total_size, entry_point) = if submission.is_package {
        // Extract files from package
        if let Some(package_data) = &submission.package_data {
            let format = submission.package_format.as_deref().unwrap_or("zip");
            match extract_package_files(package_data, format) {
                Ok(extracted) => {
                    let total_size: usize = extracted.iter().map(|f| f.size).sum();
                    let files: Vec<CodeFile> = extracted
                        .into_iter()
                        .map(|f| CodeFile {
                            path: f.path,
                            size: f.size,
                            content: String::from_utf8_lossy(&f.content).to_string(),
                        })
                        .collect();
                    let entry = submission
                        .entry_point
                        .unwrap_or_else(|| "agent.py".to_string());
                    (files, total_size, entry)
                }
                Err(e) => {
                    return Err((
                        StatusCode::INTERNAL_SERVER_ERROR,
                        Json(CodeVisibilityError {
                            error: format!("Failed to extract package: {}", e),
                            hours_remaining: None,
                        }),
                    ));
                }
            }
        } else {
            return Err((
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(CodeVisibilityError {
                    error: "Package data not available".to_string(),
                    hours_remaining: None,
                }),
            ));
        }
    } else {
        // Single file submission
        let size = submission.source_code.len();
        let files = vec![CodeFile {
            path: "agent.py".to_string(),
            content: submission.source_code,
            size,
        }];
        (files, size, "agent.py".to_string())
    };

    // Redact API keys from all file contents before returning
    let files: Vec<CodeFile> = files
        .into_iter()
        .map(|f| CodeFile {
            path: f.path,
            size: f.size,
            content: redact_api_keys(&f.content),
        })
        .collect();

    Ok(Json(AgentCodeResponse {
        agent_hash: submission.agent_hash,
        is_package: submission.is_package,
        package_format: submission.package_format,
        entry_point,
        files,
        total_size,
    }))
}

/// Extract files from a package (ZIP or TAR.GZ)
fn extract_package_files(
    data: &[u8],
    format: &str,
) -> anyhow::Result<Vec<crate::validation::package::PackageFile>> {
    use std::io::{Cursor, Read};

    match format.to_lowercase().as_str() {
        "zip" => {
            let cursor = Cursor::new(data);
            let mut archive = zip::ZipArchive::new(cursor)?;
            let mut files = Vec::new();

            for i in 0..archive.len() {
                let mut file = archive.by_index(i)?;
                if file.is_dir() {
                    continue;
                }

                let path = file
                    .enclosed_name()
                    .map(|p| p.to_string_lossy().to_string())
                    .unwrap_or_default();

                if path.is_empty() {
                    continue;
                }

                let mut content = Vec::new();
                file.read_to_end(&mut content)?;

                files.push(crate::validation::package::PackageFile {
                    path,
                    size: content.len(),
                    content,
                    is_python: false,
                });
            }
            Ok(files)
        }
        "tar.gz" | "tgz" | "targz" => {
            use flate2::read::GzDecoder;
            use tar::Archive;

            let cursor = Cursor::new(data);
            let decoder = GzDecoder::new(cursor);
            let mut archive = Archive::new(decoder);
            let mut files = Vec::new();

            for entry in archive.entries()? {
                let mut entry = entry?;
                if entry.header().entry_type().is_dir() {
                    continue;
                }

                let path = entry.path()?.to_string_lossy().to_string();
                let mut content = Vec::new();
                entry.read_to_end(&mut content)?;

                files.push(crate::validation::package::PackageFile {
                    path,
                    size: content.len(),
                    content,
                    is_python: false,
                });
            }
            Ok(files)
        }
        _ => anyhow::bail!("Unsupported format: {}", format),
    }
}

// ============================================================================
// LEADERBOARD ENDPOINT
// ============================================================================

#[derive(Debug, Deserialize)]
pub struct LeaderboardQuery {
    pub limit: Option<i64>,
    /// Filter by checkpoint ID (e.g., "checkpoint1", "checkpoint2")
    /// If not provided, uses the currently active checkpoint
    pub checkpoint: Option<String>,
}

#[derive(Debug, Serialize)]
pub struct LeaderboardResponse {
    pub entries: Vec<LeaderboardEntryResponse>,
    pub total: usize,
}

#[derive(Debug, Serialize)]
pub struct LeaderboardEntryResponse {
    pub rank: i32,
    pub agent_hash: String,
    pub miner_hotkey: String,
    pub name: Option<String>,
    pub status: String,
    pub tasks_passed: i32,
    pub tasks_total: i32,
    pub success_rate: f64,
    pub num_validators: i32,
    pub manually_validated: bool,
    pub total_cost_usd: f64,
    pub weight: f64,
    pub decay_multiplier: f64,
    pub grace_period_remaining_hours: f64,
    pub submitted_at: String,
}

/// GET /api/v1/leaderboard - Get public leaderboard
///
/// No authentication required. Does NOT include source code.
/// Returns only fully evaluated agents (status='completed') sorted by tasks_passed.
///
/// Query parameters:
/// - limit: Maximum number of entries (default: 100, max: 1000)
/// - checkpoint: Filter by checkpoint ID (default: active checkpoint)
pub async fn get_leaderboard(
    State(state): State<Arc<ApiState>>,
    Query(query): Query<LeaderboardQuery>,
) -> Result<Json<LeaderboardResponse>, (StatusCode, String)> {
    let limit = query.limit.unwrap_or(100).min(1000);

    // Determine which checkpoint to use
    let checkpoint_id: Option<String> = match &query.checkpoint {
        Some(cp) => Some(cp.clone()),
        None => {
            // Use active checkpoint by default
            state.storage.get_active_checkpoint().await.ok()
        }
    };

    // Convert owned String to &str for the query
    let checkpoint_ref = checkpoint_id.as_deref();

    let entries = state
        .storage
        .get_agent_leaderboard_by_checkpoint(limit, checkpoint_ref)
        .await
        .map_err(|e| (StatusCode::INTERNAL_SERVER_ERROR, e.to_string()))?;

    // Load time decay config from environment
    let decay_config = crate::weights::time_decay::TimeDecayConfig::from_env();

    // Find the winner (first manually_validated entry with >= 2 validators and >= 8 tasks passed per validator)
    let winner_hash: Option<String> = entries
        .iter()
        .find(|e| {
            e.manually_validated
                && e.num_validators >= 2
                && e.total_tasks_passed >= 8 * e.num_validators
        })
        .map(|e| e.agent_hash.clone());

    let response_entries: Vec<LeaderboardEntryResponse> = entries
        .into_iter()
        .enumerate()
        .map(|(i, e)| {
            // Calculate decay info for this entry (skip if decay is disabled)
            let decay_info =
                crate::weights::time_decay::calculate_decay_info(e.created_at, &decay_config);

            // Apply decay multiplier only if decay is enabled for this agent
            let effective_multiplier = if e.disable_decay {
                1.0 // No decay
            } else {
                decay_info.multiplier
            };

            // Weight is effective_multiplier for the winner (winner-takes-all with decay), 0.0 for others
            let weight = if Some(&e.agent_hash) == winner_hash.as_ref() {
                effective_multiplier
            } else {
                0.0
            };
            // Calculate success rate as percentage
            let success_rate = if e.total_tasks > 0 {
                (e.total_tasks_passed as f64 / e.total_tasks as f64) * 100.0
            } else {
                0.0
            };

            LeaderboardEntryResponse {
                rank: (i + 1) as i32,
                agent_hash: e.agent_hash,
                miner_hotkey: e.miner_hotkey,
                name: e.name,
                status: e.status,
                tasks_passed: e.total_tasks_passed,
                tasks_total: e.total_tasks,
                success_rate,
                num_validators: e.num_validators,
                manually_validated: e.manually_validated,
                total_cost_usd: e.total_cost_usd,
                weight,
                decay_multiplier: decay_info.multiplier,
                grace_period_remaining_hours: decay_info.grace_period_remaining_hours,
                submitted_at: e.created_at.to_rfc3339(),
            }
        })
        .collect();

    let total = response_entries.len();

    Ok(Json(LeaderboardResponse {
        entries: response_entries,
        total,
    }))
}

// ============================================================================
// CHECKPOINT ENDPOINTS
// ============================================================================

#[derive(Debug, Serialize)]
pub struct CheckpointResponse {
    pub id: String,
    pub name: String,
    pub description: Option<String>,
    pub tasks_count: i32,
    pub is_active: bool,
    pub submissions_count: i64,
    pub created_at: String,
    pub activated_at: Option<String>,
}

#[derive(Debug, Serialize)]
pub struct CheckpointsListResponse {
    pub checkpoints: Vec<CheckpointResponse>,
    pub active_checkpoint: String,
}

/// GET /api/v1/checkpoints - List all available checkpoints
///
/// No authentication required. Returns list of checkpoints with metadata.
pub async fn list_checkpoints(
    State(state): State<Arc<ApiState>>,
) -> Result<Json<CheckpointsListResponse>, (StatusCode, String)> {
    let checkpoints = state
        .storage
        .list_checkpoints()
        .await
        .map_err(|e| (StatusCode::INTERNAL_SERVER_ERROR, e.to_string()))?;

    let active = state
        .storage
        .get_active_checkpoint()
        .await
        .unwrap_or_else(|_| "checkpoint1".to_string());

    let mut responses = Vec::new();
    for cp in checkpoints {
        let submissions_count = state
            .storage
            .count_submissions_by_checkpoint(&cp.id)
            .await
            .unwrap_or(0);

        responses.push(CheckpointResponse {
            id: cp.id,
            name: cp.name,
            description: cp.description,
            tasks_count: cp.tasks_count,
            is_active: cp.is_active,
            submissions_count,
            created_at: chrono::DateTime::from_timestamp(cp.created_at, 0)
                .map(|dt| dt.to_rfc3339())
                .unwrap_or_default(),
            activated_at: cp.activated_at.map(|ts| {
                chrono::DateTime::from_timestamp(ts, 0)
                    .map(|dt| dt.to_rfc3339())
                    .unwrap_or_default()
            }),
        });
    }

    Ok(Json(CheckpointsListResponse {
        checkpoints: responses,
        active_checkpoint: active,
    }))
}

/// GET /api/v1/checkpoints/:id - Get checkpoint details
///
/// No authentication required.
pub async fn get_checkpoint(
    State(state): State<Arc<ApiState>>,
    Path(checkpoint_id): Path<String>,
) -> Result<Json<CheckpointResponse>, (StatusCode, String)> {
    let cp = state
        .storage
        .get_checkpoint(&checkpoint_id)
        .await
        .map_err(|e| (StatusCode::INTERNAL_SERVER_ERROR, e.to_string()))?
        .ok_or((StatusCode::NOT_FOUND, "Checkpoint not found".to_string()))?;

    let submissions_count = state
        .storage
        .count_submissions_by_checkpoint(&cp.id)
        .await
        .unwrap_or(0);

    Ok(Json(CheckpointResponse {
        id: cp.id,
        name: cp.name,
        description: cp.description,
        tasks_count: cp.tasks_count,
        is_active: cp.is_active,
        submissions_count,
        created_at: chrono::DateTime::from_timestamp(cp.created_at, 0)
            .map(|dt| dt.to_rfc3339())
            .unwrap_or_default(),
        activated_at: cp.activated_at.map(|ts| {
            chrono::DateTime::from_timestamp(ts, 0)
                .map(|dt| dt.to_rfc3339())
                .unwrap_or_default()
        }),
    }))
}

/// Agent status response including pending agents
#[derive(Debug, Serialize)]
pub struct AgentStatusResponse {
    pub agent_hash: String,
    pub miner_hotkey: String,
    pub name: Option<String>,
    pub status: String,
    pub rank: Option<i32>,
    pub best_score: Option<f64>,
    pub evaluation_count: i32,
    pub validators_completed: i32,
    pub total_validators: i32,
    pub submitted_at: Option<String>,
}

/// GET /api/v1/leaderboard/:agent_hash - Get agent details
///
/// No authentication required. Does NOT include source code.
/// Returns both evaluated agents and pending agents.
pub async fn get_agent_details(
    State(state): State<Arc<ApiState>>,
    Path(agent_hash): Path<String>,
) -> Result<Json<AgentStatusResponse>, (StatusCode, String)> {
    // First try to get agent entry (evaluated or not)
    if let Ok(Some(entry)) = state.storage.get_agent_entry(&agent_hash).await {
        let status = if entry.num_validators >= 2 {
            "completed".to_string()
        } else if entry.num_validators >= 1 {
            "evaluating".to_string()
        } else {
            "pending".to_string()
        };
        return Ok(Json(AgentStatusResponse {
            agent_hash: entry.agent_hash,
            miner_hotkey: entry.miner_hotkey,
            name: entry.name,
            status,
            rank: None, // Rank is computed dynamically in leaderboard
            best_score: Some(entry.total_tasks_passed as f64),
            evaluation_count: entry.num_validators,
            validators_completed: entry.num_validators,
            total_validators: 2, // Required validators
            submitted_at: Some(entry.created_at.to_rfc3339()),
        }));
    }

    // Try pending_evaluations (agents waiting for evaluation)
    if let Ok(Some(pending)) = state.storage.get_pending_status(&agent_hash).await {
        let submitted_at = chrono::DateTime::from_timestamp(pending.created_at, 0)
            .map(|dt| dt.to_rfc3339())
            .unwrap_or_default();
        return Ok(Json(AgentStatusResponse {
            agent_hash: pending.agent_hash,
            miner_hotkey: pending.miner_hotkey,
            name: None,
            status: pending.status,
            rank: None,
            best_score: None,
            evaluation_count: 0,
            validators_completed: pending.validators_completed,
            total_validators: pending.total_validators,
            submitted_at: Some(submitted_at),
        }));
    }

    // Try submissions (recently submitted but not yet queued)
    if let Ok(Some(sub)) = state.storage.get_submission_info(&agent_hash).await {
        let submitted_at = chrono::DateTime::from_timestamp(sub.created_at, 0)
            .map(|dt| dt.to_rfc3339())
            .unwrap_or_default();
        return Ok(Json(AgentStatusResponse {
            agent_hash: sub.agent_hash,
            miner_hotkey: sub.miner_hotkey,
            name: sub.name,
            status: sub.status,
            rank: None,
            best_score: None,
            evaluation_count: 0,
            validators_completed: 0,
            total_validators: 0,
            submitted_at: Some(submitted_at),
        }));
    }

    Err((StatusCode::NOT_FOUND, "Agent not found".to_string()))
}

/// GET /api/v1/agent/:agent_hash/status - Get detailed agent status with all phases
///
/// No authentication required. Returns comprehensive status info including:
/// - Compilation phase timing
/// - Agent initialization timing  
/// - Per-validator evaluation progress
/// - Task completion stats
pub async fn get_detailed_status(
    State(state): State<Arc<ApiState>>,
    Path(agent_hash): Path<String>,
) -> Result<Json<crate::storage::pg::DetailedAgentStatus>, (StatusCode, String)> {
    let status = state
        .storage
        .get_detailed_agent_status(&agent_hash)
        .await
        .map_err(|e| (StatusCode::INTERNAL_SERVER_ERROR, e.to_string()))?;

    match status {
        Some(s) => Ok(Json(s)),
        None => Err((StatusCode::NOT_FOUND, "Agent not found".to_string())),
    }
}

// ============================================================================
// OWNER ENDPOINTS (Authenticated miners - their own data only)
// ============================================================================

#[derive(Debug, Deserialize)]
pub struct AuthenticatedRequest {
    pub miner_hotkey: String,
    pub signature: String,
    pub timestamp: i64,
}

#[derive(Debug, Serialize)]
pub struct MyAgentsResponse {
    pub agents: Vec<SubmissionInfo>,
}

/// POST /api/v1/my/agents - List owner's agents
///
/// Requires authentication. Returns only the requesting miner's agents.
/// Does NOT include source code in listings.
pub async fn list_my_agents(
    State(state): State<Arc<ApiState>>,
    Json(req): Json<AuthenticatedRequest>,
) -> Result<Json<MyAgentsResponse>, (StatusCode, String)> {
    // Validate hotkey
    if !is_valid_ss58_hotkey(&req.miner_hotkey) {
        return Err((StatusCode::BAD_REQUEST, "Invalid hotkey format".to_string()));
    }

    // Validate timestamp
    if !is_timestamp_valid(req.timestamp) {
        return Err((StatusCode::BAD_REQUEST, "Timestamp expired".to_string()));
    }

    // Verify signature
    let message = create_list_agents_message(req.timestamp);
    if !verify_signature(&req.miner_hotkey, &message, &req.signature) {
        return Err((StatusCode::UNAUTHORIZED, "Invalid signature".to_string()));
    }

    // Get miner's submissions
    let agents = state
        .storage
        .get_miner_submissions(&req.miner_hotkey)
        .await
        .map_err(|e| (StatusCode::INTERNAL_SERVER_ERROR, e.to_string()))?;

    Ok(Json(MyAgentsResponse { agents }))
}

#[derive(Debug, Deserialize)]
pub struct GetSourceRequest {
    pub miner_hotkey: String,
    pub signature: String,
    pub timestamp: i64,
}

#[derive(Debug, Serialize)]
pub struct SourceCodeResponse {
    pub agent_hash: String,
    pub source_code: String,
    pub name: Option<String>,
}

/// POST /api/v1/my/agents/:agent_hash/source - Get source code of own agent
///
/// Requires authentication. Only returns source code if the requester owns the agent.
pub async fn get_my_agent_source(
    State(state): State<Arc<ApiState>>,
    Path(agent_hash): Path<String>,
    Json(req): Json<GetSourceRequest>,
) -> Result<Json<SourceCodeResponse>, (StatusCode, String)> {
    // Validate hotkey
    if !is_valid_ss58_hotkey(&req.miner_hotkey) {
        return Err((StatusCode::BAD_REQUEST, "Invalid hotkey format".to_string()));
    }

    // Validate timestamp
    if !is_timestamp_valid(req.timestamp) {
        return Err((StatusCode::BAD_REQUEST, "Timestamp expired".to_string()));
    }

    // Verify signature
    let message = create_get_source_message(&agent_hash, req.timestamp);
    if !verify_signature(&req.miner_hotkey, &message, &req.signature) {
        return Err((StatusCode::UNAUTHORIZED, "Invalid signature".to_string()));
    }

    // Get submission
    let submission = state
        .storage
        .get_submission(&agent_hash)
        .await
        .map_err(|e| (StatusCode::INTERNAL_SERVER_ERROR, e.to_string()))?
        .ok_or((StatusCode::NOT_FOUND, "Agent not found".to_string()))?;

    // Verify ownership
    if submission.miner_hotkey != req.miner_hotkey {
        warn!(
            "Unauthorized source access attempt: {} tried to access {}",
            &req.miner_hotkey[..16.min(req.miner_hotkey.len())],
            &agent_hash[..16]
        );
        return Err((
            StatusCode::FORBIDDEN,
            "You do not own this agent".to_string(),
        ));
    }

    Ok(Json(SourceCodeResponse {
        agent_hash: submission.agent_hash,
        source_code: submission.source_code,
        name: submission.name,
    }))
}

// ============================================================================
// VALIDATOR ENDPOINTS (Whitelisted validators only)
// ALL validators must evaluate each agent. 6h window for late validators.
// ============================================================================

#[derive(Debug, Deserialize)]
pub struct ClaimJobsRequest {
    pub validator_hotkey: String,
    pub signature: String,
    pub timestamp: i64,
    pub count: Option<usize>, // Max jobs to claim (default: 5, max: 10)
}

#[derive(Debug, Serialize)]
pub struct ClaimJobsResponse {
    pub success: bool,
    pub jobs: Vec<JobInfo>,
    pub total_available: usize,
    pub error: Option<String>,
}

#[derive(Debug, Serialize)]
pub struct JobInfo {
    pub pending_id: String,
    pub submission_id: String,
    pub agent_hash: String,
    pub miner_hotkey: String,
    /// Compiled binary (base64 encoded)
    pub binary_base64: String,
    /// Binary size in bytes
    pub binary_size: i32,
    pub window_expires_at: i64,
    pub tasks: Vec<TaskAssignment>,
}

/// POST /api/v1/validator/claim_jobs - Claim pending evaluation jobs
///
/// Each validator must evaluate ALL pending agents.
/// Returns jobs that this validator hasn't evaluated yet.
/// Window expires after 6h - late validators are exempt.
pub async fn claim_jobs(
    State(state): State<Arc<ApiState>>,
    Json(req): Json<ClaimJobsRequest>,
) -> Result<Json<ClaimJobsResponse>, (StatusCode, Json<ClaimJobsResponse>)> {
    // Validate hotkey
    if !is_valid_ss58_hotkey(&req.validator_hotkey) {
        return Err((
            StatusCode::BAD_REQUEST,
            Json(ClaimJobsResponse {
                success: false,
                jobs: vec![],
                total_available: 0,
                error: Some("Invalid hotkey format".to_string()),
            }),
        ));
    }

    // Validate timestamp
    if !is_timestamp_valid(req.timestamp) {
        return Err((
            StatusCode::BAD_REQUEST,
            Json(ClaimJobsResponse {
                success: false,
                jobs: vec![],
                total_available: 0,
                error: Some("Timestamp expired".to_string()),
            }),
        ));
    }

    // Verify signature (skip in test mode)
    let message = format!("claim_jobs:{}", req.timestamp);
    let skip_auth = std::env::var("SKIP_AUTH")
        .map(|v| v == "1")
        .unwrap_or(false);
    if !skip_auth && !verify_signature(&req.validator_hotkey, &message, &req.signature) {
        return Err((
            StatusCode::UNAUTHORIZED,
            Json(ClaimJobsResponse {
                success: false,
                jobs: vec![],
                total_available: 0,
                error: Some("Invalid signature".to_string()),
            }),
        ));
    }

    // Check if validator is authorized (>= 10000 TAO stake or whitelisted)
    if !skip_auth {
        if !state.is_authorized_validator(&req.validator_hotkey).await {
            warn!(
                "Unauthorized validator claim attempt: {} (insufficient stake)",
                &req.validator_hotkey[..16.min(req.validator_hotkey.len())]
            );
            return Err((
                StatusCode::FORBIDDEN,
                Json(ClaimJobsResponse {
                    success: false,
                    jobs: vec![],
                    total_available: 0,
                    error: Some(
                        "Validator not authorized (requires >= 10000 TAO stake)".to_string(),
                    ),
                }),
            ));
        }
    } else {
        // Auto-add to whitelist in test mode
        state.auth.add_validator(&req.validator_hotkey).await;
    }

    let count = req.count.unwrap_or(5).min(10);

    // Get jobs available for this validator
    let available_jobs = state
        .storage
        .get_jobs_for_validator(&req.validator_hotkey, count as i64)
        .await
        .map_err(|e| {
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(ClaimJobsResponse {
                    success: false,
                    jobs: vec![],
                    total_available: 0,
                    error: Some(e.to_string()),
                }),
            )
        })?;

    let total_available = available_jobs.len();

    if available_jobs.is_empty() {
        return Ok(Json(ClaimJobsResponse {
            success: true,
            jobs: vec![],
            total_available: 0,
            error: Some("No pending jobs for this validator".to_string()),
        }));
    }

    // Claim the jobs
    let agent_hashes: Vec<String> = available_jobs
        .iter()
        .map(|j| j.agent_hash.clone())
        .collect();
    let _ = state
        .storage
        .claim_jobs(&req.validator_hotkey, &agent_hashes)
        .await;

    let jobs: Vec<JobInfo> = available_jobs
        .into_iter()
        .map(|j| JobInfo {
            pending_id: j.pending_id,
            submission_id: j.submission_id,
            agent_hash: j.agent_hash,
            miner_hotkey: j.miner_hotkey,
            binary_base64: j.binary_base64,
            binary_size: j.binary_size,
            window_expires_at: j.window_expires_at,
            tasks: j.tasks,
        })
        .collect();

    info!(
        "Validator {} claimed {} jobs",
        &req.validator_hotkey[..16.min(req.validator_hotkey.len())],
        jobs.len()
    );

    Ok(Json(ClaimJobsResponse {
        success: true,
        jobs,
        total_available,
        error: None,
    }))
}

// ============================================================================
// VALIDATOR READINESS (Heartbeat for broker connectivity)
// ============================================================================

#[derive(Debug, Deserialize)]
pub struct ValidatorHeartbeatRequest {
    pub validator_hotkey: String,
    pub signature: String,
    pub timestamp: i64,
    pub is_ready: bool,
    pub broker_connected: bool,
    pub error_message: Option<String>,
}

#[derive(Debug, Serialize)]
pub struct ValidatorHeartbeatResponse {
    pub success: bool,
    pub message: String,
    pub error: Option<String>,
}

/// POST /api/v1/validator/heartbeat - Report validator readiness status
///
/// Validators must call this every 1 minute to report they are ready.
/// If broker is not connected, set broker_connected=false.
/// Validators with stale heartbeats (>2 min) are not used for task assignment.
pub async fn validator_heartbeat(
    State(state): State<Arc<ApiState>>,
    Json(req): Json<ValidatorHeartbeatRequest>,
) -> Result<Json<ValidatorHeartbeatResponse>, (StatusCode, Json<ValidatorHeartbeatResponse>)> {
    // Validate hotkey
    if !is_valid_ss58_hotkey(&req.validator_hotkey) {
        return Err((
            StatusCode::BAD_REQUEST,
            Json(ValidatorHeartbeatResponse {
                success: false,
                message: String::new(),
                error: Some("Invalid hotkey format".to_string()),
            }),
        ));
    }

    // Validate timestamp
    if !is_timestamp_valid(req.timestamp) {
        return Err((
            StatusCode::BAD_REQUEST,
            Json(ValidatorHeartbeatResponse {
                success: false,
                message: String::new(),
                error: Some("Timestamp expired".to_string()),
            }),
        ));
    }

    // Verify signature (skip in test mode)
    let message = format!("heartbeat:{}:{}", req.timestamp, req.is_ready);
    let skip_auth = std::env::var("SKIP_AUTH")
        .map(|v| v == "1")
        .unwrap_or(false);
    if !skip_auth && !verify_signature(&req.validator_hotkey, &message, &req.signature) {
        return Err((
            StatusCode::UNAUTHORIZED,
            Json(ValidatorHeartbeatResponse {
                success: false,
                message: String::new(),
                error: Some("Invalid signature".to_string()),
            }),
        ));
    }

    // Update readiness status
    state
        .storage
        .update_validator_readiness(
            &req.validator_hotkey,
            req.is_ready,
            req.broker_connected,
            req.error_message.as_deref(),
        )
        .await
        .map_err(|e| {
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(ValidatorHeartbeatResponse {
                    success: false,
                    message: String::new(),
                    error: Some(e.to_string()),
                }),
            )
        })?;

    let status = if req.is_ready && req.broker_connected {
        "ready"
    } else if req.broker_connected {
        "broker_ok_not_ready"
    } else {
        "broker_disconnected"
    };

    debug!(
        "Validator {} heartbeat: {} (broker={})",
        &req.validator_hotkey[..16.min(req.validator_hotkey.len())],
        status,
        req.broker_connected
    );

    Ok(Json(ValidatorHeartbeatResponse {
        success: true,
        message: format!("Heartbeat recorded: {}", status),
        error: None,
    }))
}

/// GET /api/v1/validators/readiness - Get all validator readiness statuses
pub async fn get_validators_readiness(
    State(state): State<Arc<ApiState>>,
) -> Result<Json<Vec<ValidatorReadiness>>, (StatusCode, Json<serde_json::Value>)> {
    let readiness = state
        .storage
        .get_all_validator_readiness()
        .await
        .map_err(|e| {
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(serde_json::json!({"error": e.to_string()})),
            )
        })?;

    Ok(Json(readiness))
}

/// GET /api/v1/validators/ready - Get only ready validators
pub async fn get_ready_validators(
    State(state): State<Arc<ApiState>>,
    Query(params): Query<std::collections::HashMap<String, String>>,
) -> Result<Json<Vec<ValidatorReadiness>>, (StatusCode, Json<serde_json::Value>)> {
    let limit = params
        .get("limit")
        .and_then(|s| s.parse().ok())
        .unwrap_or(10);

    let ready = state
        .storage
        .get_ready_validators(limit)
        .await
        .map_err(|e| {
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(serde_json::json!({"error": e.to_string()})),
            )
        })?;

    Ok(Json(ready))
}

// ============================================================================
// LOG TASK (Real-time task logging)
// ============================================================================

#[derive(Debug, Deserialize)]
pub struct LogTaskRequest {
    pub validator_hotkey: String,
    pub signature: String,
    pub timestamp: i64,
    pub agent_hash: String,
    pub task_id: String,
    pub task_name: String,
    pub passed: bool,
    pub score: f64,
    pub execution_time_ms: i64,
    pub steps: i32,
    pub cost_usd: f64,
    pub error: Option<String>,
    pub execution_log: Option<String>,
    pub trajectory: Option<serde_json::Value>,
    pub started_at: i64,
    // Verbose logging fields for debugging agent failures
    #[serde(default)]
    pub agent_stderr: Option<String>,
    #[serde(default)]
    pub agent_stdout: Option<String>,
    #[serde(default)]
    pub test_output: Option<String>,
    #[serde(default)]
    pub steps_executed: Option<i32>,
    /// For global failures (before tasks run): "download", "container_create", "binary_exec", etc.
    #[serde(default)]
    pub failure_stage: Option<String>,
}

#[derive(Debug, Serialize)]
pub struct LogTaskResponse {
    pub success: bool,
    pub tasks_logged: i32,
    pub tasks_total: i32,
    pub error: Option<String>,
}

/// POST /api/v1/validator/log_task - Log individual task result (real-time)
///
/// Validators call this endpoint after completing each task.
/// This allows real-time tracking and ensures all task data is saved.
pub async fn log_task(
    State(state): State<Arc<ApiState>>,
    Json(req): Json<LogTaskRequest>,
) -> Result<Json<LogTaskResponse>, (StatusCode, Json<LogTaskResponse>)> {
    // Validate hotkey
    if !is_valid_ss58_hotkey(&req.validator_hotkey) {
        return Err((
            StatusCode::BAD_REQUEST,
            Json(LogTaskResponse {
                success: false,
                tasks_logged: 0,
                tasks_total: 0,
                error: Some("Invalid hotkey format".to_string()),
            }),
        ));
    }

    // Validate timestamp
    if !is_timestamp_valid(req.timestamp) {
        return Err((
            StatusCode::BAD_REQUEST,
            Json(LogTaskResponse {
                success: false,
                tasks_logged: 0,
                tasks_total: 0,
                error: Some("Timestamp expired".to_string()),
            }),
        ));
    }

    // Verify signature (skip in test mode)
    let message = format!(
        "log_task:{}:{}:{}",
        req.agent_hash, req.task_id, req.timestamp
    );
    let skip_auth = std::env::var("SKIP_AUTH")
        .map(|v| v == "1")
        .unwrap_or(false);
    if !skip_auth && !verify_signature(&req.validator_hotkey, &message, &req.signature) {
        return Err((
            StatusCode::UNAUTHORIZED,
            Json(LogTaskResponse {
                success: false,
                tasks_logged: 0,
                tasks_total: 0,
                error: Some("Invalid signature".to_string()),
            }),
        ));
    }

    // Check if validator is authorized (>= 10000 TAO stake or whitelisted)
    if !skip_auth && !state.is_authorized_validator(&req.validator_hotkey).await {
        return Err((
            StatusCode::FORBIDDEN,
            Json(LogTaskResponse {
                success: false,
                tasks_logged: 0,
                tasks_total: 0,
                error: Some("Validator not authorized (requires >= 10000 TAO stake)".to_string()),
            }),
        ));
    }

    // Check if validator is assigned to this agent (skip in test mode)
    let is_assigned = if skip_auth {
        true // In test mode, allow any validator
    } else {
        state
            .storage
            .is_validator_assigned(&req.agent_hash, &req.validator_hotkey)
            .await
            .unwrap_or(false)
    };

    if !is_assigned {
        return Err((
            StatusCode::FORBIDDEN,
            Json(LogTaskResponse {
                success: false,
                tasks_logged: 0,
                tasks_total: 0,
                error: Some("Validator not assigned to this agent".to_string()),
            }),
        ));
    }

    // Create task log
    let task_log = TaskLog {
        id: uuid::Uuid::new_v4().to_string(),
        agent_hash: req.agent_hash.clone(),
        validator_hotkey: req.validator_hotkey.clone(),
        task_id: req.task_id.clone(),
        task_name: req.task_name.clone(),
        passed: req.passed,
        score: req.score,
        execution_time_ms: req.execution_time_ms,
        steps: req.steps,
        cost_usd: req.cost_usd,
        error: req.error,
        execution_log: req.execution_log,
        trajectory: req.trajectory,
        started_at: req.started_at,
        completed_at: chrono::Utc::now().timestamp(),
        // Verbose logging fields
        agent_stderr: req.agent_stderr,
        agent_stdout: req.agent_stdout,
        test_output: req.test_output,
        steps_executed: req.steps_executed,
        failure_stage: req.failure_stage,
    };

    // Store task log
    if let Err(e) = state.storage.store_task_log(&task_log).await {
        return Err((
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(LogTaskResponse {
                success: false,
                tasks_logged: 0,
                tasks_total: 0,
                error: Some(format!("Failed to store task log: {}", e)),
            }),
        ));
    }

    // Calculate and update cost from llm_usage table
    // This aggregates all LLM calls made during this task execution
    match state
        .storage
        .get_task_llm_cost(&req.agent_hash, &req.validator_hotkey, &req.task_id)
        .await
    {
        Ok(calculated_cost) if calculated_cost > 0.0 => {
            if let Err(e) = state
                .storage
                .update_task_log_cost(
                    &req.agent_hash,
                    &req.validator_hotkey,
                    &req.task_id,
                    calculated_cost,
                )
                .await
            {
                warn!(
                    "Failed to update task cost for {}/{}: {}",
                    &req.agent_hash[..16.min(req.agent_hash.len())],
                    &req.task_id,
                    e
                );
            } else {
                debug!(
                    "Updated task {} cost to ${:.4} from llm_usage",
                    &req.task_id, calculated_cost
                );
            }
        }
        Ok(_) => {
            // No LLM usage recorded for this task (agent might not use LLM)
        }
        Err(e) => {
            warn!("Failed to get task LLM cost: {}", e);
        }
    }

    // Get current progress
    let summary = state
        .storage
        .get_task_log_summary(&req.agent_hash, &req.validator_hotkey)
        .await
        .unwrap_or_default();

    // Remove from real-time cache now that task is persisted to DB
    if let Some(ref cache) = state.task_stream_cache {
        cache.remove(&req.agent_hash, &req.validator_hotkey, &req.task_id);
    }

    info!(
        "Task logged: {} {} task={} ({}/{} complete)",
        &req.validator_hotkey[..16.min(req.validator_hotkey.len())],
        &req.agent_hash[..16.min(req.agent_hash.len())],
        req.task_name,
        summary.completed_tasks,
        summary.total_tasks
    );

    // Auto-detect completion: when all tasks are logged, auto-complete the evaluation
    // This replaces the need for validators to call submit_result
    if summary.completed_tasks == summary.total_tasks && summary.total_tasks > 0 {
        info!(
            "Validator {} completed all {} tasks for agent {}, auto-completing evaluation",
            &req.validator_hotkey[..16.min(req.validator_hotkey.len())],
            summary.total_tasks,
            &req.agent_hash[..16.min(req.agent_hash.len())]
        );

        match state
            .storage
            .auto_complete_validator_evaluation(&req.agent_hash, &req.validator_hotkey, &summary)
            .await
        {
            Ok((consensus_reached, final_score)) => {
                if consensus_reached {
                    info!(
                        "Consensus reached for agent {}: final score = {:.4}",
                        &req.agent_hash[..16.min(req.agent_hash.len())],
                        final_score.unwrap_or(0.0)
                    );
                }
            }
            Err(e) => {
                warn!(
                    "Failed to auto-complete evaluation for {} on {}: {}",
                    &req.validator_hotkey[..16.min(req.validator_hotkey.len())],
                    &req.agent_hash[..16.min(req.agent_hash.len())],
                    e
                );
            }
        }
    }

    Ok(Json(LogTaskResponse {
        success: true,
        tasks_logged: summary.completed_tasks,
        tasks_total: summary.total_tasks,
        error: None,
    }))
}

// ============================================================================
// REAL-TIME TASK STREAMING
// ============================================================================

#[derive(Debug, Deserialize)]
pub struct TaskStreamUpdateRequest {
    pub validator_hotkey: String,
    pub signature: String,
    pub timestamp: i64,
    pub agent_hash: String,
    pub task_id: String,
    pub task_name: Option<String>,
    pub status: Option<String>,
    pub stdout_chunk: Option<String>,
    pub stderr_chunk: Option<String>,
    pub current_step: Option<i32>,
}

#[derive(Debug, Serialize)]
pub struct TaskStreamUpdateResponse {
    pub success: bool,
    pub error: Option<String>,
}

/// POST /api/v1/validator/task_stream_update - Push real-time task progress
///
/// Validators call this during task execution to stream live stdout/stderr.
/// Data is stored in memory cache and evicted when task is persisted to DB.
pub async fn task_stream_update(
    State(state): State<Arc<ApiState>>,
    Json(req): Json<TaskStreamUpdateRequest>,
) -> Result<Json<TaskStreamUpdateResponse>, (StatusCode, Json<TaskStreamUpdateResponse>)> {
    // Check if cache is available and enabled
    let cache = match &state.task_stream_cache {
        Some(c) if c.is_enabled() => c,
        _ => {
            return Ok(Json(TaskStreamUpdateResponse {
                success: true,
                error: None,
            }));
        }
    };

    // Validate hotkey
    if !is_valid_ss58_hotkey(&req.validator_hotkey) {
        return Err((
            StatusCode::BAD_REQUEST,
            Json(TaskStreamUpdateResponse {
                success: false,
                error: Some("Invalid hotkey format".to_string()),
            }),
        ));
    }

    // Validate timestamp
    if !is_timestamp_valid(req.timestamp) {
        return Err((
            StatusCode::BAD_REQUEST,
            Json(TaskStreamUpdateResponse {
                success: false,
                error: Some("Timestamp expired".to_string()),
            }),
        ));
    }

    // Verify signature
    let message = format!(
        "task_stream:{}:{}:{}",
        req.agent_hash, req.task_id, req.timestamp
    );
    let skip_auth = std::env::var("SKIP_AUTH")
        .map(|v| v == "1")
        .unwrap_or(false);
    if !skip_auth && !verify_signature(&req.validator_hotkey, &message, &req.signature) {
        return Err((
            StatusCode::UNAUTHORIZED,
            Json(TaskStreamUpdateResponse {
                success: false,
                error: Some("Invalid signature".to_string()),
            }),
        ));
    }

    // Push update to cache
    let update = crate::cache::task_stream::TaskStreamUpdate {
        agent_hash: req.agent_hash,
        validator_hotkey: req.validator_hotkey,
        task_id: req.task_id,
        task_name: req.task_name,
        status: req.status,
        stdout_chunk: req.stdout_chunk,
        stderr_chunk: req.stderr_chunk,
        current_step: req.current_step,
    };

    cache.push_update(update);

    Ok(Json(TaskStreamUpdateResponse {
        success: true,
        error: None,
    }))
}

#[derive(Debug, Serialize)]
pub struct LiveTasksResponse {
    pub agent_hash: String,
    pub tasks: Vec<crate::cache::task_stream::LiveTaskProgress>,
    pub cache_stats: Option<crate::cache::task_stream::TaskStreamStats>,
}

/// GET /api/v1/agent/:agent_hash/tasks/live - Get all live task progress for an agent
///
/// Returns real-time streaming progress from the in-memory cache.
/// No authentication required.
pub async fn get_live_tasks(
    State(state): State<Arc<ApiState>>,
    Path(agent_hash): Path<String>,
) -> Result<Json<LiveTasksResponse>, (StatusCode, String)> {
    let cache = match &state.task_stream_cache {
        Some(c) => c,
        None => {
            return Ok(Json(LiveTasksResponse {
                agent_hash,
                tasks: vec![],
                cache_stats: None,
            }));
        }
    };

    let entries = cache.get_agent_tasks(&agent_hash);
    let tasks: Vec<_> = entries
        .into_iter()
        .map(crate::cache::task_stream::LiveTaskProgress::from)
        .collect();

    Ok(Json(LiveTasksResponse {
        agent_hash,
        tasks,
        cache_stats: Some(cache.stats()),
    }))
}

#[derive(Debug, Serialize)]
pub struct LiveTaskDetailResponse {
    pub agent_hash: String,
    pub task_id: String,
    pub validators: Vec<crate::cache::task_stream::LiveTaskProgress>,
}

/// GET /api/v1/agent/:agent_hash/tasks/:task_id/live - Get live progress for specific task
///
/// Returns real-time progress for a specific task across all validators.
pub async fn get_live_task_detail(
    State(state): State<Arc<ApiState>>,
    Path((agent_hash, task_id)): Path<(String, String)>,
) -> Result<Json<LiveTaskDetailResponse>, (StatusCode, String)> {
    let cache = match &state.task_stream_cache {
        Some(c) => c,
        None => {
            return Ok(Json(LiveTaskDetailResponse {
                agent_hash,
                task_id,
                validators: vec![],
            }));
        }
    };

    let entries = cache.get_task_by_id(&agent_hash, &task_id);
    let validators: Vec<_> = entries
        .into_iter()
        .map(crate::cache::task_stream::LiveTaskProgress::from)
        .collect();

    Ok(Json(LiveTaskDetailResponse {
        agent_hash,
        task_id,
        validators,
    }))
}

// ============================================================================
// SUBMIT RESULT - DEPRECATED
// ============================================================================
// NOTE: submit_result has been removed. Validator evaluation completion is now
// automatically detected when all tasks are logged via log_task().
// The server auto-creates ValidatorEvaluation records when a validator logs
// all their assigned tasks (completed_tasks == total_tasks).
// ============================================================================

#[derive(Debug, Deserialize)]
pub struct GetMyJobsRequest {
    pub validator_hotkey: String,
    pub signature: String,
    pub timestamp: i64,
}

#[derive(Debug, Serialize)]
pub struct GetMyJobsResponse {
    pub success: bool,
    pub pending_jobs: Vec<ValidatorJob>,
    pub completed_count: usize,
    pub error: Option<String>,
}

#[derive(Debug, Serialize)]
pub struct ValidatorJob {
    pub agent_hash: String,
    pub miner_hotkey: String,
    pub submission_id: String,
    pub assigned_at: i64,
    pub compile_status: String, // "pending", "compiling", "success", "failed"
    pub binary_ready: bool,     // true if compile_status == "success"
    /// Task IDs assigned to this validator for this agent (10 tasks each)
    pub assigned_task_ids: Vec<String>,
}

/// POST /api/v1/validator/my_jobs - Get validator's pending jobs
pub async fn get_my_jobs(
    State(state): State<Arc<ApiState>>,
    Json(req): Json<GetMyJobsRequest>,
) -> Result<Json<GetMyJobsResponse>, (StatusCode, Json<GetMyJobsResponse>)> {
    // Validate hotkey
    if !is_valid_ss58_hotkey(&req.validator_hotkey) {
        return Err((
            StatusCode::BAD_REQUEST,
            Json(GetMyJobsResponse {
                success: false,
                pending_jobs: vec![],
                completed_count: 0,
                error: Some("Invalid hotkey format".to_string()),
            }),
        ));
    }

    // Validate timestamp
    if !is_timestamp_valid(req.timestamp) {
        return Err((
            StatusCode::BAD_REQUEST,
            Json(GetMyJobsResponse {
                success: false,
                pending_jobs: vec![],
                completed_count: 0,
                error: Some("Timestamp expired".to_string()),
            }),
        ));
    }

    // Verify signature (skip in test mode)
    let message = format!("get_my_jobs:{}", req.timestamp);
    let skip_auth = std::env::var("SKIP_AUTH")
        .map(|v| v == "1")
        .unwrap_or(false);
    if !skip_auth && !verify_signature(&req.validator_hotkey, &message, &req.signature) {
        return Err((
            StatusCode::UNAUTHORIZED,
            Json(GetMyJobsResponse {
                success: false,
                pending_jobs: vec![],
                completed_count: 0,
                error: Some("Invalid signature".to_string()),
            }),
        ));
    }

    // Check if validator is authorized (>= 10000 TAO stake or whitelisted)
    if !state.is_authorized_validator(&req.validator_hotkey).await {
        return Err((
            StatusCode::FORBIDDEN,
            Json(GetMyJobsResponse {
                success: false,
                pending_jobs: vec![],
                completed_count: 0,
                error: Some("Validator not authorized (requires >= 10000 TAO stake)".to_string()),
            }),
        ));
    }

    // Get pending jobs for this validator with compile status
    let jobs = state
        .storage
        .get_validator_jobs_with_status(&req.validator_hotkey, 100)
        .await
        .map_err(|e| {
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(GetMyJobsResponse {
                    success: false,
                    pending_jobs: vec![],
                    completed_count: 0,
                    error: Some(e.to_string()),
                }),
            )
        })?;

    // Get claims (jobs in progress)
    let claims = state
        .storage
        .get_validator_claims(&req.validator_hotkey)
        .await
        .unwrap_or_default();

    // Build pending jobs with assigned task IDs for each
    let mut pending_jobs: Vec<ValidatorJob> = Vec::new();
    for j in jobs {
        // Get assigned task IDs for this validator/agent pair
        let assigned_task_ids = state
            .storage
            .get_validator_tasks(&j.agent_hash, &req.validator_hotkey)
            .await
            .map(|tasks| tasks.into_iter().map(|t| t.task_id).collect())
            .unwrap_or_else(|_| Vec::new());

        pending_jobs.push(ValidatorJob {
            agent_hash: j.agent_hash,
            miner_hotkey: j.miner_hotkey,
            submission_id: j.submission_id,
            assigned_at: j.assigned_at,
            compile_status: j.compile_status.clone(),
            binary_ready: j.compile_status == "success",
            assigned_task_ids,
        });
    }

    Ok(Json(GetMyJobsResponse {
        success: true,
        pending_jobs,
        completed_count: claims.iter().filter(|c| c.status == "completed").count(),
        error: None,
    }))
}

// ============================================================================
// GET ASSIGNED TASKS ENDPOINT (for live refresh)
// ============================================================================

#[derive(Debug, Deserialize)]
pub struct GetAssignedTasksRequest {
    pub validator_hotkey: String,
    pub agent_hash: String,
    pub signature: String,
    pub timestamp: i64,
}

#[derive(Debug, Serialize)]
pub struct GetAssignedTasksResponse {
    pub success: bool,
    pub task_ids: Vec<String>,
    pub error: Option<String>,
}

/// POST /api/v1/validator/get_assigned_tasks - Get current assigned tasks for an agent
/// Allows validators to refresh their task list during evaluation (for live reassignments)
pub async fn get_assigned_tasks(
    State(state): State<Arc<ApiState>>,
    Json(req): Json<GetAssignedTasksRequest>,
) -> Result<Json<GetAssignedTasksResponse>, (StatusCode, Json<GetAssignedTasksResponse>)> {
    // Validate hotkey
    if !is_valid_ss58_hotkey(&req.validator_hotkey) {
        return Err((
            StatusCode::BAD_REQUEST,
            Json(GetAssignedTasksResponse {
                success: false,
                task_ids: vec![],
                error: Some("Invalid hotkey format".to_string()),
            }),
        ));
    }

    // Validate timestamp
    if !is_timestamp_valid(req.timestamp) {
        return Err((
            StatusCode::BAD_REQUEST,
            Json(GetAssignedTasksResponse {
                success: false,
                task_ids: vec![],
                error: Some("Timestamp expired".to_string()),
            }),
        ));
    }

    // Verify signature (skip in test mode)
    let message = format!("get_assigned_tasks:{}:{}", req.agent_hash, req.timestamp);
    let skip_auth = std::env::var("SKIP_AUTH")
        .map(|v| v == "1")
        .unwrap_or(false);

    if !skip_auth && !verify_signature(&req.validator_hotkey, &message, &req.signature) {
        return Err((
            StatusCode::UNAUTHORIZED,
            Json(GetAssignedTasksResponse {
                success: false,
                task_ids: vec![],
                error: Some("Invalid signature".to_string()),
            }),
        ));
    }

    // Get assigned tasks from DB
    let task_ids = state
        .storage
        .get_validator_tasks(&req.agent_hash, &req.validator_hotkey)
        .await
        .map(|tasks| tasks.into_iter().map(|t| t.task_id).collect())
        .unwrap_or_default();

    Ok(Json(GetAssignedTasksResponse {
        success: true,
        task_ids,
        error: None,
    }))
}

// ============================================================================
// AGENT CLEANUP ENDPOINT
// ============================================================================

#[derive(Debug, Deserialize)]
pub struct GetAgentsToCleanupRequest {
    pub validator_hotkey: String,
    pub signature: String,
    pub timestamp: i64,
}

#[derive(Debug, Serialize)]
pub struct GetAgentsToCleanupResponse {
    pub success: bool,
    pub agents: Vec<String>,
    pub error: Option<String>,
}

/// POST /api/v1/validator/agents_to_cleanup - Get agents that need cleanup
/// Returns agents where submission status is failed/completed/banned/rejected
/// Validators should kill containers and clean up resources for these agents
pub async fn get_agents_to_cleanup(
    State(state): State<Arc<ApiState>>,
    Json(req): Json<GetAgentsToCleanupRequest>,
) -> Result<Json<GetAgentsToCleanupResponse>, (StatusCode, Json<GetAgentsToCleanupResponse>)> {
    // Validate hotkey
    if !is_valid_ss58_hotkey(&req.validator_hotkey) {
        return Err((
            StatusCode::BAD_REQUEST,
            Json(GetAgentsToCleanupResponse {
                success: false,
                agents: vec![],
                error: Some("Invalid hotkey format".to_string()),
            }),
        ));
    }

    // Validate timestamp
    if !is_timestamp_valid(req.timestamp) {
        return Err((
            StatusCode::BAD_REQUEST,
            Json(GetAgentsToCleanupResponse {
                success: false,
                agents: vec![],
                error: Some("Timestamp expired".to_string()),
            }),
        ));
    }

    // Verify signature
    let message = format!("agents_to_cleanup:{}", req.timestamp);
    let skip_auth = std::env::var("SKIP_AUTH")
        .map(|v| v == "1")
        .unwrap_or(false);
    if !skip_auth && !verify_signature(&req.validator_hotkey, &message, &req.signature) {
        return Err((
            StatusCode::UNAUTHORIZED,
            Json(GetAgentsToCleanupResponse {
                success: false,
                agents: vec![],
                error: Some("Invalid signature".to_string()),
            }),
        ));
    }

    // Get agents needing cleanup
    let agents = state
        .storage
        .get_agents_needing_cleanup(&req.validator_hotkey)
        .await
        .map_err(|e| {
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(GetAgentsToCleanupResponse {
                    success: false,
                    agents: vec![],
                    error: Some(e.to_string()),
                }),
            )
        })?;

    if !agents.is_empty() {
        info!(
            "Validator {} has {} agents to cleanup: {:?}",
            &req.validator_hotkey[..16.min(req.validator_hotkey.len())],
            agents.len(),
            agents
                .iter()
                .map(|a| &a[..16.min(a.len())])
                .collect::<Vec<_>>()
        );
    }

    Ok(Json(GetAgentsToCleanupResponse {
        success: true,
        agents,
        error: None,
    }))
}

#[derive(Debug, Deserialize)]
pub struct NotifyCleanupCompleteRequest {
    pub validator_hotkey: String,
    pub signature: String,
    pub timestamp: i64,
    pub agent_hash: String,
}

#[derive(Debug, Serialize)]
pub struct NotifyCleanupCompleteResponse {
    pub success: bool,
    pub error: Option<String>,
}

/// POST /api/v1/validator/cleanup_complete - Notify server that cleanup is done
pub async fn notify_cleanup_complete(
    State(state): State<Arc<ApiState>>,
    Json(req): Json<NotifyCleanupCompleteRequest>,
) -> Result<Json<NotifyCleanupCompleteResponse>, (StatusCode, Json<NotifyCleanupCompleteResponse>)>
{
    // Validate hotkey
    if !is_valid_ss58_hotkey(&req.validator_hotkey) {
        return Err((
            StatusCode::BAD_REQUEST,
            Json(NotifyCleanupCompleteResponse {
                success: false,
                error: Some("Invalid hotkey format".to_string()),
            }),
        ));
    }

    // Validate timestamp
    if !is_timestamp_valid(req.timestamp) {
        return Err((
            StatusCode::BAD_REQUEST,
            Json(NotifyCleanupCompleteResponse {
                success: false,
                error: Some("Timestamp expired".to_string()),
            }),
        ));
    }

    // Verify signature
    let message = format!("cleanup_complete:{}:{}", req.agent_hash, req.timestamp);
    let skip_auth = std::env::var("SKIP_AUTH")
        .map(|v| v == "1")
        .unwrap_or(false);
    if !skip_auth && !verify_signature(&req.validator_hotkey, &message, &req.signature) {
        return Err((
            StatusCode::UNAUTHORIZED,
            Json(NotifyCleanupCompleteResponse {
                success: false,
                error: Some("Invalid signature".to_string()),
            }),
        ));
    }

    // Mark assignment as cancelled
    state
        .storage
        .mark_assignment_cancelled(&req.agent_hash, &req.validator_hotkey)
        .await
        .map_err(|e| {
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(NotifyCleanupCompleteResponse {
                    success: false,
                    error: Some(e.to_string()),
                }),
            )
        })?;

    info!(
        "Cleanup complete for agent {} by validator {}",
        &req.agent_hash[..16.min(req.agent_hash.len())],
        &req.validator_hotkey[..16.min(req.validator_hotkey.len())]
    );

    Ok(Json(NotifyCleanupCompleteResponse {
        success: true,
        error: None,
    }))
}

/// GET /api/v1/validator/agent_status/:agent_hash - Check if agent has been evaluated
pub async fn get_agent_eval_status(
    State(state): State<Arc<ApiState>>,
    Path(agent_hash): Path<String>,
) -> Result<Json<AgentEvalStatusResponse>, (StatusCode, String)> {
    let pending = state
        .storage
        .get_pending_status(&agent_hash)
        .await
        .map_err(|e| (StatusCode::INTERNAL_SERVER_ERROR, e.to_string()))?;

    let evaluations = state
        .storage
        .get_validator_evaluations(&agent_hash)
        .await
        .map_err(|e| (StatusCode::INTERNAL_SERVER_ERROR, e.to_string()))?;

    Ok(Json(AgentEvalStatusResponse {
        agent_hash,
        status: pending
            .as_ref()
            .map(|p| p.status.clone())
            .unwrap_or_else(|| "not_found".to_string()),
        validators_completed: pending
            .as_ref()
            .map(|p| p.validators_completed)
            .unwrap_or(0),
        total_validators: pending.as_ref().map(|p| p.total_validators).unwrap_or(0),
        window_expires_at: pending.as_ref().map(|p| p.window_expires_at),
        evaluations: evaluations
            .into_iter()
            .map(|e| ValidatorEvalInfo {
                validator_hotkey: e.validator_hotkey,
                score: e.score,
                tasks_passed: e.tasks_passed,
                tasks_total: e.tasks_total,
            })
            .collect(),
    }))
}

#[derive(Debug, Serialize)]
pub struct AgentEvalStatusResponse {
    pub agent_hash: String,
    pub status: String,
    pub validators_completed: i32,
    pub total_validators: i32,
    pub window_expires_at: Option<i64>,
    pub evaluations: Vec<ValidatorEvalInfo>,
}

#[derive(Debug, Serialize)]
pub struct ValidatorEvalInfo {
    pub validator_hotkey: String,
    pub score: f64,
    pub tasks_passed: i32,
    pub tasks_total: i32,
}

// ============================================================================
// GET EVALUATION PROGRESS (Resume support)
// ============================================================================

#[derive(Debug, Deserialize)]
pub struct GetProgressRequest {
    pub validator_hotkey: String,
    pub signature: String,
    pub timestamp: i64,
    pub agent_hash: String,
}

#[derive(Debug, Serialize)]
pub struct GetProgressResponse {
    pub success: bool,
    pub agent_hash: String,
    pub total_tasks: i32,
    pub completed_tasks: Vec<CompletedTaskInfo>,
    pub remaining_task_ids: Vec<String>,
    pub partial_score: f64,
    pub error: Option<String>,
}

// Re-export CompletedTaskInfo from api module to avoid duplication
pub use crate::api::routes::validator::CompletedTaskInfo;

/// POST /api/v1/validator/get_evaluation_progress - Get progress for resuming evaluation
///
/// Returns which tasks have already been completed for this agent by this validator,
/// allowing the validator to skip already-evaluated tasks and resume from where it left off.
pub async fn get_evaluation_progress(
    State(state): State<Arc<ApiState>>,
    Json(req): Json<GetProgressRequest>,
) -> Result<Json<GetProgressResponse>, (StatusCode, Json<GetProgressResponse>)> {
    // Validate hotkey
    if !is_valid_ss58_hotkey(&req.validator_hotkey) {
        return Err((
            StatusCode::BAD_REQUEST,
            Json(GetProgressResponse {
                success: false,
                agent_hash: req.agent_hash.clone(),
                total_tasks: 0,
                completed_tasks: vec![],
                remaining_task_ids: vec![],
                partial_score: 0.0,
                error: Some("Invalid hotkey format".to_string()),
            }),
        ));
    }

    // Validate timestamp
    if !is_timestamp_valid(req.timestamp) {
        return Err((
            StatusCode::BAD_REQUEST,
            Json(GetProgressResponse {
                success: false,
                agent_hash: req.agent_hash.clone(),
                total_tasks: 0,
                completed_tasks: vec![],
                remaining_task_ids: vec![],
                partial_score: 0.0,
                error: Some("Timestamp expired".to_string()),
            }),
        ));
    }

    // Verify signature
    let message = format!("get_progress:{}:{}", req.agent_hash, req.timestamp);
    let skip_auth = std::env::var("SKIP_AUTH")
        .map(|v| v == "1")
        .unwrap_or(false);
    if !skip_auth && !verify_signature(&req.validator_hotkey, &message, &req.signature) {
        return Err((
            StatusCode::UNAUTHORIZED,
            Json(GetProgressResponse {
                success: false,
                agent_hash: req.agent_hash.clone(),
                total_tasks: 0,
                completed_tasks: vec![],
                remaining_task_ids: vec![],
                partial_score: 0.0,
                error: Some("Invalid signature".to_string()),
            }),
        ));
    }

    // Check if validator is authorized
    if !skip_auth && !state.is_authorized_validator(&req.validator_hotkey).await {
        return Err((
            StatusCode::FORBIDDEN,
            Json(GetProgressResponse {
                success: false,
                agent_hash: req.agent_hash.clone(),
                total_tasks: 0,
                completed_tasks: vec![],
                remaining_task_ids: vec![],
                partial_score: 0.0,
                error: Some("Validator not authorized (requires >= 10000 TAO stake)".to_string()),
            }),
        ));
    }

    // Get evaluation progress from storage
    match state
        .storage
        .get_evaluation_progress(&req.agent_hash, &req.validator_hotkey)
        .await
    {
        Ok(progress) => {
            info!(
                "Progress for {} by {}: {}/{} tasks completed",
                &req.agent_hash[..16.min(req.agent_hash.len())],
                &req.validator_hotkey[..16.min(req.validator_hotkey.len())],
                progress.completed_tasks.len(),
                progress.total_tasks
            );
            Ok(Json(GetProgressResponse {
                success: true,
                agent_hash: req.agent_hash,
                total_tasks: progress.total_tasks,
                completed_tasks: progress.completed_tasks,
                remaining_task_ids: progress.remaining_task_ids,
                partial_score: progress.partial_score,
                error: None,
            }))
        }
        Err(e) => Err((
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(GetProgressResponse {
                success: false,
                agent_hash: req.agent_hash,
                total_tasks: 0,
                completed_tasks: vec![],
                remaining_task_ids: vec![],
                partial_score: 0.0,
                error: Some(format!("Failed to get progress: {}", e)),
            }),
        )),
    }
}

// ============================================================================
// BINARY DOWNLOAD ENDPOINT
// ============================================================================

/// Request for binary download - uses POST for authentication
#[derive(Debug, Deserialize)]
pub struct DownloadBinaryRequest {
    pub validator_hotkey: String,
    pub signature: String,
    pub timestamp: i64,
}

/// POST /api/v1/validator/download_binary/:agent_hash
///
/// Allows assigned validators to download the compiled binary for evaluation.
/// Only validators who are assigned to this agent can download the binary.
///
/// Authentication:
/// - validator_hotkey: SS58 format validator hotkey
/// - signature: sr25519 signature of "download_binary:{agent_hash}:{timestamp}"
/// - timestamp: Unix timestamp (must be within 5 minutes)
///
/// Returns:
/// - Binary file with Content-Type: application/octet-stream
/// - 403 Forbidden if validator is not assigned to this agent
/// - 404 Not Found if binary not compiled yet
pub async fn download_binary(
    State(state): State<Arc<ApiState>>,
    Path(agent_hash): Path<String>,
    Json(req): Json<DownloadBinaryRequest>,
) -> Result<impl axum::response::IntoResponse, (StatusCode, String)> {
    use axum::http::header;

    // Validate hotkey format
    if !is_valid_ss58_hotkey(&req.validator_hotkey) {
        return Err((StatusCode::BAD_REQUEST, "Invalid hotkey format".to_string()));
    }

    // Validate timestamp (5 min window)
    if !is_timestamp_valid(req.timestamp) {
        return Err((StatusCode::BAD_REQUEST, "Timestamp expired".to_string()));
    }

    // Verify signature
    let message = format!("download_binary:{}:{}", agent_hash, req.timestamp);
    let skip_auth = std::env::var("SKIP_AUTH")
        .map(|v| v == "1")
        .unwrap_or(false);

    if !skip_auth && !verify_signature(&req.validator_hotkey, &message, &req.signature) {
        warn!(
            "Invalid signature for binary download from {}",
            &req.validator_hotkey[..16.min(req.validator_hotkey.len())]
        );
        return Err((StatusCode::UNAUTHORIZED, "Invalid signature".to_string()));
    }

    // Check if validator is assigned to this agent
    if !skip_auth {
        let is_assigned = state
            .storage
            .is_validator_assigned(&agent_hash, &req.validator_hotkey)
            .await
            .unwrap_or(false);

        if !is_assigned {
            warn!(
                "Validator {} not assigned to agent {}, denying binary download",
                &req.validator_hotkey[..16.min(req.validator_hotkey.len())],
                &agent_hash[..16.min(agent_hash.len())]
            );
            return Err((
                StatusCode::FORBIDDEN,
                "Validator not assigned to this agent".to_string(),
            ));
        }
    }

    // Get binary from database
    let binary = state
        .storage
        .get_binary(&agent_hash)
        .await
        .map_err(|e| (StatusCode::INTERNAL_SERVER_ERROR, e.to_string()))?
        .ok_or_else(|| {
            (
                StatusCode::NOT_FOUND,
                "Binary not found or not compiled yet".to_string(),
            )
        })?;

    info!(
        "Validator {} downloading binary for agent {} ({} bytes)",
        &req.validator_hotkey[..16.min(req.validator_hotkey.len())],
        &agent_hash[..16.min(agent_hash.len())],
        binary.len()
    );

    // Return raw binary with appropriate headers
    Ok((
        [
            (header::CONTENT_TYPE, "application/octet-stream".to_string()),
            (header::CONTENT_LENGTH, binary.len().to_string()),
            (
                header::CONTENT_DISPOSITION,
                format!(
                    "attachment; filename=\"{}.bin\"",
                    &agent_hash[..16.min(agent_hash.len())]
                ),
            ),
        ],
        binary,
    ))
}

// ============================================================================
// TASK OBSERVABILITY RESPONSE TYPES
// ============================================================================

/// Response for GET /api/v1/agent/:agent_hash/tasks
#[derive(Debug, Serialize)]
pub struct AgentTasksResponse {
    pub agent_hash: String,
    pub validators: Vec<ValidatorTasksSummary>,
}

#[derive(Debug, Serialize)]
pub struct ValidatorTasksSummary {
    pub validator_hotkey: String,
    pub status: String,
    pub tasks: Vec<TaskLogResponse>,
    pub summary: TaskSummaryStats,
}

#[derive(Debug, Serialize)]
pub struct TaskLogResponse {
    pub task_id: String,
    pub task_name: String,
    pub passed: bool,
    pub score: f64,
    pub execution_time_ms: i64,
    pub error: Option<String>,
    pub agent_stderr: Option<String>,
    pub agent_stdout: Option<String>,
    pub test_output: Option<String>,
    pub failure_stage: Option<String>,
    pub completed_at: i64,
}

#[derive(Debug, Serialize)]
pub struct TaskSummaryStats {
    pub total: i32,
    pub passed: i32,
    pub failed: i32,
    pub score: f64,
}

/// Response for GET /api/v1/agent/:agent_hash/progress
#[derive(Debug, Serialize)]
pub struct AgentProgressResponse {
    pub agent_hash: String,
    pub overall_status: String,
    pub validators: Vec<ValidatorProgressResponse>,
}

#[derive(Debug, Serialize)]
pub struct ValidatorProgressResponse {
    pub validator_hotkey: String,
    pub status: String,
    pub total_tasks: i32,
    pub completed_tasks: i32,
    pub passed_tasks: i32,
    pub failed_tasks: i32,
    pub remaining_tasks: Vec<String>,
    pub current_task: Option<String>,
    pub started_at: Option<i64>,
    pub last_update: Option<i64>,
}

/// Response for validator evaluations
#[derive(Debug, Serialize)]
pub struct ValidatorEvaluationsResponse {
    pub validator_hotkey: String,
    pub evaluations: Vec<EvaluationSummary>,
}

#[derive(Debug, Serialize)]
pub struct EvaluationSummary {
    pub agent_hash: String,
    pub miner_hotkey: String,
    pub score: f64,
    pub tasks_passed: i32,
    pub tasks_total: i32,
    pub tasks_failed: i32,
    pub total_cost_usd: f64,
    pub created_at: i64,
}

// ============================================================================
// STATUS ENDPOINTS
// ============================================================================

#[derive(Debug, Serialize)]
pub struct StatusResponse {
    pub status: String,
    pub epoch: i64,
    pub pending_jobs: i64,
}

/// GET /api/v1/status - Get challenge status
pub async fn get_status(
    State(state): State<Arc<ApiState>>,
) -> Result<Json<StatusResponse>, (StatusCode, String)> {
    let epoch = state
        .storage
        .get_current_epoch()
        .await
        .map_err(|e| (StatusCode::INTERNAL_SERVER_ERROR, e.to_string()))?;

    let pending = state
        .storage
        .get_all_pending()
        .await
        .map_err(|e| (StatusCode::INTERNAL_SERVER_ERROR, e.to_string()))?;

    Ok(Json(StatusResponse {
        status: "running".to_string(),
        epoch,
        pending_jobs: pending.len() as i64,
    }))
}

// ============================================================================
// PUBLIC ENDPOINTS (No authentication required)
// ============================================================================

#[derive(Debug, Deserialize)]
pub struct PendingSubmissionsQuery {
    pub limit: Option<i64>,
}

#[derive(Debug, Serialize)]
pub struct PendingSubmissionsResponse {
    pub submissions: Vec<crate::storage::pg::PublicSubmissionInfo>,
    pub total: usize,
}

/// GET /api/v1/pending - Get all pending submissions (public)
///
/// No authentication required. Does NOT include source code, API keys, or binaries.
/// Shows: agent_hash, miner_hotkey, name, version, epoch, status, compile_status,
///        flagged, created_at, validators_completed, total_validators
pub async fn get_pending_submissions(
    State(state): State<Arc<ApiState>>,
    Query(query): Query<PendingSubmissionsQuery>,
) -> Result<Json<PendingSubmissionsResponse>, (StatusCode, String)> {
    let limit = query.limit.unwrap_or(100).min(500);

    let submissions = state
        .storage
        .get_pending_submissions_public(limit)
        .await
        .map_err(|e| (StatusCode::INTERNAL_SERVER_ERROR, e.to_string()))?;

    let total = submissions.len();

    Ok(Json(PendingSubmissionsResponse { submissions, total }))
}

#[derive(Debug, Serialize)]
pub struct AgentAssignmentsResponse {
    pub agent_hash: String,
    pub assignments: Vec<crate::storage::pg::PublicAssignment>,
    pub total: usize,
}

/// GET /api/v1/assignments/:agent_hash - Get validator assignments for an agent (public)
///
/// No authentication required. Shows which validators are assigned to evaluate
/// a specific agent, their status (pending/in_progress/completed), and scores.
pub async fn get_agent_assignments(
    State(state): State<Arc<ApiState>>,
    Path(agent_hash): Path<String>,
) -> Result<Json<AgentAssignmentsResponse>, (StatusCode, String)> {
    let assignments = state
        .storage
        .get_agent_assignments_public(&agent_hash)
        .await
        .map_err(|e| (StatusCode::INTERNAL_SERVER_ERROR, e.to_string()))?;

    let total = assignments.len();

    Ok(Json(AgentAssignmentsResponse {
        agent_hash,
        assignments,
        total,
    }))
}

#[derive(Debug, Deserialize)]
pub struct AllAssignmentsQuery {
    pub limit: Option<i64>,
}

#[derive(Debug, Serialize)]
pub struct AllAssignmentsResponse {
    pub agents: Vec<crate::storage::pg::PublicAgentAssignments>,
    pub total: usize,
}

/// GET /api/v1/assignments - Get all pending agents with their validator assignments (public)
///
/// No authentication required. Dashboard view showing all pending agents
/// and which validators are assigned to each, with their evaluation status.
pub async fn get_all_assignments(
    State(state): State<Arc<ApiState>>,
    Query(query): Query<AllAssignmentsQuery>,
) -> Result<Json<AllAssignmentsResponse>, (StatusCode, String)> {
    let limit = query.limit.unwrap_or(50).min(200);

    let agents = state
        .storage
        .get_all_assignments_public(limit)
        .await
        .map_err(|e| (StatusCode::INTERNAL_SERVER_ERROR, e.to_string()))?;

    let total = agents.len();

    Ok(Json(AllAssignmentsResponse { agents, total }))
}

// =============================================================================
// LLM Proxy Endpoint - Routes agent LLM calls through validator to central server
// =============================================================================

#[derive(Debug, Deserialize)]
pub struct LlmProxyRequest {
    /// Validator hotkey making the request (must be whitelisted)
    pub validator_hotkey: String,
    /// Signature of "llm_chat:<timestamp>:<agent_hash>"
    pub signature: String,
    /// Request timestamp (must be within 5 minutes)
    pub timestamp: i64,
    /// Agent hash (to lookup API key from submission)
    pub agent_hash: String,
    /// LLM messages
    pub messages: Vec<LlmMessage>,
    /// Model to use (optional, defaults to agent's provider default)
    pub model: Option<String>,
    /// Max tokens (optional)
    pub max_tokens: Option<u32>,
    /// Temperature (optional)
    pub temperature: Option<f32>,
    /// Task ID for tracking (optional)
    pub task_id: Option<String>,
    /// Extra parameters to merge into LLM request body (e.g., thinking, top_p, stop)
    pub extra_params: Option<serde_json::Value>,
    /// If true, use extra_params as the complete raw body (for fully custom requests)
    pub raw_request: Option<bool>,
}

/// LLM message supporting full OpenAI format with tool_calls
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LlmMessage {
    pub role: String,
    /// Content can be String, null, or array (for multimodal)
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub content: Option<serde_json::Value>,
    /// Tool calls from assistant (OpenAI format)
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tool_calls: Option<Vec<LlmToolCallInput>>,
    /// Tool call ID for tool response messages (role: tool)
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tool_call_id: Option<String>,
    /// Optional name field (for some providers)
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
}

/// Tool call input from agent (OpenAI format)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LlmToolCallInput {
    pub id: String,
    #[serde(rename = "type")]
    pub call_type: String,
    pub function: LlmFunctionCallInput,
}

/// Function call input from agent
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LlmFunctionCallInput {
    pub name: String,
    pub arguments: String,
}

/// Tool call output in response (for backwards compatibility)
#[derive(Debug, Serialize, Clone)]
pub struct LlmToolCall {
    pub id: Option<String>,
    #[serde(rename = "type")]
    pub call_type: String,
    pub function: LlmFunctionCall,
}

/// Function call output in response
#[derive(Debug, Serialize, Clone)]
pub struct LlmFunctionCall {
    pub name: String,
    pub arguments: String,
}

#[derive(Debug, Serialize)]
pub struct LlmProxyResponse {
    pub success: bool,
    pub content: Option<String>,
    pub model: Option<String>,
    pub usage: Option<LlmUsage>,
    pub cost_usd: Option<f64>,
    pub error: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub tool_calls: Option<Vec<LlmToolCall>>,
}

#[derive(Debug, Serialize)]
pub struct LlmUsage {
    pub prompt_tokens: u32,
    pub completion_tokens: u32,
    pub total_tokens: u32,
    /// Detailed prompt token breakdown (cached_tokens, cache_write_tokens, etc.)
    #[serde(skip_serializing_if = "Option::is_none")]
    pub prompt_tokens_details: Option<serde_json::Value>,
}

/// POST /api/v1/llm/chat - LLM proxy for agent requests
///
/// Flow:
/// 1. Agent in container calls term-sdk LLM
/// 2. term-sdk routes to validator's term-challenge container
/// 3. Validator container forwards to this central endpoint
/// 4. Central server verifies validator is whitelisted
/// 5. Looks up agent's API key from submission
/// 6. Makes LLM call and returns response
///
/// Authentication: Validator must be whitelisted and sign the request
pub async fn llm_chat_proxy(
    State(state): State<Arc<ApiState>>,
    Json(req): Json<LlmProxyRequest>,
) -> Result<Json<LlmProxyResponse>, (StatusCode, Json<LlmProxyResponse>)> {
    let err_response = |msg: String| LlmProxyResponse {
        success: false,
        content: None,
        model: None,
        usage: None,
        cost_usd: None,
        error: Some(msg),
        tool_calls: None,
    };

    // Validate validator hotkey
    if !is_valid_ss58_hotkey(&req.validator_hotkey) {
        return Err((
            StatusCode::BAD_REQUEST,
            Json(err_response("Invalid validator hotkey format".to_string())),
        ));
    }

    // Validate timestamp
    if !is_timestamp_valid(req.timestamp) {
        return Err((
            StatusCode::BAD_REQUEST,
            Json(err_response("Request timestamp expired".to_string())),
        ));
    }

    // Verify signature (skip in test mode)
    let message = format!("llm_chat:{}:{}", req.timestamp, req.agent_hash);
    let skip_auth = std::env::var("SKIP_AUTH")
        .map(|v| v == "1")
        .unwrap_or(false);

    if !skip_auth && !verify_signature(&req.validator_hotkey, &message, &req.signature) {
        return Err((
            StatusCode::UNAUTHORIZED,
            Json(err_response("Invalid signature".to_string())),
        ));
    }

    // Verify validator is authorized (>= 10000 TAO stake or whitelisted)
    if !skip_auth && !state.is_authorized_validator(&req.validator_hotkey).await {
        warn!(
            "LLM proxy: unauthorized validator {} (insufficient stake)",
            &req.validator_hotkey[..16.min(req.validator_hotkey.len())]
        );
        return Err((
            StatusCode::FORBIDDEN,
            Json(err_response(
                "Validator not authorized (requires >= 10000 TAO stake)".to_string(),
            )),
        ));
    }

    // Get agent's DECRYPTED API key and provider from submission
    // The API key is stored encrypted in the DB and must be decrypted server-side
    let (api_key, provider) = state
        .storage
        .get_submission_api_key(&req.agent_hash)
        .await
        .map_err(|e| {
            error!("LLM proxy: failed to get API key: {}", e);
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(err_response(format!(
                    "Failed to lookup agent API key: {}",
                    e
                ))),
            )
        })?
        .ok_or_else(|| {
            (
                StatusCode::BAD_REQUEST,
                Json(err_response("Agent has no API key configured".to_string())),
            )
        })?;

    info!(
        "LLM proxy: validator {} requesting for agent {} (provider: {})",
        &req.validator_hotkey[..12.min(req.validator_hotkey.len())],
        &req.agent_hash[..12.min(req.agent_hash.len())],
        provider
    );

    // Check cost limit before making the LLM call
    let (current_cost, cost_limit) = state
        .storage
        .get_submission_costs(&req.agent_hash)
        .await
        .map_err(|e| {
            error!("Failed to get submission costs: {}", e);
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(err_response(format!("Database error: {}", e))),
            )
        })?;

    if current_cost >= cost_limit {
        warn!(
            "LLM proxy: cost limit exceeded for agent {}: ${:.4} >= ${:.4}",
            &req.agent_hash[..12.min(req.agent_hash.len())],
            current_cost,
            cost_limit
        );
        return Err((
            StatusCode::PAYMENT_REQUIRED,
            Json(err_response(format!(
                "cost_limit_exceeded: ${:.4} used of ${:.4} limit",
                current_cost, cost_limit
            ))),
        ));
    }

    // Make LLM call
    let llm_response = make_llm_request(
        &api_key,
        &provider,
        &req.messages,
        req.model.as_deref(),
        req.max_tokens,
        req.temperature,
        req.extra_params.as_ref(),
        req.raw_request.unwrap_or(false),
    )
    .await;

    match llm_response {
        Ok(response) => {
            // Track cost in llm_usage table and update submission total
            let cost = response.cost_usd.unwrap_or(0.0);
            let model_name = response
                .model
                .clone()
                .unwrap_or_else(|| "unknown".to_string());

            // Record detailed usage for auditing
            if let Err(e) = state
                .storage
                .record_llm_usage(LlmUsageRecord {
                    agent_hash: req.agent_hash.clone(),
                    validator_hotkey: req.validator_hotkey.clone(),
                    task_id: req.task_id.clone(),
                    model: model_name.clone(),
                    prompt_tokens: response
                        .usage
                        .as_ref()
                        .map(|u| u.prompt_tokens as i32)
                        .unwrap_or(0),
                    completion_tokens: response
                        .usage
                        .as_ref()
                        .map(|u| u.completion_tokens as i32)
                        .unwrap_or(0),
                    cost_usd: cost,
                })
                .await
            {
                warn!("Failed to record LLM usage: {}", e);
            }

            // Update total cost on submission
            if cost > 0.0 {
                if let Err(e) = state
                    .storage
                    .add_submission_cost(&req.agent_hash, cost)
                    .await
                {
                    warn!("Failed to update submission cost: {}", e);
                }
            }

            info!(
                "LLM proxy: success for agent {}, model={}, tokens={}, cost=${:.4}",
                &req.agent_hash[..12.min(req.agent_hash.len())],
                model_name,
                response.usage.as_ref().map(|u| u.total_tokens).unwrap_or(0),
                cost
            );

            Ok(Json(LlmProxyResponse {
                success: true,
                content: response.content,
                model: response.model,
                usage: response.usage,
                cost_usd: response.cost_usd,
                error: None,
                tool_calls: response.tool_calls,
            }))
        }
        Err(e) => {
            // Check if it's an LlmApiError with preserved status code
            if let Some(llm_err) = e.downcast_ref::<LlmApiError>() {
                warn!(
                    "LLM proxy: API error for agent {} - status={}, type={:?}, msg={}",
                    &req.agent_hash[..12.min(req.agent_hash.len())],
                    llm_err.status_code,
                    llm_err.error_type,
                    llm_err.message
                );

                // Log raw response at debug level for troubleshooting
                if let Some(ref raw) = llm_err.raw_response {
                    debug!("LLM raw error response: {}", raw);
                }

                // Map LLM provider status codes to appropriate HTTP responses
                let http_status = map_llm_status_code(llm_err.status_code);

                return Err((
                    http_status,
                    Json(LlmProxyResponse {
                        success: false,
                        content: None,
                        model: None,
                        usage: None,
                        cost_usd: None,
                        error: Some(format!(
                            "{}: {}",
                            llm_err.error_type.as_deref().unwrap_or("llm_error"),
                            llm_err.message
                        )),
                        tool_calls: None,
                    }),
                ));
            }

            // Generic/network error
            error!(
                "LLM proxy: request failed for agent {}: {}",
                &req.agent_hash[..12.min(req.agent_hash.len())],
                e
            );
            Err((
                StatusCode::BAD_GATEWAY,
                Json(err_response(format!("LLM request failed: {}", e))),
            ))
        }
    }
}

/// LLM API error with preserved HTTP status code from provider
#[derive(Debug)]
pub struct LlmApiError {
    /// Original HTTP status code from provider (401, 402, 429, etc.)
    pub status_code: u16,
    /// Error message extracted from provider response
    pub message: String,
    /// Error type/code from provider (e.g., "invalid_api_key")
    pub error_type: Option<String>,
    /// Raw response body for debugging (truncated to 500 chars)
    pub raw_response: Option<String>,
}

impl std::fmt::Display for LlmApiError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "LLM API error ({}): {}", self.status_code, self.message)
    }
}

impl std::error::Error for LlmApiError {}

/// Parse error response from LLM providers (OpenRouter, OpenAI, Anthropic)
fn parse_llm_error_response(response_text: &str) -> (String, Option<String>) {
    if let Ok(json) = serde_json::from_str::<serde_json::Value>(response_text) {
        // OpenRouter/OpenAI format: {"error": {"message": "...", "type": "...", "code": "..."}}
        if let Some(error_obj) = json.get("error") {
            let message = error_obj
                .get("message")
                .and_then(|m| m.as_str())
                .unwrap_or("Unknown error")
                .to_string();
            let error_type = error_obj
                .get("type")
                .or_else(|| error_obj.get("code"))
                .and_then(|t| t.as_str())
                .map(|s| s.to_string());
            return (message, error_type);
        }

        // Simple format: {"message": "..."}
        if let Some(message) = json.get("message").and_then(|m| m.as_str()) {
            return (message.to_string(), None);
        }
    }

    // Fallback: return raw text (truncated)
    (truncate_utf8_safe(response_text, 200), None)
}

/// Map LLM provider HTTP status code to appropriate response status
fn map_llm_status_code(status_code: u16) -> StatusCode {
    match status_code {
        400 => StatusCode::BAD_REQUEST,
        401 => StatusCode::UNAUTHORIZED,
        402 => StatusCode::PAYMENT_REQUIRED,
        403 => StatusCode::FORBIDDEN,
        404 => StatusCode::NOT_FOUND,
        429 => StatusCode::TOO_MANY_REQUESTS,
        500 => StatusCode::BAD_GATEWAY, // Provider internal error
        502 => StatusCode::BAD_GATEWAY, // Provider upstream error
        503 => StatusCode::SERVICE_UNAVAILABLE,
        504 => StatusCode::GATEWAY_TIMEOUT,
        _ => StatusCode::BAD_GATEWAY,
    }
}

struct LlmCallResponse {
    content: Option<String>,
    model: Option<String>,
    usage: Option<LlmUsage>,
    cost_usd: Option<f64>,
    tool_calls: Option<Vec<LlmToolCall>>,
}

// =============================================================================
// OpenAI Responses API Support (GPT-4.1+, GPT-5.x)
// =============================================================================

/// Check if model uses OpenAI's /v1/responses API instead of /v1/chat/completions
fn is_openai_responses_model(model: &str) -> bool {
    let model_lower = model.to_lowercase();
    model_lower.starts_with("gpt-4.1") || model_lower.starts_with("gpt-5")
}

/// Transform chat messages to OpenAI Responses API input format
fn transform_to_responses_api(
    messages: &[LlmMessage],
    model: &str,
    max_tokens: Option<u32>,
    temperature: Option<f32>,
    extra_params: Option<&serde_json::Value>,
) -> serde_json::Value {
    let mut instructions: Option<String> = None;
    let mut input_items: Vec<serde_json::Value> = Vec::new();

    for msg in messages {
        match msg.role.as_str() {
            "system" => {
                // System messages become 'instructions' parameter
                let content_str = msg.content.as_ref().and_then(|v| v.as_str()).unwrap_or("");
                if let Some(ref mut inst) = instructions {
                    inst.push_str("\n\n");
                    inst.push_str(content_str);
                } else {
                    instructions = Some(content_str.to_string());
                }
            }
            "user" => {
                // User messages become input items
                let content_str = msg.content.as_ref().and_then(|v| v.as_str()).unwrap_or("");
                input_items.push(serde_json::json!({
                    "type": "message",
                    "role": "user",
                    "content": [{"type": "input_text", "text": content_str}]
                }));
            }
            "assistant" => {
                // Check for tool_calls
                if let Some(ref tool_calls) = msg.tool_calls {
                    for tc in tool_calls {
                        input_items.push(serde_json::json!({
                            "type": "function_call",
                            "id": &tc.id,
                            "call_id": &tc.id,
                            "name": tc.function.name,
                            "arguments": tc.function.arguments
                        }));
                    }
                } else if let Some(ref content) = msg.content {
                    if let Some(text) = content.as_str() {
                        if !text.is_empty() {
                            input_items.push(serde_json::json!({
                                "type": "message",
                                "role": "assistant",
                                "content": [{"type": "output_text", "text": text}]
                            }));
                        }
                    }
                }
            }
            "tool" => {
                // Tool results become function_call_output items
                let content_str = msg.content.as_ref().and_then(|v| v.as_str()).unwrap_or("");
                input_items.push(serde_json::json!({
                    "type": "function_call_output",
                    "call_id": msg.tool_call_id.as_deref().unwrap_or(""),
                    "output": content_str
                }));
            }
            _ => {}
        }
    }

    let mut body = serde_json::json!({
        "model": model,
        "input": input_items,
        "max_output_tokens": max_tokens.unwrap_or(64000),
        "store": false,
    });

    // Only add temperature if explicitly provided
    if let Some(temp) = temperature {
        body["temperature"] = serde_json::json!(temp);
    }

    if let Some(inst) = instructions {
        body["instructions"] = serde_json::Value::String(inst);
    }

    // Merge tools from extra_params if present
    if let Some(extra) = extra_params {
        if let Some(tools) = extra.get("tools") {
            // Transform tools to Responses API format
            if let Some(tools_array) = tools.as_array() {
                let mut transformed_tools: Vec<serde_json::Value> = Vec::new();
                for tool in tools_array {
                    if tool.get("type").and_then(|t| t.as_str()) == Some("function") {
                        if let Some(func) = tool.get("function") {
                            transformed_tools.push(serde_json::json!({
                                "type": "function",
                                "name": func.get("name"),
                                "description": func.get("description"),
                                "parameters": func.get("parameters"),
                                "strict": true
                            }));
                        }
                    }
                }
                if !transformed_tools.is_empty() {
                    body["tools"] = serde_json::Value::Array(transformed_tools);
                    body["tool_choice"] = serde_json::json!("auto");
                }
            }
        }

        // Copy other extra params (but not messages, model, etc.)
        if let Some(extra_obj) = extra.as_object() {
            for (key, value) in extra_obj {
                // Skip params that are handled elsewhere or not supported by Responses API
                if [
                    "tools",
                    "tool_choice",
                    "messages",
                    "model",
                    "max_tokens",
                    "temperature",
                    "max_completion_tokens", // Not supported by Responses API, use max_output_tokens
                ]
                .contains(&key.as_str())
                {
                    continue;
                }
                body[key] = value.clone();
            }
            // Handle max_completion_tokens -> max_output_tokens conversion for Responses API
            // The Responses API uses max_output_tokens, not max_completion_tokens
            if let Some(mct) = extra_obj.get("max_completion_tokens") {
                body["max_output_tokens"] = mct.clone();
            }
        }
    }

    body
}

/// Parse OpenAI Responses API response into LlmCallResponse
fn parse_responses_api_response(json: &serde_json::Value, model: &str) -> LlmCallResponse {
    let mut content = String::new();
    let mut tool_calls: Vec<LlmToolCall> = Vec::new();

    if let Some(output) = json.get("output").and_then(|o| o.as_array()) {
        for item in output {
            match item.get("type").and_then(|t| t.as_str()) {
                Some("message") => {
                    // Extract text from message content
                    if let Some(contents) = item.get("content").and_then(|c| c.as_array()) {
                        for c in contents {
                            if c.get("type").and_then(|t| t.as_str()) == Some("output_text") {
                                if let Some(text) = c.get("text").and_then(|t| t.as_str()) {
                                    content.push_str(text);
                                }
                            }
                        }
                    }
                }
                Some("function_call") => {
                    // Extract function calls
                    let name = item
                        .get("name")
                        .and_then(|n| n.as_str())
                        .unwrap_or("")
                        .to_string();
                    let arguments = item
                        .get("arguments")
                        .and_then(|a| a.as_str())
                        .unwrap_or("{}")
                        .to_string();
                    let id = item
                        .get("id")
                        .or_else(|| item.get("call_id"))
                        .and_then(|i| i.as_str())
                        .map(|s| s.to_string());

                    tool_calls.push(LlmToolCall {
                        id,
                        call_type: "function".to_string(),
                        function: LlmFunctionCall { name, arguments },
                    });
                }
                _ => {}
            }
        }
    }

    // Extract usage
    let usage = json.get("usage").map(|u| LlmUsage {
        prompt_tokens: u.get("input_tokens").and_then(|t| t.as_u64()).unwrap_or(0) as u32,
        completion_tokens: u.get("output_tokens").and_then(|t| t.as_u64()).unwrap_or(0) as u32,
        total_tokens: u.get("total_tokens").and_then(|t| t.as_u64()).unwrap_or(0) as u32,
        prompt_tokens_details: None,
    });

    // OpenAI Responses API doesn't return cost, so we set it to None
    // The SDK will use 0 when cost is not provided
    let cost_usd: Option<f64> = None;

    LlmCallResponse {
        content: if content.is_empty() {
            None
        } else {
            Some(content)
        },
        model: json
            .get("model")
            .and_then(|m| m.as_str())
            .map(|s| s.to_string()),
        usage,
        cost_usd,
        tool_calls: if tool_calls.is_empty() {
            None
        } else {
            Some(tool_calls)
        },
    }
}

/// Transform request body for Anthropic Messages API format
///
/// Anthropic's Messages API has specific requirements:
/// 1. System messages must be in a top-level `system` parameter, not in messages array
/// 2. Maximum of 4 cache_control blocks allowed
fn transform_for_anthropic(mut body: serde_json::Value) -> serde_json::Value {
    if let Some(messages) = body.get_mut("messages").and_then(|m| m.as_array_mut()) {
        // Extract system messages and combine into top-level system parameter
        let mut system_contents: Vec<serde_json::Value> = Vec::new();
        let mut non_system_messages: Vec<serde_json::Value> = Vec::new();

        for msg in messages.drain(..) {
            if msg.get("role").and_then(|r| r.as_str()) == Some("system") {
                // Extract content from system message
                if let Some(content) = msg.get("content") {
                    if let Some(text) = content.as_str() {
                        // Simple string content
                        system_contents.push(serde_json::json!({
                            "type": "text",
                            "text": text
                        }));
                    } else if let Some(arr) = content.as_array() {
                        // Array content (possibly with cache_control)
                        for item in arr {
                            system_contents.push(item.clone());
                        }
                    } else {
                        // Object content - pass through
                        system_contents.push(content.clone());
                    }
                }
            } else {
                non_system_messages.push(msg);
            }
        }

        // Replace messages with non-system messages only
        *messages = non_system_messages;

        // Add system parameter if we have system content
        if !system_contents.is_empty() {
            // Limit cache_control blocks to 4 (Anthropic limit)
            let mut cache_count = 0;
            for item in system_contents.iter_mut().rev() {
                if item.get("cache_control").is_some() {
                    cache_count += 1;
                    if cache_count > 4 {
                        // Remove excess cache_control
                        if let Some(obj) = item.as_object_mut() {
                            obj.remove("cache_control");
                        }
                    }
                }
            }

            // Also limit cache_control in messages
            for msg in messages.iter_mut() {
                if let Some(content) = msg.get_mut("content").and_then(|c| c.as_array_mut()) {
                    for item in content.iter_mut().rev() {
                        if item.get("cache_control").is_some() {
                            cache_count += 1;
                            if cache_count > 4 {
                                if let Some(obj) = item.as_object_mut() {
                                    obj.remove("cache_control");
                                }
                            }
                        }
                    }
                }
            }

            body["system"] = serde_json::Value::Array(system_contents);
        }
    }

    body
}

/// Make actual LLM API call
#[allow(clippy::too_many_arguments)]
async fn make_llm_request(
    api_key: &str,
    provider: &str,
    messages: &[LlmMessage],
    model: Option<&str>,
    max_tokens: Option<u32>,
    temperature: Option<f32>,
    extra_params: Option<&serde_json::Value>,
    raw_request: bool,
) -> anyhow::Result<LlmCallResponse> {
    // Use a client with 15 minute timeout for LLM calls (reasoning models can take a long time)
    let client = reqwest::Client::builder()
        .timeout(std::time::Duration::from_secs(900)) // 15 min timeout for LLM calls
        .connect_timeout(std::time::Duration::from_secs(30))
        .build()
        .unwrap_or_else(|_| reqwest::Client::new());

    // Determine endpoint and model based on provider
    let (endpoint, default_model, auth_header) = match provider.to_lowercase().as_str() {
        "openrouter" => (
            "https://openrouter.ai/api/v1/chat/completions",
            "anthropic/claude-3.5-sonnet",
            format!("Bearer {}", api_key),
        ),
        "openai" => (
            "https://api.openai.com/v1/chat/completions",
            "gpt-4o",
            format!("Bearer {}", api_key),
        ),
        "anthropic" => (
            "https://api.anthropic.com/v1/messages",
            "claude-3-5-sonnet-20241022",
            api_key.to_string(), // Anthropic uses x-api-key header
        ),
        "chutes" => (
            "https://llm.chutes.ai/v1/chat/completions",
            "deepseek-ai/DeepSeek-V3",
            format!("Bearer {}", api_key),
        ),
        "grok" => (
            "https://api.x.ai/v1/chat/completions",
            "grok-2-latest",
            format!("Bearer {}", api_key),
        ),
        _ => {
            anyhow::bail!("Unsupported provider: {}", provider);
        }
    };

    let model = model.unwrap_or(default_model);

    // Check if this is an OpenAI Responses API model (GPT-4.1+, GPT-5.x)
    let use_responses_api = provider == "openai" && is_openai_responses_model(model);

    // Determine the actual endpoint
    let actual_endpoint = if use_responses_api {
        "https://api.openai.com/v1/responses"
    } else {
        endpoint
    };

    // Build request body
    let mut body = if use_responses_api {
        // Use Responses API format for GPT-4.1+ and GPT-5.x
        transform_to_responses_api(messages, model, max_tokens, temperature, extra_params)
    } else if raw_request {
        // For raw_request mode, build body with messages + model + extra_params
        // This allows full control over tool_calls, tool messages, etc.
        let mut b = serde_json::json!({
            "model": model,
            "messages": messages,
        });
        // Only add temperature if explicitly provided
        if let Some(temp) = temperature {
            b["temperature"] = serde_json::json!(temp);
        }
        // Check if max_completion_tokens is in extra_params (for o-series models)
        // If not, use max_tokens
        let has_max_completion_tokens = extra_params
            .as_ref()
            .and_then(|e| e.as_object())
            .map(|o| o.contains_key("max_completion_tokens"))
            .unwrap_or(false);
        if !has_max_completion_tokens {
            b["max_tokens"] = serde_json::json!(max_tokens.unwrap_or(64000));
        }
        // Merge extra_params (tools, tool_choice, max_completion_tokens, etc.) into body
        if let Some(extra) = extra_params {
            if let (Some(base), Some(extra_obj)) = (b.as_object_mut(), extra.as_object()) {
                for (key, value) in extra_obj {
                    base.insert(key.clone(), value.clone());
                }
            }
        }
        b
    } else {
        // Standard request body - check for max_completion_tokens in extra_params
        let has_max_completion_tokens = extra_params
            .as_ref()
            .and_then(|e| e.as_object())
            .map(|o| o.contains_key("max_completion_tokens"))
            .unwrap_or(false);

        let mut b = serde_json::json!({
            "model": model,
            "messages": messages,
        });
        // Only add temperature if explicitly provided
        if let Some(temp) = temperature {
            b["temperature"] = serde_json::json!(temp);
        }
        // Use max_completion_tokens if provided in extra_params (for o-series models)
        // Otherwise use max_tokens (for other models)
        if !has_max_completion_tokens {
            b["max_tokens"] = serde_json::json!(max_tokens.unwrap_or(64000));
        }
        b
    };

    // Merge extra_params if provided and not in raw_request mode (and not Responses API)
    if !raw_request && !use_responses_api {
        if let Some(extra) = extra_params {
            if let (Some(base), Some(extra_obj)) = (body.as_object_mut(), extra.as_object()) {
                for (key, value) in extra_obj {
                    // Allow all params to be overridden/added - no restrictions
                    base.insert(key.clone(), value.clone());
                }
            }
        }
    }

    // For OpenRouter: add usage: {include: true} to get cost and cache info in response
    // This enables prompt_tokens_details.cached_tokens and usage.cost fields
    // See: https://openrouter.ai/docs/guides/guides/usage-accounting
    if provider == "openrouter" {
        if let Some(base) = body.as_object_mut() {
            base.insert("usage".to_string(), serde_json::json!({"include": true}));
        }
    }

    // Transform request for Anthropic Messages API format
    // Only for direct Anthropic API - OpenRouter handles the transformation itself
    // OpenRouter uses OpenAI-compatible format (messages array with system role)
    // Skip if using Responses API
    if !use_responses_api && provider == "anthropic" {
        body = transform_for_anthropic(body);
    }

    // Make request
    let mut request = client
        .post(actual_endpoint)
        .header("Content-Type", "application/json");

    if provider == "anthropic" {
        request = request
            .header("x-api-key", api_key)
            .header("anthropic-version", "2023-06-01");
    } else {
        request = request.header("Authorization", &auth_header);
    }

    let response = request
        .json(&body)
        .send()
        .await
        .map_err(|e| anyhow::anyhow!("Request failed: {}", e))?;

    let status = response.status();
    let response_text = response.text().await?;

    // Handle empty responses explicitly - this usually indicates a timeout or server issue
    if response_text.is_empty() {
        warn!(
            "LLM API: provider returned empty response (status {})",
            status
        );
        return Err(LlmApiError {
            status_code: status.as_u16(),
            message: "LLM provider returned empty response - this usually indicates a timeout or server overload".to_string(),
            error_type: Some("empty_response".to_string()),
            raw_response: None,
        }
        .into());
    }

    if !status.is_success() {
        // Parse error response from provider
        let (error_message, error_type) = parse_llm_error_response(&response_text);

        warn!(
            "LLM API error: status={}, type={:?}, message={}",
            status.as_u16(),
            error_type,
            error_message
        );

        return Err(LlmApiError {
            status_code: status.as_u16(),
            message: error_message,
            error_type,
            raw_response: Some(truncate_utf8_safe(&response_text, 500)),
        }
        .into());
    }

    // Parse response - handle non-JSON responses gracefully
    let json: serde_json::Value = match serde_json::from_str(&response_text) {
        Ok(json) => json,
        Err(_parse_err) => {
            // Response is not valid JSON - this can happen with some provider errors
            // (e.g., "error code: 504" from nginx/cloudflare proxies)
            let truncated = truncate_utf8_safe(&response_text, 500);

            // Check if the raw response indicates a known error condition
            let lower_response = response_text.to_lowercase();
            let (error_type, status_code) =
                if lower_response.contains("504") || lower_response.contains("gateway timeout") {
                    (Some("gateway_timeout".to_string()), 504u16)
                } else if lower_response.contains("503")
                    || lower_response.contains("service unavailable")
                {
                    (Some("service_unavailable".to_string()), 503u16)
                } else if lower_response.contains("502") || lower_response.contains("bad gateway") {
                    (Some("bad_gateway".to_string()), 502u16)
                } else {
                    (Some("invalid_response".to_string()), 502u16)
                };

            warn!(
                "LLM API: received non-JSON response (detected error type: {:?}): {}",
                error_type, truncated
            );

            return Err(LlmApiError {
                status_code,
                message: format!("LLM provider returned non-JSON response: {}", truncated),
                error_type,
                raw_response: Some(truncated),
            }
            .into());
        }
    };

    // Use specialized parser for Responses API
    if use_responses_api {
        // Check for API-level errors in Responses API format
        if json.get("status").and_then(|s| s.as_str()) == Some("failed") {
            let error = json.get("error").cloned().unwrap_or(serde_json::json!({}));
            let error_msg = error
                .get("message")
                .and_then(|m| m.as_str())
                .unwrap_or("Unknown error");
            anyhow::bail!("Responses API error: {}", error_msg);
        }
        return Ok(parse_responses_api_response(&json, model));
    }

    // Extract content (OpenAI/OpenRouter format)
    let content = json["choices"][0]["message"]["content"]
        .as_str()
        .map(|s| s.to_string());

    let response_model = json["model"].as_str().map(|s| s.to_string());

    let usage = json.get("usage").map(|usage_obj| LlmUsage {
        prompt_tokens: usage_obj["prompt_tokens"].as_u64().unwrap_or(0) as u32,
        completion_tokens: usage_obj["completion_tokens"].as_u64().unwrap_or(0) as u32,
        total_tokens: usage_obj["total_tokens"].as_u64().unwrap_or(0) as u32,
        prompt_tokens_details: usage_obj.get("prompt_tokens_details").cloned(),
    });

    // Try to use provider-reported cost first (OpenRouter, some providers include this)
    // Common fields: usage.cost, usage.total_cost, cost (top-level)
    let provider_cost = json["usage"]["cost"]
        .as_f64()
        .or_else(|| json["usage"]["total_cost"].as_f64())
        .or_else(|| json["cost"].as_f64());

    // Use provider-reported cost only, no estimation fallback
    // OpenRouter returns cost in usage.cost, OpenAI doesn't return cost
    // If provider doesn't report cost, it will be None (SDK will use 0)
    let cost_usd = provider_cost;

    // Log cache information if available (OpenRouter with usage: {include: true})
    // cached_tokens = tokens read from cache (reduces cost)
    let cached_tokens = json["usage"]["prompt_tokens_details"]["cached_tokens"]
        .as_u64()
        .unwrap_or(0);
    if cached_tokens > 0 {
        let prompt_tokens = json["usage"]["prompt_tokens"].as_u64().unwrap_or(0);
        let cache_hit_ratio = if prompt_tokens > 0 {
            (cached_tokens as f64 / prompt_tokens as f64) * 100.0
        } else {
            0.0
        };
        info!(
            "LLM cache hit: {} cached of {} prompt tokens ({:.1}% hit rate)",
            cached_tokens, prompt_tokens, cache_hit_ratio
        );
    }

    // Extract tool_calls if present (OpenAI/OpenRouter format)
    let tool_calls = json["choices"][0]["message"]["tool_calls"]
        .as_array()
        .map(|calls| {
            calls
                .iter()
                .filter_map(|tc| {
                    let id = tc["id"].as_str().map(|s| s.to_string());
                    let call_type = tc["type"].as_str().unwrap_or("function").to_string();
                    let func = &tc["function"];
                    let name = func["name"].as_str()?.to_string();
                    let arguments = func["arguments"].as_str().unwrap_or("{}").to_string();
                    Some(LlmToolCall {
                        id,
                        call_type,
                        function: LlmFunctionCall { name, arguments },
                    })
                })
                .collect::<Vec<_>>()
        })
        .filter(|v| !v.is_empty());

    Ok(LlmCallResponse {
        content,
        model: response_model,
        usage,
        cost_usd,
        tool_calls,
    })
}

/// POST /api/v1/llm/chat/stream - Streaming LLM proxy for agent requests
///
/// Same validation as non-streaming endpoint, but returns SSE stream.
/// Usage is tracked after the stream completes (from final usage chunk).
pub async fn llm_chat_proxy_stream(
    State(state): State<Arc<ApiState>>,
    Json(req): Json<LlmProxyRequest>,
) -> Result<Response, (StatusCode, Json<LlmProxyResponse>)> {
    let err_response = |msg: String| LlmProxyResponse {
        success: false,
        content: None,
        model: None,
        usage: None,
        cost_usd: None,
        error: Some(msg),
        tool_calls: None,
    };

    // Validate validator hotkey
    if !is_valid_ss58_hotkey(&req.validator_hotkey) {
        return Err((
            StatusCode::BAD_REQUEST,
            Json(err_response("Invalid validator hotkey format".to_string())),
        ));
    }

    // Validate timestamp
    if !is_timestamp_valid(req.timestamp) {
        return Err((
            StatusCode::BAD_REQUEST,
            Json(err_response("Request timestamp expired".to_string())),
        ));
    }

    // Verify signature (skip in test mode)
    let message = format!("llm_chat:{}:{}", req.timestamp, req.agent_hash);
    let skip_auth = std::env::var("SKIP_AUTH")
        .map(|v| v == "1")
        .unwrap_or(false);

    if !skip_auth && !verify_signature(&req.validator_hotkey, &message, &req.signature) {
        return Err((
            StatusCode::UNAUTHORIZED,
            Json(err_response("Invalid signature".to_string())),
        ));
    }

    // Verify validator is authorized
    if !skip_auth && !state.is_authorized_validator(&req.validator_hotkey).await {
        return Err((
            StatusCode::FORBIDDEN,
            Json(err_response(
                "Validator not authorized (requires >= 10000 TAO stake)".to_string(),
            )),
        ));
    }

    // Get agent's DECRYPTED API key and provider from submission
    // The API key is stored encrypted in the DB and must be decrypted server-side
    let (api_key, provider) = state
        .storage
        .get_submission_api_key(&req.agent_hash)
        .await
        .map_err(|e| {
            error!("LLM stream: failed to get API key: {}", e);
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(err_response(format!(
                    "Failed to lookup agent API key: {}",
                    e
                ))),
            )
        })?
        .ok_or_else(|| {
            (
                StatusCode::BAD_REQUEST,
                Json(err_response("Agent has no API key configured".to_string())),
            )
        })?;

    // Check cost limit before making the LLM call
    let (current_cost, cost_limit) = state
        .storage
        .get_submission_costs(&req.agent_hash)
        .await
        .map_err(|e| {
            error!("Failed to get submission costs: {}", e);
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(err_response(format!("Database error: {}", e))),
            )
        })?;

    if current_cost >= cost_limit {
        warn!(
            "LLM stream: cost limit exceeded for agent {}: ${:.4} >= ${:.4}",
            &req.agent_hash[..12.min(req.agent_hash.len())],
            current_cost,
            cost_limit
        );
        return Err((
            StatusCode::PAYMENT_REQUIRED,
            Json(err_response(format!(
                "cost_limit_exceeded: ${:.4} used of ${:.4} limit",
                current_cost, cost_limit
            ))),
        ));
    }

    info!(
        "LLM stream: validator {} requesting for agent {} (provider: {})",
        &req.validator_hotkey[..12.min(req.validator_hotkey.len())],
        &req.agent_hash[..12.min(req.agent_hash.len())],
        provider
    );

    // Make streaming LLM request and return SSE response
    let stream_response = make_llm_stream_request(
        &api_key,
        &provider,
        &req.messages,
        req.model.as_deref(),
        req.max_tokens,
        req.temperature,
        req.extra_params.as_ref(),
        req.raw_request.unwrap_or(false),
        state.clone(),
        req.agent_hash.clone(),
        req.validator_hotkey.clone(),
        req.task_id.clone(),
    )
    .await;

    match stream_response {
        Ok(response) => Ok(response),
        Err(e) => {
            // Check if it's an LlmApiError with preserved status code
            if let Some(llm_err) = e.downcast_ref::<LlmApiError>() {
                warn!(
                    "LLM stream: API error for agent {} - status={}, type={:?}, msg={}",
                    &req.agent_hash[..12.min(req.agent_hash.len())],
                    llm_err.status_code,
                    llm_err.error_type,
                    llm_err.message
                );

                // Log raw response at debug level for troubleshooting
                if let Some(ref raw) = llm_err.raw_response {
                    debug!("LLM stream raw error response: {}", raw);
                }

                // Map LLM provider status codes to appropriate HTTP responses
                let http_status = map_llm_status_code(llm_err.status_code);

                return Err((
                    http_status,
                    Json(LlmProxyResponse {
                        success: false,
                        content: None,
                        model: None,
                        usage: None,
                        cost_usd: None,
                        error: Some(format!(
                            "{}: {}",
                            llm_err.error_type.as_deref().unwrap_or("llm_error"),
                            llm_err.message
                        )),
                        tool_calls: None,
                    }),
                ));
            }

            // Generic/network error
            error!(
                "LLM stream: request failed for agent {}: {}",
                &req.agent_hash[..12.min(req.agent_hash.len())],
                e
            );
            Err((
                StatusCode::BAD_GATEWAY,
                Json(err_response(format!("LLM stream failed: {}", e))),
            ))
        }
    }
}

/// Make streaming LLM API call and return SSE response
#[allow(clippy::too_many_arguments)]
async fn make_llm_stream_request(
    api_key: &str,
    provider: &str,
    messages: &[LlmMessage],
    model: Option<&str>,
    max_tokens: Option<u32>,
    temperature: Option<f32>,
    extra_params: Option<&serde_json::Value>,
    raw_request: bool,
    state: Arc<ApiState>,
    agent_hash: String,
    validator_hotkey: String,
    task_id: Option<String>,
) -> anyhow::Result<Response> {
    use futures::StreamExt;
    use tokio_stream::wrappers::ReceiverStream;

    // Determine endpoint and model based on provider
    // Note: Anthropic requires different streaming format (not OpenAI-compatible)
    let (endpoint, default_model, auth_header) = match provider.to_lowercase().as_str() {
        "openrouter" => (
            "https://openrouter.ai/api/v1/chat/completions",
            "anthropic/claude-3.5-sonnet",
            format!("Bearer {}", api_key),
        ),
        "openai" => (
            "https://api.openai.com/v1/chat/completions",
            "gpt-4o",
            format!("Bearer {}", api_key),
        ),
        "chutes" => (
            "https://llm.chutes.ai/v1/chat/completions",
            "deepseek-ai/DeepSeek-V3",
            format!("Bearer {}", api_key),
        ),
        "grok" => (
            "https://api.x.ai/v1/chat/completions",
            "grok-2-latest",
            format!("Bearer {}", api_key),
        ),
        "anthropic" => {
            // Anthropic streaming is supported but uses different format
            // We'll handle it specially below
            (
                "https://api.anthropic.com/v1/messages",
                "claude-3-5-sonnet-20241022",
                api_key.to_string(),
            )
        }
        _ => {
            anyhow::bail!("Streaming not supported for provider: {}", provider);
        }
    };

    let model = model.unwrap_or(default_model).to_string();

    // Check if this is an OpenAI Responses API model (GPT-4.1+, GPT-5.x)
    let use_responses_api = provider == "openai" && is_openai_responses_model(&model);

    // Determine the actual endpoint
    let actual_endpoint = if use_responses_api {
        "https://api.openai.com/v1/responses"
    } else {
        endpoint
    };

    // Build request body with stream: true
    let mut body = if use_responses_api {
        // Use Responses API format with streaming
        let mut responses_body =
            transform_to_responses_api(messages, &model, max_tokens, temperature, extra_params);
        responses_body["stream"] = serde_json::json!(true);
        responses_body
    } else if raw_request {
        // For raw_request mode, build body with messages + model + extra_params
        // This allows full control over tool_calls, tool messages, etc.
        let mut b = serde_json::json!({
            "model": model,
            "messages": messages,
            "stream": true,
        });
        // Only add temperature if explicitly provided
        if let Some(temp) = temperature {
            b["temperature"] = serde_json::json!(temp);
        }
        // Check if max_completion_tokens is in extra_params (for o-series models)
        let has_max_completion_tokens = extra_params
            .as_ref()
            .and_then(|e| e.as_object())
            .map(|o| o.contains_key("max_completion_tokens"))
            .unwrap_or(false);
        if !has_max_completion_tokens {
            b["max_tokens"] = serde_json::json!(max_tokens.unwrap_or(4096));
        }
        // Merge extra_params (tools, tool_choice, max_completion_tokens, etc.) into body
        if let Some(extra) = extra_params {
            if let (Some(base), Some(extra_obj)) = (b.as_object_mut(), extra.as_object()) {
                for (key, value) in extra_obj {
                    base.insert(key.clone(), value.clone());
                }
            }
        }
        b
    } else {
        // Standard request body - check for max_completion_tokens in extra_params
        let has_max_completion_tokens = extra_params
            .as_ref()
            .and_then(|e| e.as_object())
            .map(|o| o.contains_key("max_completion_tokens"))
            .unwrap_or(false);

        let mut b = serde_json::json!({
            "model": model,
            "messages": messages,
            "stream": true,
        });
        // Only add temperature if explicitly provided
        if let Some(temp) = temperature {
            b["temperature"] = serde_json::json!(temp);
        }
        if !has_max_completion_tokens {
            b["max_tokens"] = serde_json::json!(max_tokens.unwrap_or(4096));
        }
        b
    };

    // Merge extra_params if provided and not in raw_request mode (and not Responses API)
    if !raw_request && !use_responses_api {
        if let Some(extra) = extra_params {
            if let (Some(base), Some(extra_obj)) = (body.as_object_mut(), extra.as_object()) {
                for (key, value) in extra_obj {
                    base.insert(key.clone(), value.clone());
                }
            }
        }
    }

    // For OpenRouter: add usage: {include: true} to get cost and cache info in final SSE chunk
    // This enables prompt_tokens_details.cached_tokens and usage.cost fields
    // See: https://openrouter.ai/docs/guides/guides/usage-accounting
    if provider == "openrouter" {
        if let Some(base) = body.as_object_mut() {
            base.insert("usage".to_string(), serde_json::json!({"include": true}));
        }
    }

    // Transform request for Anthropic Messages API format
    // (system messages must be top-level `system` param, not in messages array)
    // Skip if using Responses API
    if !use_responses_api && provider == "anthropic" {
        body = transform_for_anthropic(body);
    }

    let client = reqwest::Client::new();
    let mut request = client
        .post(actual_endpoint)
        .header("Content-Type", "application/json");

    // Add provider-specific headers
    if provider == "anthropic" {
        request = request
            .header("x-api-key", api_key)
            .header("anthropic-version", "2023-06-01");
    } else {
        request = request.header("Authorization", &auth_header);
    }

    if provider == "openrouter" {
        request = request.header("HTTP-Referer", "https://platform.network");
    }

    let response = request
        .json(&body)
        .send()
        .await
        .map_err(|e| anyhow::anyhow!("Stream request failed: {}", e))?;

    if !response.status().is_success() {
        let status = response.status();
        let error_text = response.text().await.unwrap_or_default();

        // Parse error response from provider
        let (error_message, error_type) = parse_llm_error_response(&error_text);

        warn!(
            "LLM stream API error: status={}, type={:?}, message={}",
            status.as_u16(),
            error_type,
            error_message
        );

        return Err(LlmApiError {
            status_code: status.as_u16(),
            message: error_message,
            error_type,
            raw_response: Some(truncate_utf8_safe(&error_text, 500)),
        }
        .into());
    }

    // Create a channel to send SSE events
    let (tx, rx) = tokio::sync::mpsc::channel::<Result<String, std::io::Error>>(32);

    // Spawn a task to process the upstream stream
    let model_for_tracking = model.clone();
    let is_responses_api = use_responses_api; // Capture for the async block
    tokio::spawn(async move {
        use futures::TryStreamExt;

        let mut byte_stream = response.bytes_stream();
        let mut buffer = String::new();
        let mut total_content = String::new();

        // Track usage from stream chunks (some providers send usage in final chunk)
        let mut stream_usage: Option<(i32, i32)> = None; // (prompt_tokens, completion_tokens)
        let mut stream_cost: Option<f64> = None; // Provider-reported cost

        while let Ok(Some(chunk)) = byte_stream.try_next().await {
            if let Ok(text) = String::from_utf8(chunk.to_vec()) {
                buffer.push_str(&text);

                // Process complete SSE lines
                while let Some(newline_pos) = buffer.find('\n') {
                    let line = buffer[..newline_pos].trim().to_string();
                    buffer = buffer[newline_pos + 1..].to_string();

                    if line.is_empty() || !line.starts_with("data: ") {
                        continue;
                    }

                    let data = &line[6..];
                    if data == "[DONE]" {
                        // Send done marker
                        let _ = tx.send(Ok("data: [DONE]\n\n".to_string())).await;
                        break;
                    }

                    // Parse chunk to extract content and usage info
                    if let Ok(json) = serde_json::from_str::<serde_json::Value>(data) {
                        if is_responses_api {
                            // Responses API streaming format
                            let event_type =
                                json.get("type").and_then(|t| t.as_str()).unwrap_or("");

                            match event_type {
                                "response.output_text.delta" => {
                                    // Extract text delta
                                    if let Some(delta) = json.get("delta").and_then(|d| d.as_str())
                                    {
                                        total_content.push_str(delta);
                                        // Convert to OpenAI-compatible format for downstream
                                        let compat_chunk = serde_json::json!({
                                            "choices": [{
                                                "delta": {"content": delta},
                                                "index": 0
                                            }]
                                        });
                                        let sse_line = format!("data: {}\n\n", compat_chunk);
                                        if tx.send(Ok(sse_line)).await.is_err() {
                                            break;
                                        }
                                    }
                                }
                                "response.completed" => {
                                    // Extract usage from completed event
                                    if let Some(resp) = json.get("response") {
                                        if let Some(usage) = resp.get("usage") {
                                            let input =
                                                usage["input_tokens"].as_i64().unwrap_or(0) as i32;
                                            let output =
                                                usage["output_tokens"].as_i64().unwrap_or(0) as i32;
                                            if input > 0 || output > 0 {
                                                stream_usage = Some((input, output));
                                            }
                                        }
                                    }
                                }
                                _ => {
                                    // Forward other events as-is (function_call, etc.)
                                    let sse_line = format!("data: {}\n\n", data);
                                    if tx.send(Ok(sse_line)).await.is_err() {
                                        break;
                                    }
                                }
                            }
                        } else {
                            // Standard OpenAI/OpenRouter streaming format
                            // Extract content from delta
                            if let Some(content) = json["choices"][0]["delta"]["content"].as_str() {
                                total_content.push_str(content);
                            }

                            // Check for usage info (sent in final chunks by OpenAI, OpenRouter, etc.)
                            if let Some(usage) = json.get("usage") {
                                let prompt = usage["prompt_tokens"].as_i64().unwrap_or(0) as i32;
                                let completion =
                                    usage["completion_tokens"].as_i64().unwrap_or(0) as i32;
                                if prompt > 0 || completion > 0 {
                                    stream_usage = Some((prompt, completion));
                                }

                                // Check for provider-reported cost
                                if let Some(cost) = usage["cost"]
                                    .as_f64()
                                    .or_else(|| usage["total_cost"].as_f64())
                                {
                                    stream_cost = Some(cost);
                                }
                            }

                            // Also check top-level cost field (some providers)
                            if stream_cost.is_none() {
                                if let Some(cost) = json["cost"].as_f64() {
                                    stream_cost = Some(cost);
                                }
                            }

                            // Forward the SSE line
                            let sse_line = format!("data: {}\n\n", data);
                            if tx.send(Ok(sse_line)).await.is_err() {
                                break;
                            }
                        }
                    }
                }
            }
        }

        // Track usage after stream completes
        // Use actual usage from stream if available, otherwise estimate
        let (prompt_tokens, completion_tokens) = stream_usage.unwrap_or_else(|| {
            // Estimate tokens: ~4 chars per token for English text, ~2-3 for code
            // Use 3.5 as a conservative middle ground
            let est_completion = (total_content.len() as f64 / 3.5).ceil() as i32;
            // Estimate prompt tokens from completion (rough approximation)
            let est_prompt = (est_completion as f64 * 0.3).ceil() as i32;
            (est_prompt, est_completion)
        });

        // Use provider-reported cost only, no estimation fallback
        // OpenRouter returns cost, OpenAI doesn't - if no cost, use 0
        let cost = stream_cost.unwrap_or(0.0);

        if let Err(e) = state
            .storage
            .record_llm_usage(LlmUsageRecord {
                agent_hash: agent_hash.clone(),
                validator_hotkey: validator_hotkey.clone(),
                task_id,
                model: model_for_tracking.clone(),
                prompt_tokens,
                completion_tokens,
                cost_usd: cost,
            })
            .await
        {
            warn!("Failed to record stream LLM usage: {}", e);
        }

        if cost > 0.0 {
            if let Err(e) = state.storage.add_submission_cost(&agent_hash, cost).await {
                warn!("Failed to update submission cost after stream: {}", e);
            }
        }

        let usage_source = if stream_usage.is_some() {
            "actual"
        } else {
            "estimated"
        };
        let cost_source = if stream_cost.is_some() {
            "provider"
        } else {
            "calculated"
        };
        info!(
            "LLM stream: completed for agent {}, model={}, {} tokens ({} prompt={}, completion={}), ${:.4} ({})",
            &agent_hash[..12.min(agent_hash.len())],
            model_for_tracking,
            prompt_tokens + completion_tokens,
            usage_source,
            prompt_tokens,
            completion_tokens,
            cost,
            cost_source
        );
    });

    // Return SSE response
    let stream = ReceiverStream::new(rx);
    let body = Body::from_stream(stream);

    Ok(Response::builder()
        .status(StatusCode::OK)
        .header("Content-Type", "text/event-stream")
        .header("Cache-Control", "no-cache")
        .header("Connection", "keep-alive")
        .body(body)
        .unwrap())
}

// =============================================================================
// SUDO Endpoints - Subnet Owner Only (signature verified)
// =============================================================================

#[derive(Debug, Deserialize)]
pub struct SudoRequest {
    /// Owner hotkey (must be the subnet owner)
    pub owner_hotkey: String,
    /// Signature of "sudo:<action>:<timestamp>:<agent_hash>"
    pub signature: String,
    /// Request timestamp (must be within 5 minutes)
    pub timestamp: i64,
}

#[derive(Debug, Serialize)]
pub struct SudoResponse {
    pub success: bool,
    pub message: String,
    pub error: Option<String>,
}

/// Verify sudo request is from subnet owner
fn verify_sudo_request(
    req: &SudoRequest,
    action: &str,
    agent_hash: &str,
) -> Result<(), (StatusCode, Json<SudoResponse>)> {
    let err = |msg: &str| {
        Err((
            StatusCode::FORBIDDEN,
            Json(SudoResponse {
                success: false,
                message: String::new(),
                error: Some(msg.to_string()),
            }),
        ))
    };

    // Validate owner hotkey format
    if !is_valid_ss58_hotkey(&req.owner_hotkey) {
        return err("Invalid owner hotkey format");
    }

    // Validate timestamp
    if !is_timestamp_valid(req.timestamp) {
        return err("Request timestamp expired");
    }

    // Get expected owner from environment (with default for term-challenge)
    let expected_owner = std::env::var("SUBNET_OWNER_HOTKEY")
        .unwrap_or_else(|_| "5GziQCcRpN8NCJktX343brnfuVe3w6gUYieeStXPD1Dag2At".to_string());
    if expected_owner.is_empty() {
        return err("Subnet owner not configured");
    }

    // Verify owner matches
    if req.owner_hotkey != expected_owner {
        warn!(
            "Sudo attempt by non-owner: {} (expected: {})",
            &req.owner_hotkey[..16.min(req.owner_hotkey.len())],
            &expected_owner[..16.min(expected_owner.len())]
        );
        return err("Not subnet owner");
    }

    // Verify signature (skip in test mode)
    let message = format!("sudo:{}:{}:{}", action, req.timestamp, agent_hash);
    let skip_auth = std::env::var("SKIP_AUTH")
        .map(|v| v == "1")
        .unwrap_or(false);

    if !skip_auth && !verify_signature(&req.owner_hotkey, &message, &req.signature) {
        return err("Invalid signature");
    }

    Ok(())
}

/// POST /api/v1/sudo/relaunch/:agent_hash - Relaunch evaluation for an agent
///
/// Resets validator assignments and allows re-evaluation.
/// Use when evaluations failed or need to be redone.
pub async fn sudo_relaunch_evaluation(
    State(state): State<Arc<ApiState>>,
    Path(agent_hash): Path<String>,
    Json(req): Json<SudoRequest>,
) -> Result<Json<SudoResponse>, (StatusCode, Json<SudoResponse>)> {
    verify_sudo_request(&req, "relaunch", &agent_hash)?;

    // Reset validator assignments for this agent
    state
        .storage
        .reset_agent_assignments(&agent_hash)
        .await
        .map_err(|e| {
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(SudoResponse {
                    success: false,
                    message: String::new(),
                    error: Some(e.to_string()),
                }),
            )
        })?;

    info!("SUDO: Relaunched evaluation for agent {}", agent_hash);

    Ok(Json(SudoResponse {
        success: true,
        message: format!("Evaluation relaunched for agent {}", agent_hash),
        error: None,
    }))
}

/// POST /api/v1/sudo/approve/:agent_hash - Manually approve a flagged agent
///
/// Approves an agent that was flagged by LLM review and assigns validators.
pub async fn sudo_approve_agent(
    State(state): State<Arc<ApiState>>,
    Path(agent_hash): Path<String>,
    Json(req): Json<SudoRequest>,
) -> Result<Json<SudoResponse>, (StatusCode, Json<SudoResponse>)> {
    verify_sudo_request(&req, "approve", &agent_hash)?;

    // Update agent to approved and assign validators
    state
        .storage
        .sudo_approve_agent(&agent_hash)
        .await
        .map_err(|e| {
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(SudoResponse {
                    success: false,
                    message: String::new(),
                    error: Some(e.to_string()),
                }),
            )
        })?;

    info!("SUDO: Approved agent {}", agent_hash);

    Ok(Json(SudoResponse {
        success: true,
        message: format!("Agent {} approved and validators assigned", agent_hash),
        error: None,
    }))
}

/// POST /api/v1/sudo/reject/:agent_hash - Reject an agent
///
/// Permanently rejects an agent submission.
pub async fn sudo_reject_agent(
    State(state): State<Arc<ApiState>>,
    Path(agent_hash): Path<String>,
    Json(req): Json<SudoRequest>,
) -> Result<Json<SudoResponse>, (StatusCode, Json<SudoResponse>)> {
    verify_sudo_request(&req, "reject", &agent_hash)?;

    state
        .storage
        .sudo_reject_agent(&agent_hash)
        .await
        .map_err(|e| {
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(SudoResponse {
                    success: false,
                    message: String::new(),
                    error: Some(e.to_string()),
                }),
            )
        })?;

    info!("SUDO: Rejected agent {}", agent_hash);

    Ok(Json(SudoResponse {
        success: true,
        message: format!("Agent {} rejected", agent_hash),
        error: None,
    }))
}

#[derive(Debug, Deserialize)]
pub struct SudoSetStatusRequest {
    pub owner_hotkey: String,
    pub signature: String,
    pub timestamp: i64,
    pub status: String,
    pub reason: Option<String>,
}

/// POST /api/v1/sudo/set_status/:agent_hash - Set agent status
///
/// Set arbitrary status on an agent (pending, approved, rejected, etc.)
pub async fn sudo_set_agent_status(
    State(state): State<Arc<ApiState>>,
    Path(agent_hash): Path<String>,
    Json(req): Json<SudoSetStatusRequest>,
) -> Result<Json<SudoResponse>, (StatusCode, Json<SudoResponse>)> {
    // Create a SudoRequest for verification
    let sudo_req = SudoRequest {
        owner_hotkey: req.owner_hotkey.clone(),
        signature: req.signature.clone(),
        timestamp: req.timestamp,
    };
    verify_sudo_request(&sudo_req, "set_status", &agent_hash)?;

    state
        .storage
        .sudo_set_status(&agent_hash, &req.status, req.reason.as_deref())
        .await
        .map_err(|e| {
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(SudoResponse {
                    success: false,
                    message: String::new(),
                    error: Some(e.to_string()),
                }),
            )
        })?;

    info!("SUDO: Set agent {} status to {}", agent_hash, req.status);

    Ok(Json(SudoResponse {
        success: true,
        message: format!("Agent {} status set to {}", agent_hash, req.status),
        error: None,
    }))
}

#[derive(Debug, Deserialize)]
pub struct SudoCancelRequest {
    pub owner_hotkey: String,
    pub signature: String,
    pub timestamp: i64,
    pub reason: Option<String>,
}

/// POST /api/v1/sudo/cancel/:agent_hash - Cancel an agent evaluation
///
/// Cancels an in-progress or pending agent evaluation.
/// This will:
/// - Set status to 'cancelled'
/// - Remove from pending_evaluations
/// - Remove validator_assignments
/// - Log the cancellation for audit
pub async fn sudo_cancel_agent(
    State(state): State<Arc<ApiState>>,
    Path(agent_hash): Path<String>,
    Json(req): Json<SudoCancelRequest>,
) -> Result<Json<SudoResponse>, (StatusCode, Json<SudoResponse>)> {
    // Create a SudoRequest for verification
    let sudo_req = SudoRequest {
        owner_hotkey: req.owner_hotkey.clone(),
        signature: req.signature.clone(),
        timestamp: req.timestamp,
    };
    verify_sudo_request(&sudo_req, "cancel", &agent_hash)?;

    state
        .storage
        .cancel_agent(&agent_hash, &req.owner_hotkey, req.reason.as_deref())
        .await
        .map_err(|e| {
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(SudoResponse {
                    success: false,
                    message: String::new(),
                    error: Some(e.to_string()),
                }),
            )
        })?;

    info!(
        "SUDO: Cancelled agent {} by {} (reason: {:?})",
        agent_hash, req.owner_hotkey, req.reason
    );

    Ok(Json(SudoResponse {
        success: true,
        message: format!("Agent {} cancelled", agent_hash),
        error: None,
    }))
}

// ============================================================================
// TASK OBSERVABILITY ENDPOINTS
// ============================================================================

/// GET /api/v1/agent/:agent_hash/tasks - Get all task logs for an agent
pub async fn get_agent_tasks(
    State(state): State<Arc<ApiState>>,
    Path(agent_hash): Path<String>,
) -> Result<Json<AgentTasksResponse>, (StatusCode, Json<serde_json::Value>)> {
    let task_logs = state
        .storage
        .get_agent_task_logs(&agent_hash)
        .await
        .map_err(|e| {
            error!("Failed to get agent task logs: {}", e);
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(serde_json::json!({"error": format!("Database error: {}", e)})),
            )
        })?;

    // Group by validator
    let mut validators_map: std::collections::HashMap<String, Vec<_>> =
        std::collections::HashMap::new();
    for log in task_logs {
        validators_map
            .entry(log.validator_hotkey.clone())
            .or_default()
            .push(log);
    }

    let validators: Vec<ValidatorTasksSummary> = validators_map
        .into_iter()
        .map(|(validator_hotkey, logs)| {
            let passed = logs.iter().filter(|l| l.passed).count() as i32;
            let failed = logs.iter().filter(|l| !l.passed).count() as i32;
            let total = logs.len() as i32;
            let score = if total > 0 {
                passed as f64 / total as f64
            } else {
                0.0
            };

            // Determine status
            let status = if total == 0 {
                "pending"
            } else {
                "completed" // We only have logs for completed tasks
            };

            ValidatorTasksSummary {
                validator_hotkey,
                status: status.to_string(),
                tasks: logs
                    .into_iter()
                    .map(|l| TaskLogResponse {
                        task_id: l.task_id,
                        task_name: l.task_name,
                        passed: l.passed,
                        score: l.score,
                        execution_time_ms: l.execution_time_ms,
                        error: l.error,
                        agent_stderr: l.agent_stderr,
                        agent_stdout: l.agent_stdout,
                        test_output: l.test_output,
                        failure_stage: l.failure_stage,
                        completed_at: l.completed_at,
                    })
                    .collect(),
                summary: TaskSummaryStats {
                    total,
                    passed,
                    failed,
                    score,
                },
            }
        })
        .collect();

    Ok(Json(AgentTasksResponse {
        agent_hash,
        validators,
    }))
}

/// GET /api/v1/agent/:agent_hash/tasks/:task_id - Get specific task details
pub async fn get_agent_task_detail(
    State(state): State<Arc<ApiState>>,
    Path((agent_hash, task_id)): Path<(String, String)>,
) -> Result<Json<serde_json::Value>, (StatusCode, Json<serde_json::Value>)> {
    let task_logs = state
        .storage
        .get_agent_task_logs(&agent_hash)
        .await
        .map_err(|e| {
            error!("Failed to get agent task logs: {}", e);
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(serde_json::json!({"error": format!("Database error: {}", e)})),
            )
        })?;

    // Filter by task_id
    let matching_logs: Vec<_> = task_logs
        .into_iter()
        .filter(|l| l.task_id == task_id)
        .map(|l| TaskLogResponse {
            task_id: l.task_id,
            task_name: l.task_name,
            passed: l.passed,
            score: l.score,
            execution_time_ms: l.execution_time_ms,
            error: l.error,
            agent_stderr: l.agent_stderr,
            agent_stdout: l.agent_stdout,
            test_output: l.test_output,
            failure_stage: l.failure_stage,
            completed_at: l.completed_at,
        })
        .collect();

    if matching_logs.is_empty() {
        return Err((
            StatusCode::NOT_FOUND,
            Json(serde_json::json!({"error": "Task not found"})),
        ));
    }

    Ok(Json(serde_json::json!({
        "agent_hash": agent_hash,
        "task_id": task_id,
        "validators": matching_logs,
    })))
}

/// GET /api/v1/agent/:agent_hash/progress - Get evaluation progress for an agent
pub async fn get_agent_progress(
    State(state): State<Arc<ApiState>>,
    Path(agent_hash): Path<String>,
) -> Result<Json<AgentProgressResponse>, (StatusCode, Json<serde_json::Value>)> {
    let progress = state
        .storage
        .get_agent_evaluation_progress_all_validators(&agent_hash)
        .await
        .map_err(|e| {
            error!("Failed to get agent progress: {}", e);
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(serde_json::json!({"error": format!("Database error: {}", e)})),
            )
        })?;

    // Determine overall status
    let overall_status = if progress.is_empty() {
        "no_validators"
    } else if progress.iter().all(|p| p.status == "completed") {
        "completed"
    } else if progress.iter().any(|p| p.status == "in_progress") {
        "in_progress"
    } else {
        "pending"
    };

    let validators: Vec<ValidatorProgressResponse> = progress
        .into_iter()
        .map(|p| ValidatorProgressResponse {
            validator_hotkey: p.validator_hotkey,
            status: p.status,
            total_tasks: p.total_tasks,
            completed_tasks: p.completed_tasks,
            passed_tasks: p.passed_tasks,
            failed_tasks: p.failed_tasks,
            remaining_tasks: p.remaining_task_ids,
            current_task: p.current_task,
            started_at: p.started_at,
            last_update: p.last_update,
        })
        .collect();

    Ok(Json(AgentProgressResponse {
        agent_hash,
        overall_status: overall_status.to_string(),
        validators,
    }))
}

/// Query params for evaluations list
#[derive(Debug, Deserialize)]
pub struct EvaluationsQuery {
    pub limit: Option<i32>,
}

/// GET /api/v1/validator/:hotkey/evaluations - Get recent evaluations by a validator
pub async fn get_validator_evaluations_list(
    State(state): State<Arc<ApiState>>,
    Path(hotkey): Path<String>,
    Query(query): Query<EvaluationsQuery>,
) -> Result<Json<ValidatorEvaluationsResponse>, (StatusCode, Json<serde_json::Value>)> {
    let limit = query.limit.unwrap_or(50).min(100);

    let evaluations = state
        .storage
        .get_validator_recent_evaluations(&hotkey, limit)
        .await
        .map_err(|e| {
            error!("Failed to get validator evaluations: {}", e);
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(serde_json::json!({"error": format!("Database error: {}", e)})),
            )
        })?;

    let summaries: Vec<EvaluationSummary> = evaluations
        .into_iter()
        .map(|e| EvaluationSummary {
            agent_hash: e.agent_hash,
            miner_hotkey: e.miner_hotkey,
            score: e.score,
            tasks_passed: e.tasks_passed,
            tasks_total: e.tasks_total,
            tasks_failed: e.tasks_failed,
            total_cost_usd: e.total_cost_usd,
            created_at: e.created_at,
        })
        .collect();

    Ok(Json(ValidatorEvaluationsResponse {
        validator_hotkey: hotkey,
        evaluations: summaries,
    }))
}

/// GET /api/v1/validator/:hotkey/agent/:agent_hash/tasks - Get tasks for an agent by a specific validator
pub async fn get_validator_agent_tasks(
    State(state): State<Arc<ApiState>>,
    Path((hotkey, agent_hash)): Path<(String, String)>,
) -> Result<Json<ValidatorTasksSummary>, (StatusCode, Json<serde_json::Value>)> {
    let logs = state
        .storage
        .get_agent_task_logs_by_validator(&agent_hash, &hotkey)
        .await
        .map_err(|e| {
            error!("Failed to get validator agent tasks: {}", e);
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(serde_json::json!({"error": format!("Database error: {}", e)})),
            )
        })?;

    let passed = logs.iter().filter(|l| l.passed).count() as i32;
    let failed = logs.iter().filter(|l| !l.passed).count() as i32;
    let total = logs.len() as i32;
    let score = if total > 0 {
        passed as f64 / total as f64
    } else {
        0.0
    };

    let status = if total == 0 { "pending" } else { "completed" };

    let tasks: Vec<TaskLogResponse> = logs
        .into_iter()
        .map(|l| TaskLogResponse {
            task_id: l.task_id,
            task_name: l.task_name,
            passed: l.passed,
            score: l.score,
            execution_time_ms: l.execution_time_ms,
            error: l.error,
            agent_stderr: l.agent_stderr,
            agent_stdout: l.agent_stdout,
            test_output: l.test_output,
            failure_stage: l.failure_stage,
            completed_at: l.completed_at,
        })
        .collect();

    Ok(Json(ValidatorTasksSummary {
        validator_hotkey: hotkey,
        status: status.to_string(),
        tasks,
        summary: TaskSummaryStats {
            total,
            passed,
            failed,
            score,
        },
    }))
}

// ============================================================================
// TESTS
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_redact_api_keys_openai() {
        let code = r#"api_key = "sk-1234567890abcdefghijklmnopqrst""#;
        let redacted = redact_api_keys(code);
        assert!(!redacted.contains("sk-1234567890"));
        assert!(redacted.contains("[REDACTED:sk-***]"));
    }

    #[test]
    fn test_redact_api_keys_anthropic() {
        let code = r#"key = "sk-ant-api03-abcdefghij1234567890xyzabc""#;
        let redacted = redact_api_keys(code);
        assert!(!redacted.contains("sk-ant-api03"));
        assert!(redacted.contains("[REDACTED:sk-ant-***]"));
    }

    #[test]
    fn test_redact_api_keys_openrouter() {
        // Test OPENROUTER_API_KEY env var pattern
        let code = r#"OPENROUTER_API_KEY = "my-openrouter-key-12345""#;
        let redacted = redact_api_keys(code);
        assert!(!redacted.contains("my-openrouter-key"));
        assert!(redacted.contains("[REDACTED]"));
    }

    #[test]
    fn test_redact_api_keys_groq() {
        let code = r#"groq_key = "gsk_abcdefghij1234567890xyzabc""#;
        let redacted = redact_api_keys(code);
        assert!(!redacted.contains("gsk_abcdefghij"));
        assert!(redacted.contains("[REDACTED:gsk_***]"));
    }

    #[test]
    fn test_redact_api_keys_xai() {
        let code = r#"XAI_KEY = "xai-abcdefghij1234567890xyzabc""#;
        let redacted = redact_api_keys(code);
        assert!(!redacted.contains("xai-abcdefghij"));
        assert!(redacted.contains("[REDACTED:xai-***]"));
    }

    #[test]
    fn test_redact_api_keys_chutes() {
        let code = r#"chutes_key = "cpk_abcdefghij1234567890xyzabc""#;
        let redacted = redact_api_keys(code);
        assert!(!redacted.contains("cpk_abcdefghij"));
        assert!(redacted.contains("[REDACTED:cpk_***]"));
    }

    #[test]
    fn test_redact_api_keys_env_var() {
        let code = r#"OPENAI_API_KEY = "my-secret-key-12345""#;
        let redacted = redact_api_keys(code);
        assert!(!redacted.contains("my-secret-key"));
        assert!(redacted.contains("[REDACTED]"));
    }

    #[test]
    fn test_redact_api_keys_multiple() {
        let code = r#"
# Config
openai_key = "sk-proj-abcdefghij1234567890xyz"
anthropic = "sk-ant-api03-1234567890abcdefghijk"
groq = "gsk_1234567890abcdefghijklmn"
        "#;
        let redacted = redact_api_keys(code);
        assert!(!redacted.contains("sk-proj-abcdefghij"));
        assert!(!redacted.contains("sk-ant-api03"));
        assert!(!redacted.contains("gsk_1234567890"));
        assert!(redacted.contains("[REDACTED"));
    }

    #[test]
    fn test_redact_api_keys_preserves_short_strings() {
        // Short strings should not be redacted (less than 20 chars)
        let code = r#"short = "sk-short""#;
        let redacted = redact_api_keys(code);
        assert_eq!(code, redacted); // No change for short keys
    }

    #[test]
    fn test_redact_api_keys_preserves_normal_code() {
        let code = r#"
def main():
    print("Hello world")
    x = 42
    return x
        "#;
        let redacted = redact_api_keys(code);
        assert_eq!(code, redacted); // No change for normal code
    }

    #[test]
    fn test_redact_private_variables_python() {
        let code = r#"PRIVATE_KEY = "my-secret-key""#;
        let redacted = redact_api_keys(code);
        assert!(!redacted.contains("my-secret-key"));
        assert!(redacted.contains("PRIVATE_KEY = \"[REDACTED]\""));
    }

    #[test]
    fn test_redact_private_variables_json() {
        let code = r#"{"PRIVATE_API_KEY": "secret-value-123"}"#;
        let redacted = redact_api_keys(code);
        assert!(!redacted.contains("secret-value-123"));
        assert!(redacted.contains("\"PRIVATE_API_KEY\": \"[REDACTED]\""));
    }

    #[test]
    fn test_redact_secret_token_password() {
        let code = r#"
DB_SECRET = "database-password-123"
AUTH_TOKEN = "auth-token-xyz"
ADMIN_PASSWORD = "admin123"
        "#;
        let redacted = redact_api_keys(code);
        assert!(!redacted.contains("database-password-123"));
        assert!(!redacted.contains("auth-token-xyz"));
        assert!(!redacted.contains("admin123"));
        assert!(redacted.contains("[REDACTED]"));
    }

    #[test]
    fn test_redact_json_api_key() {
        let code = r#"{"api_key": "my-very-long-api-key-value-here"}"#;
        let redacted = redact_api_keys(code);
        assert!(!redacted.contains("my-very-long-api-key"));
        assert!(redacted.contains("[REDACTED]"));
    }

    #[test]
    fn test_redact_toml_format() {
        let code = r#"
[config]
PRIVATE_SECRET = "toml-secret-value"
API_KEY = "sk-toml-key-12345678901234567890"
        "#;
        let redacted = redact_api_keys(code);
        assert!(!redacted.contains("toml-secret-value"));
        assert!(!redacted.contains("sk-toml-key"));
    }
}
