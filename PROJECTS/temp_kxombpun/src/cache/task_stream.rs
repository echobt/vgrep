//! Real-time task progress cache for live evaluation updates
//!
//! Stores streaming stdout/stderr from validators during task execution.
//! Clients can poll for live progress before task results are persisted to DB.
//!
//! Features:
//! - Max 1MB per task entry (configurable)
//! - 1 hour TTL with automatic cleanup
//! - Thread-safe concurrent access via DashMap
//! - Automatic eviction when task is persisted to DB

use dashmap::DashMap;
use serde::{Deserialize, Serialize};
use std::sync::Arc;
use std::time::{Duration, SystemTime, UNIX_EPOCH};
use tracing::{debug, info};

/// Default maximum size per task entry (1 MB)
pub const DEFAULT_MAX_ENTRY_SIZE: usize = 1_048_576;

/// Default TTL in seconds (1 hour)
pub const DEFAULT_TTL_SECS: u64 = 3600;

/// Default cleanup interval in seconds (5 minutes)
pub const DEFAULT_CLEANUP_INTERVAL_SECS: u64 = 300;

/// Default streaming interval in milliseconds (2 seconds)
pub const DEFAULT_STREAM_INTERVAL_MS: u64 = 2000;

/// Configuration for the task stream cache
#[derive(Debug, Clone)]
pub struct TaskStreamConfig {
    pub max_entry_size_bytes: usize,
    pub ttl_secs: u64,
    pub cleanup_interval_secs: u64,
    pub stream_interval_ms: u64,
    pub enabled: bool,
}

impl Default for TaskStreamConfig {
    fn default() -> Self {
        Self {
            max_entry_size_bytes: DEFAULT_MAX_ENTRY_SIZE,
            ttl_secs: DEFAULT_TTL_SECS,
            cleanup_interval_secs: DEFAULT_CLEANUP_INTERVAL_SECS,
            stream_interval_ms: DEFAULT_STREAM_INTERVAL_MS,
            enabled: true,
        }
    }
}

impl TaskStreamConfig {
    pub fn from_env() -> Self {
        Self {
            max_entry_size_bytes: std::env::var("TASK_STREAM_MAX_SIZE")
                .ok()
                .and_then(|v| v.parse().ok())
                .unwrap_or(DEFAULT_MAX_ENTRY_SIZE),
            ttl_secs: std::env::var("TASK_STREAM_TTL_SECS")
                .ok()
                .and_then(|v| v.parse().ok())
                .unwrap_or(DEFAULT_TTL_SECS),
            cleanup_interval_secs: std::env::var("TASK_STREAM_CLEANUP_INTERVAL")
                .ok()
                .and_then(|v| v.parse().ok())
                .unwrap_or(DEFAULT_CLEANUP_INTERVAL_SECS),
            stream_interval_ms: std::env::var("TASK_STREAM_INTERVAL_MS")
                .ok()
                .and_then(|v| v.parse().ok())
                .unwrap_or(DEFAULT_STREAM_INTERVAL_MS),
            enabled: std::env::var("TASK_STREAM_ENABLED")
                .map(|v| v != "false" && v != "0")
                .unwrap_or(true),
        }
    }
}

/// A single task's streaming progress entry
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TaskStreamEntry {
    pub agent_hash: String,
    pub validator_hotkey: String,
    pub task_id: String,
    pub task_name: String,
    /// Status: "running", "completed", "failed"
    pub status: String,
    /// Accumulated stdout (truncated to max size, keeps recent data)
    pub stdout_buffer: String,
    /// Accumulated stderr (truncated to max size, keeps recent data)
    pub stderr_buffer: String,
    /// Current step number from agent
    pub current_step: i32,
    /// Unix timestamp when task started
    pub started_at: i64,
    /// Unix timestamp of last update
    pub updated_at: i64,
    /// Current total size in bytes
    pub size_bytes: usize,
}

impl TaskStreamEntry {
    pub fn new(
        agent_hash: String,
        validator_hotkey: String,
        task_id: String,
        task_name: String,
    ) -> Self {
        let now = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap()
            .as_secs() as i64;

        Self {
            agent_hash,
            validator_hotkey,
            task_id,
            task_name,
            status: "running".to_string(),
            stdout_buffer: String::new(),
            stderr_buffer: String::new(),
            current_step: 0,
            started_at: now,
            updated_at: now,
            size_bytes: 0,
        }
    }

    fn calculate_size(&self) -> usize {
        self.stdout_buffer.len() + self.stderr_buffer.len()
    }

    /// Append to stdout, keeping recent data if exceeds max size
    pub fn append_stdout(&mut self, chunk: &str, max_size: usize) {
        if chunk.is_empty() {
            return;
        }
        self.stdout_buffer.push_str(chunk);
        self.truncate_if_needed(max_size);
        self.update_timestamp();
    }

    /// Append to stderr, keeping recent data if exceeds max size
    pub fn append_stderr(&mut self, chunk: &str, max_size: usize) {
        if chunk.is_empty() {
            return;
        }
        self.stderr_buffer.push_str(chunk);
        self.truncate_if_needed(max_size);
        self.update_timestamp();
    }

    /// Truncate from the beginning to keep recent data
    fn truncate_if_needed(&mut self, max_size: usize) {
        let current_size = self.calculate_size();
        if current_size > max_size {
            let excess = current_size - max_size;
            // Remove from stdout first (usually larger), keeping recent data
            if self.stdout_buffer.len() > excess {
                // Find a good boundary (newline) near the truncation point
                let truncate_at = self.stdout_buffer[..excess]
                    .rfind('\n')
                    .map(|i| i + 1)
                    .unwrap_or(excess);
                self.stdout_buffer = self.stdout_buffer[truncate_at..].to_string();
            } else {
                let remaining = excess - self.stdout_buffer.len();
                self.stdout_buffer.clear();
                if self.stderr_buffer.len() > remaining {
                    let truncate_at = self.stderr_buffer[..remaining]
                        .rfind('\n')
                        .map(|i| i + 1)
                        .unwrap_or(remaining);
                    self.stderr_buffer = self.stderr_buffer[truncate_at..].to_string();
                }
            }
        }
        self.size_bytes = self.calculate_size();
    }

    fn update_timestamp(&mut self) {
        self.updated_at = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap()
            .as_secs() as i64;
    }

    pub fn is_expired(&self, ttl_secs: u64) -> bool {
        let now = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap()
            .as_secs() as i64;
        (now - self.updated_at) > ttl_secs as i64
    }

    pub fn duration_secs(&self) -> i64 {
        let now = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap()
            .as_secs() as i64;
        now - self.started_at
    }
}

/// Thread-safe cache for task streaming progress
#[derive(Clone)]
pub struct TaskStreamCache {
    entries: Arc<DashMap<String, TaskStreamEntry>>,
    config: TaskStreamConfig,
}

impl TaskStreamCache {
    pub fn new(config: TaskStreamConfig) -> Self {
        Self {
            entries: Arc::new(DashMap::new()),
            config,
        }
    }

    pub fn from_env() -> Self {
        Self::new(TaskStreamConfig::from_env())
    }

    pub fn is_enabled(&self) -> bool {
        self.config.enabled
    }

    pub fn stream_interval_ms(&self) -> u64 {
        self.config.stream_interval_ms
    }

    /// Generate cache key
    pub fn make_key(agent_hash: &str, validator_hotkey: &str, task_id: &str) -> String {
        format!("{}:{}:{}", agent_hash, validator_hotkey, task_id)
    }

    /// Push a streaming update
    pub fn push_update(&self, update: TaskStreamUpdate) {
        if !self.config.enabled {
            return;
        }

        let key = Self::make_key(
            &update.agent_hash,
            &update.validator_hotkey,
            &update.task_id,
        );
        let max_size = self.config.max_entry_size_bytes;

        self.entries
            .entry(key)
            .and_modify(|entry| {
                if let Some(ref status) = update.status {
                    entry.status = status.clone();
                }
                if let Some(ref chunk) = update.stdout_chunk {
                    entry.append_stdout(chunk, max_size);
                }
                if let Some(ref chunk) = update.stderr_chunk {
                    entry.append_stderr(chunk, max_size);
                }
                if let Some(step) = update.current_step {
                    entry.current_step = step;
                }
                entry.update_timestamp();
            })
            .or_insert_with(|| {
                let mut entry = TaskStreamEntry::new(
                    update.agent_hash.clone(),
                    update.validator_hotkey.clone(),
                    update.task_id.clone(),
                    update.task_name.clone().unwrap_or_default(),
                );
                if let Some(ref status) = update.status {
                    entry.status = status.clone();
                }
                if let Some(ref chunk) = update.stdout_chunk {
                    entry.append_stdout(chunk, max_size);
                }
                if let Some(ref chunk) = update.stderr_chunk {
                    entry.append_stderr(chunk, max_size);
                }
                if let Some(step) = update.current_step {
                    entry.current_step = step;
                }
                entry
            });
    }

    /// Get entry by key
    pub fn get_entry(&self, key: &str) -> Option<TaskStreamEntry> {
        self.entries.get(key).map(|e| e.clone())
    }

    /// Get entry by components
    pub fn get_task(
        &self,
        agent_hash: &str,
        validator_hotkey: &str,
        task_id: &str,
    ) -> Option<TaskStreamEntry> {
        let key = Self::make_key(agent_hash, validator_hotkey, task_id);
        self.get_entry(&key)
    }

    /// Get all live tasks for an agent
    pub fn get_agent_tasks(&self, agent_hash: &str) -> Vec<TaskStreamEntry> {
        self.entries
            .iter()
            .filter(|e| e.agent_hash == agent_hash)
            .map(|e| e.clone())
            .collect()
    }

    /// Get all entries for a specific task across validators
    pub fn get_task_by_id(&self, agent_hash: &str, task_id: &str) -> Vec<TaskStreamEntry> {
        self.entries
            .iter()
            .filter(|e| e.agent_hash == agent_hash && e.task_id == task_id)
            .map(|e| e.clone())
            .collect()
    }

    /// Remove entry (called when task is persisted to DB)
    pub fn remove(&self, agent_hash: &str, validator_hotkey: &str, task_id: &str) {
        let key = Self::make_key(agent_hash, validator_hotkey, task_id);
        if self.entries.remove(&key).is_some() {
            debug!(
                "Removed task stream entry: {}:{}",
                &agent_hash[..16.min(agent_hash.len())],
                task_id
            );
        }
    }

    /// Remove all entries for an agent
    pub fn remove_agent(&self, agent_hash: &str) {
        let keys_to_remove: Vec<String> = self
            .entries
            .iter()
            .filter(|e| e.agent_hash == agent_hash)
            .map(|e| e.key().clone())
            .collect();

        for key in keys_to_remove {
            self.entries.remove(&key);
        }
    }

    /// Cleanup expired entries
    pub fn cleanup_expired(&self) -> usize {
        let ttl = self.config.ttl_secs;
        let keys_to_remove: Vec<String> = self
            .entries
            .iter()
            .filter(|e| e.is_expired(ttl))
            .map(|e| e.key().clone())
            .collect();

        let count = keys_to_remove.len();
        for key in keys_to_remove {
            self.entries.remove(&key);
        }

        if count > 0 {
            info!("Cleaned up {} expired task stream entries", count);
        }
        count
    }

    /// Get cache stats
    pub fn stats(&self) -> TaskStreamStats {
        let entries: Vec<_> = self.entries.iter().collect();
        let total_size: usize = entries.iter().map(|e| e.size_bytes).sum();

        TaskStreamStats {
            entry_count: entries.len(),
            total_size_bytes: total_size,
            max_entry_size: self.config.max_entry_size_bytes,
            ttl_secs: self.config.ttl_secs,
            enabled: self.config.enabled,
        }
    }

    /// Spawn background cleanup task
    pub fn spawn_cleanup_task(self: Arc<Self>) {
        let cleanup_interval = self.config.cleanup_interval_secs;
        let interval = Duration::from_secs(cleanup_interval);

        tokio::spawn(async move {
            let mut ticker = tokio::time::interval(interval);
            loop {
                ticker.tick().await;
                self.cleanup_expired();
            }
        });

        info!(
            "Task stream cache cleanup task started (interval: {}s)",
            cleanup_interval
        );
    }
}

/// Update to push to the cache
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TaskStreamUpdate {
    pub agent_hash: String,
    pub validator_hotkey: String,
    pub task_id: String,
    pub task_name: Option<String>,
    pub status: Option<String>,
    pub stdout_chunk: Option<String>,
    pub stderr_chunk: Option<String>,
    pub current_step: Option<i32>,
}

/// Cache statistics
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TaskStreamStats {
    pub entry_count: usize,
    pub total_size_bytes: usize,
    pub max_entry_size: usize,
    pub ttl_secs: u64,
    pub enabled: bool,
}

/// Response for live task progress
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LiveTaskProgress {
    pub task_id: String,
    pub task_name: String,
    pub validator_hotkey: String,
    pub status: String,
    pub stdout: String,
    pub stderr: String,
    pub current_step: i32,
    pub duration_secs: i64,
    pub size_bytes: usize,
    pub is_live: bool,
}

impl From<TaskStreamEntry> for LiveTaskProgress {
    fn from(entry: TaskStreamEntry) -> Self {
        let is_live = entry.status == "running";
        let duration_secs = entry.duration_secs();
        let size_bytes = entry.size_bytes;
        Self {
            task_id: entry.task_id,
            task_name: entry.task_name,
            validator_hotkey: entry.validator_hotkey,
            status: entry.status,
            stdout: entry.stdout_buffer,
            stderr: entry.stderr_buffer,
            current_step: entry.current_step,
            duration_secs,
            size_bytes,
            is_live,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_cache_basic_operations() {
        let cache = TaskStreamCache::new(TaskStreamConfig::default());

        let update = TaskStreamUpdate {
            agent_hash: "agent123".to_string(),
            validator_hotkey: "val456".to_string(),
            task_id: "task789".to_string(),
            task_name: Some("test_task".to_string()),
            status: Some("running".to_string()),
            stdout_chunk: Some("Hello ".to_string()),
            stderr_chunk: None,
            current_step: Some(1),
        };

        cache.push_update(update);

        let entry = cache.get_task("agent123", "val456", "task789");
        assert!(entry.is_some());
        let entry = entry.unwrap();
        assert_eq!(entry.status, "running");
        assert_eq!(entry.stdout_buffer, "Hello ");

        // Append more
        let update2 = TaskStreamUpdate {
            agent_hash: "agent123".to_string(),
            validator_hotkey: "val456".to_string(),
            task_id: "task789".to_string(),
            task_name: None,
            status: None,
            stdout_chunk: Some("World!".to_string()),
            stderr_chunk: None,
            current_step: Some(2),
        };
        cache.push_update(update2);

        let entry = cache.get_task("agent123", "val456", "task789").unwrap();
        assert_eq!(entry.stdout_buffer, "Hello World!");
        assert_eq!(entry.current_step, 2);

        // Remove
        cache.remove("agent123", "val456", "task789");
        assert!(cache.get_task("agent123", "val456", "task789").is_none());
    }

    #[test]
    fn test_size_limit() {
        let config = TaskStreamConfig {
            max_entry_size_bytes: 100,
            ..Default::default()
        };
        let cache = TaskStreamCache::new(config);

        let large_chunk = "X".repeat(80);
        let update = TaskStreamUpdate {
            agent_hash: "agent".to_string(),
            validator_hotkey: "val".to_string(),
            task_id: "task".to_string(),
            task_name: Some("test".to_string()),
            status: Some("running".to_string()),
            stdout_chunk: Some(large_chunk.clone()),
            stderr_chunk: None,
            current_step: None,
        };
        cache.push_update(update);

        // Push more to exceed limit
        let update2 = TaskStreamUpdate {
            agent_hash: "agent".to_string(),
            validator_hotkey: "val".to_string(),
            task_id: "task".to_string(),
            task_name: None,
            status: None,
            stdout_chunk: Some(large_chunk),
            stderr_chunk: None,
            current_step: None,
        };
        cache.push_update(update2);

        let entry = cache.get_task("agent", "val", "task").unwrap();
        assert!(entry.size_bytes <= 100);
    }

    #[test]
    fn test_get_agent_tasks() {
        let cache = TaskStreamCache::new(TaskStreamConfig::default());

        for i in 0..3 {
            let update = TaskStreamUpdate {
                agent_hash: "agent123".to_string(),
                validator_hotkey: format!("val{}", i),
                task_id: format!("task{}", i),
                task_name: Some(format!("test_{}", i)),
                status: Some("running".to_string()),
                stdout_chunk: None,
                stderr_chunk: None,
                current_step: None,
            };
            cache.push_update(update);
        }

        let tasks = cache.get_agent_tasks("agent123");
        assert_eq!(tasks.len(), 3);
    }

    #[test]
    fn test_task_stream_entry_creation() {
        let entry = TaskStreamEntry::new(
            "agent1".to_string(),
            "validator1".to_string(),
            "task1".to_string(),
            "Test Task".to_string(),
        );

        assert_eq!(entry.agent_hash, "agent1");
        assert_eq!(entry.validator_hotkey, "validator1");
        assert_eq!(entry.task_id, "task1");
        assert_eq!(entry.task_name, "Test Task");
        assert_eq!(entry.status, "running");
        assert!(entry.stdout_buffer.is_empty());
        assert!(entry.stderr_buffer.is_empty());
        assert_eq!(entry.current_step, 0);
        assert!(entry.started_at > 0);
    }

    #[test]
    fn test_task_stream_entry_append_stdout() {
        let mut entry = TaskStreamEntry::new(
            "agent".to_string(),
            "val".to_string(),
            "task".to_string(),
            "Test".to_string(),
        );

        entry.append_stdout("Hello ", 1000);
        assert_eq!(entry.stdout_buffer, "Hello ");

        entry.append_stdout("World!", 1000);
        assert_eq!(entry.stdout_buffer, "Hello World!");

        // Empty chunk should not change anything
        entry.append_stdout("", 1000);
        assert_eq!(entry.stdout_buffer, "Hello World!");
    }

    #[test]
    fn test_task_stream_entry_append_stderr() {
        let mut entry = TaskStreamEntry::new(
            "agent".to_string(),
            "val".to_string(),
            "task".to_string(),
            "Test".to_string(),
        );

        entry.append_stderr("Error: ", 1000);
        assert_eq!(entry.stderr_buffer, "Error: ");

        entry.append_stderr("Something failed", 1000);
        assert_eq!(entry.stderr_buffer, "Error: Something failed");
    }

    #[test]
    fn test_task_stream_update_struct() {
        let update = TaskStreamUpdate {
            agent_hash: "agent".to_string(),
            validator_hotkey: "val".to_string(),
            task_id: "task".to_string(),
            task_name: Some("My Task".to_string()),
            status: Some("completed".to_string()),
            stdout_chunk: Some("output".to_string()),
            stderr_chunk: Some("error".to_string()),
            current_step: Some(5),
        };

        assert_eq!(update.agent_hash, "agent");
        assert_eq!(update.task_name.as_ref().unwrap(), "My Task");
        assert_eq!(update.status.as_ref().unwrap(), "completed");
        assert_eq!(update.current_step.unwrap(), 5);
    }

    #[test]
    fn test_task_stream_config_default() {
        let config = TaskStreamConfig::default();

        assert!(config.max_entry_size_bytes > 0);
        assert!(config.ttl_secs > 0);
        assert!(config.cleanup_interval_secs > 0);
        assert!(config.enabled);
    }

    #[test]
    fn test_update_status() {
        let cache = TaskStreamCache::new(TaskStreamConfig::default());

        // Create task
        let update = TaskStreamUpdate {
            agent_hash: "agent".to_string(),
            validator_hotkey: "val".to_string(),
            task_id: "task".to_string(),
            task_name: Some("Test".to_string()),
            status: Some("running".to_string()),
            stdout_chunk: None,
            stderr_chunk: None,
            current_step: None,
        };
        cache.push_update(update);

        // Update status
        let update2 = TaskStreamUpdate {
            agent_hash: "agent".to_string(),
            validator_hotkey: "val".to_string(),
            task_id: "task".to_string(),
            task_name: None,
            status: Some("completed".to_string()),
            stdout_chunk: None,
            stderr_chunk: None,
            current_step: Some(10),
        };
        cache.push_update(update2);

        let entry = cache.get_task("agent", "val", "task").unwrap();
        assert_eq!(entry.status, "completed");
        assert_eq!(entry.current_step, 10);
    }

    #[test]
    fn test_nonexistent_task() {
        let cache = TaskStreamCache::new(TaskStreamConfig::default());

        let entry = cache.get_task("nonexistent", "val", "task");
        assert!(entry.is_none());
    }

    #[test]
    fn test_empty_agent_tasks() {
        let cache = TaskStreamCache::new(TaskStreamConfig::default());

        let tasks = cache.get_agent_tasks("nonexistent");
        assert!(tasks.is_empty());
    }

    #[test]
    fn test_stderr_update() {
        let cache = TaskStreamCache::new(TaskStreamConfig::default());

        let update = TaskStreamUpdate {
            agent_hash: "agent".to_string(),
            validator_hotkey: "val".to_string(),
            task_id: "task".to_string(),
            task_name: Some("Test".to_string()),
            status: Some("running".to_string()),
            stdout_chunk: None,
            stderr_chunk: Some("Warning message".to_string()),
            current_step: None,
        };
        cache.push_update(update);

        let entry = cache.get_task("agent", "val", "task").unwrap();
        assert_eq!(entry.stderr_buffer, "Warning message");
    }

    #[test]
    fn test_remove_agent() {
        let cache = TaskStreamCache::new(TaskStreamConfig::default());

        // Add multiple tasks for the same agent
        for i in 0..3 {
            let update = TaskStreamUpdate {
                agent_hash: "agent123".to_string(),
                validator_hotkey: format!("val{}", i),
                task_id: format!("task{}", i),
                task_name: Some("Test".to_string()),
                status: Some("running".to_string()),
                stdout_chunk: None,
                stderr_chunk: None,
                current_step: None,
            };
            cache.push_update(update);
        }

        // Add task for different agent
        let update = TaskStreamUpdate {
            agent_hash: "agent456".to_string(),
            validator_hotkey: "val1".to_string(),
            task_id: "task1".to_string(),
            task_name: Some("Test".to_string()),
            status: Some("running".to_string()),
            stdout_chunk: None,
            stderr_chunk: None,
            current_step: None,
        };
        cache.push_update(update);

        // Verify agent123 has 3 tasks
        let tasks = cache.get_agent_tasks("agent123");
        assert_eq!(tasks.len(), 3);

        // Remove all tasks for agent123
        cache.remove_agent("agent123");

        // Verify agent123 has no tasks
        let tasks = cache.get_agent_tasks("agent123");
        assert!(tasks.is_empty());

        // Verify agent456 still has tasks
        let tasks = cache.get_agent_tasks("agent456");
        assert_eq!(tasks.len(), 1);
    }

    #[test]
    fn test_remove_agent_nonexistent() {
        let cache = TaskStreamCache::new(TaskStreamConfig::default());
        // Should not panic
        cache.remove_agent("nonexistent");
    }

    #[test]
    fn test_cleanup_expired() {
        let config = TaskStreamConfig {
            ttl_secs: 0, // 0 second TTL - expires immediately after 1 second
            ..Default::default()
        };
        let cache = TaskStreamCache::new(config);

        // Add a task
        let update = TaskStreamUpdate {
            agent_hash: "agent".to_string(),
            validator_hotkey: "val".to_string(),
            task_id: "task".to_string(),
            task_name: Some("Test".to_string()),
            status: Some("running".to_string()),
            stdout_chunk: None,
            stderr_chunk: None,
            current_step: None,
        };
        cache.push_update(update);

        // Verify task exists
        assert!(cache.get_task("agent", "val", "task").is_some());

        // Sleep for 1 second to ensure time passes at seconds granularity
        std::thread::sleep(std::time::Duration::from_secs(1));

        // Cleanup expired entries
        let count = cache.cleanup_expired();
        assert_eq!(count, 1);

        // Verify task is gone
        assert!(cache.get_task("agent", "val", "task").is_none());
    }

    #[test]
    fn test_cleanup_expired_no_entries() {
        let cache = TaskStreamCache::new(TaskStreamConfig::default());
        let count = cache.cleanup_expired();
        assert_eq!(count, 0);
    }

    #[test]
    fn test_cleanup_expired_mixed() {
        let config = TaskStreamConfig {
            ttl_secs: 0,
            ..Default::default()
        };
        let cache = TaskStreamCache::new(config);

        // Add first task
        let update1 = TaskStreamUpdate {
            agent_hash: "agent".to_string(),
            validator_hotkey: "val1".to_string(),
            task_id: "task1".to_string(),
            task_name: Some("Test".to_string()),
            status: Some("running".to_string()),
            stdout_chunk: None,
            stderr_chunk: None,
            current_step: None,
        };
        cache.push_update(update1);

        // Sleep to ensure task1 expires (1 second for seconds-level timestamps)
        std::thread::sleep(std::time::Duration::from_secs(1));

        // Add second task (should not be expired)
        let update2 = TaskStreamUpdate {
            agent_hash: "agent".to_string(),
            validator_hotkey: "val2".to_string(),
            task_id: "task2".to_string(),
            task_name: Some("Test".to_string()),
            status: Some("running".to_string()),
            stdout_chunk: None,
            stderr_chunk: None,
            current_step: None,
        };
        cache.push_update(update2);

        // Cleanup should remove only expired task
        let count = cache.cleanup_expired();
        assert_eq!(count, 1);

        assert!(cache.get_task("agent", "val1", "task1").is_none());
        assert!(cache.get_task("agent", "val2", "task2").is_some());
    }

    #[test]
    fn test_stats() {
        let cache = TaskStreamCache::new(TaskStreamConfig::default());

        // Empty cache
        let stats = cache.stats();
        assert_eq!(stats.entry_count, 0);
        assert_eq!(stats.total_size_bytes, 0);
        assert!(stats.enabled);

        // Add entries
        for i in 0..3 {
            let update = TaskStreamUpdate {
                agent_hash: "agent".to_string(),
                validator_hotkey: format!("val{}", i),
                task_id: format!("task{}", i),
                task_name: Some("Test".to_string()),
                status: Some("running".to_string()),
                stdout_chunk: Some("X".repeat(100)),
                stderr_chunk: None,
                current_step: None,
            };
            cache.push_update(update);
        }

        let stats = cache.stats();
        assert_eq!(stats.entry_count, 3);
        assert!(stats.total_size_bytes >= 300); // At least 100 bytes per entry
        assert_eq!(stats.max_entry_size, DEFAULT_MAX_ENTRY_SIZE);
    }

    #[test]
    fn test_is_expired() {
        let entry = TaskStreamEntry::new(
            "agent".to_string(),
            "val".to_string(),
            "task".to_string(),
            "Test".to_string(),
        );

        // Should not be expired with long TTL (even if some time passes)
        assert!(!entry.is_expired(3600));

        // is_expired checks: (now - updated_at) > ttl_secs
        // With 0 TTL, even 1 second passed means expired
        // Let's sleep 1 second to ensure expiration with 0 TTL
        std::thread::sleep(std::time::Duration::from_secs(1));
        assert!(entry.is_expired(0));
    }

    #[test]
    fn test_duration_secs() {
        let entry = TaskStreamEntry::new(
            "agent".to_string(),
            "val".to_string(),
            "task".to_string(),
            "Test".to_string(),
        );

        let duration = entry.duration_secs();
        assert!(duration >= 0);

        // Sleep for at least 1 second to ensure measurable change in seconds
        std::thread::sleep(std::time::Duration::from_secs(1));
        let duration2 = entry.duration_secs();
        assert!(duration2 >= duration); // Allow >= since we only measure in seconds
    }

    #[test]
    fn test_calculate_size() {
        let mut entry = TaskStreamEntry::new(
            "agent".to_string(),
            "val".to_string(),
            "task".to_string(),
            "Test".to_string(),
        );

        assert_eq!(entry.calculate_size(), 0);

        entry.stdout_buffer = "Hello".to_string();
        assert_eq!(entry.calculate_size(), 5);

        entry.stderr_buffer = "World".to_string();
        assert_eq!(entry.calculate_size(), 10);
    }

    #[test]
    fn test_truncate_if_needed_stdout_only() {
        let mut entry = TaskStreamEntry::new(
            "agent".to_string(),
            "val".to_string(),
            "task".to_string(),
            "Test".to_string(),
        );

        // Add data that exceeds max size
        entry.stdout_buffer = "A".repeat(150);
        entry.truncate_if_needed(100);

        assert!(entry.stdout_buffer.len() <= 100);
        assert_eq!(entry.size_bytes, entry.stdout_buffer.len());
    }

    #[test]
    fn test_truncate_if_needed_both_buffers() {
        let mut entry = TaskStreamEntry::new(
            "agent".to_string(),
            "val".to_string(),
            "task".to_string(),
            "Test".to_string(),
        );

        // Fill both buffers
        entry.stdout_buffer = "A".repeat(80);
        entry.stderr_buffer = "B".repeat(80);
        entry.truncate_if_needed(100);

        let total_size = entry.stdout_buffer.len() + entry.stderr_buffer.len();
        assert!(total_size <= 100);
        assert_eq!(entry.size_bytes, total_size);
    }

    #[test]
    fn test_truncate_if_needed_with_newlines() {
        let mut entry = TaskStreamEntry::new(
            "agent".to_string(),
            "val".to_string(),
            "task".to_string(),
            "Test".to_string(),
        );

        // Add data with newlines
        entry.stdout_buffer = "line1\nline2\nline3\n".repeat(10);
        let original_len = entry.stdout_buffer.len();
        entry.truncate_if_needed(100);

        // Should truncate to keep recent data (implementation truncates from beginning)
        // The size should be close to max_size but may be slightly over due to newline boundary
        assert!(entry.stdout_buffer.len() <= 150); // Allow some slack for newline boundaries
        assert!(entry.stdout_buffer.len() < original_len);
    }

    #[test]
    fn test_truncate_if_needed_no_truncation() {
        let mut entry = TaskStreamEntry::new(
            "agent".to_string(),
            "val".to_string(),
            "task".to_string(),
            "Test".to_string(),
        );

        entry.stdout_buffer = "Short".to_string();
        entry.truncate_if_needed(1000);

        assert_eq!(entry.stdout_buffer, "Short");
        assert_eq!(entry.size_bytes, 5);
    }

    #[test]
    fn test_make_key() {
        let key = TaskStreamCache::make_key("agent123", "val456", "task789");
        assert_eq!(key, "agent123:val456:task789");
    }

    #[test]
    fn test_get_entry_by_key() {
        let cache = TaskStreamCache::new(TaskStreamConfig::default());

        let update = TaskStreamUpdate {
            agent_hash: "agent".to_string(),
            validator_hotkey: "val".to_string(),
            task_id: "task".to_string(),
            task_name: Some("Test".to_string()),
            status: Some("running".to_string()),
            stdout_chunk: None,
            stderr_chunk: None,
            current_step: None,
        };
        cache.push_update(update);

        let key = TaskStreamCache::make_key("agent", "val", "task");
        let entry = cache.get_entry(&key);
        assert!(entry.is_some());

        let entry = cache.get_entry("nonexistent:key");
        assert!(entry.is_none());
    }

    #[test]
    fn test_get_task_by_id() {
        let cache = TaskStreamCache::new(TaskStreamConfig::default());

        // Add multiple validators evaluating same task
        for i in 0..3 {
            let update = TaskStreamUpdate {
                agent_hash: "agent123".to_string(),
                validator_hotkey: format!("val{}", i),
                task_id: "task_common".to_string(),
                task_name: Some("Test".to_string()),
                status: Some("running".to_string()),
                stdout_chunk: None,
                stderr_chunk: None,
                current_step: None,
            };
            cache.push_update(update);
        }

        let entries = cache.get_task_by_id("agent123", "task_common");
        assert_eq!(entries.len(), 3);

        // Different agent should return empty
        let entries = cache.get_task_by_id("agent456", "task_common");
        assert!(entries.is_empty());
    }

    #[test]
    fn test_is_enabled() {
        let config_enabled = TaskStreamConfig {
            enabled: true,
            ..Default::default()
        };
        let cache = TaskStreamCache::new(config_enabled);
        assert!(cache.is_enabled());

        let config_disabled = TaskStreamConfig {
            enabled: false,
            ..Default::default()
        };
        let cache = TaskStreamCache::new(config_disabled);
        assert!(!cache.is_enabled());
    }

    #[test]
    fn test_stream_interval_ms() {
        let config = TaskStreamConfig {
            stream_interval_ms: 5000,
            ..Default::default()
        };
        let cache = TaskStreamCache::new(config);
        assert_eq!(cache.stream_interval_ms(), 5000);
    }

    #[test]
    fn test_push_update_disabled() {
        let config = TaskStreamConfig {
            enabled: false,
            ..Default::default()
        };
        let cache = TaskStreamCache::new(config);

        let update = TaskStreamUpdate {
            agent_hash: "agent".to_string(),
            validator_hotkey: "val".to_string(),
            task_id: "task".to_string(),
            task_name: Some("Test".to_string()),
            status: Some("running".to_string()),
            stdout_chunk: None,
            stderr_chunk: None,
            current_step: None,
        };
        cache.push_update(update);

        // Should not add entry when disabled
        let entry = cache.get_task("agent", "val", "task");
        assert!(entry.is_none());
    }

    #[test]
    fn test_live_task_progress_conversion() {
        let entry = TaskStreamEntry::new(
            "agent123".to_string(),
            "validator456".to_string(),
            "task789".to_string(),
            "Test Task".to_string(),
        );

        let progress: LiveTaskProgress = entry.into();
        assert_eq!(progress.task_id, "task789");
        assert_eq!(progress.task_name, "Test Task");
        assert_eq!(progress.validator_hotkey, "validator456");
        assert_eq!(progress.status, "running");
        assert!(progress.is_live);
    }

    #[test]
    fn test_live_task_progress_completed() {
        let mut entry = TaskStreamEntry::new(
            "agent".to_string(),
            "val".to_string(),
            "task".to_string(),
            "Test".to_string(),
        );
        entry.status = "completed".to_string();

        let progress: LiveTaskProgress = entry.into();
        assert_eq!(progress.status, "completed");
        assert!(!progress.is_live);
    }

    #[test]
    fn test_multiple_updates_same_key() {
        let cache = TaskStreamCache::new(TaskStreamConfig::default());

        // Push multiple updates to same task
        for i in 0..5 {
            let update = TaskStreamUpdate {
                agent_hash: "agent".to_string(),
                validator_hotkey: "val".to_string(),
                task_id: "task".to_string(),
                task_name: Some("Test".to_string()),
                status: Some("running".to_string()),
                stdout_chunk: Some(format!("Line {}\n", i)),
                stderr_chunk: None,
                current_step: Some(i),
            };
            cache.push_update(update);
        }

        let entry = cache.get_task("agent", "val", "task").unwrap();
        assert_eq!(entry.current_step, 4);
        assert!(entry.stdout_buffer.contains("Line 0"));
        assert!(entry.stdout_buffer.contains("Line 4"));
    }

    #[test]
    fn test_update_timestamp() {
        let mut entry = TaskStreamEntry::new(
            "agent".to_string(),
            "val".to_string(),
            "task".to_string(),
            "Test".to_string(),
        );

        let initial_timestamp = entry.updated_at;
        // Sleep for 1 second to ensure measurable difference in seconds
        std::thread::sleep(std::time::Duration::from_secs(1));

        entry.update_timestamp();
        assert!(entry.updated_at >= initial_timestamp);
    }

    #[test]
    fn test_task_stream_stats_clone() {
        let stats = TaskStreamStats {
            entry_count: 5,
            total_size_bytes: 1000,
            max_entry_size: 2000,
            ttl_secs: 3600,
            enabled: true,
        };

        let cloned = stats.clone();
        assert_eq!(cloned.entry_count, 5);
        assert_eq!(cloned.total_size_bytes, 1000);
        assert!(cloned.enabled);
    }

    #[test]
    #[serial_test::serial]
    fn test_config_from_env_defaults() {
        // This tests the default values when env vars are not set
        std::env::remove_var("TASK_STREAM_MAX_SIZE");
        std::env::remove_var("TASK_STREAM_TTL_SECS");
        std::env::remove_var("TASK_STREAM_CLEANUP_INTERVAL");
        std::env::remove_var("TASK_STREAM_INTERVAL_MS");
        std::env::remove_var("TASK_STREAM_ENABLED");

        let config = TaskStreamConfig::from_env();
        assert_eq!(config.max_entry_size_bytes, DEFAULT_MAX_ENTRY_SIZE);
        assert_eq!(config.ttl_secs, DEFAULT_TTL_SECS);
        assert_eq!(config.cleanup_interval_secs, DEFAULT_CLEANUP_INTERVAL_SECS);
        assert_eq!(config.stream_interval_ms, DEFAULT_STREAM_INTERVAL_MS);
        assert!(config.enabled);
    }

    #[test]
    #[serial_test::serial]
    fn test_cache_from_env() {
        std::env::remove_var("TASK_STREAM_ENABLED");
        let cache = TaskStreamCache::from_env();
        assert!(cache.is_enabled());
    }

    #[test]
    fn test_append_empty_chunks() {
        let mut entry = TaskStreamEntry::new(
            "agent".to_string(),
            "val".to_string(),
            "task".to_string(),
            "Test".to_string(),
        );

        entry.append_stdout("", 1000);
        entry.append_stderr("", 1000);

        assert!(entry.stdout_buffer.is_empty());
        assert!(entry.stderr_buffer.is_empty());
    }

    #[test]
    fn test_truncate_with_stderr_overflow() {
        let mut entry = TaskStreamEntry::new(
            "agent".to_string(),
            "val".to_string(),
            "task".to_string(),
            "Test".to_string(),
        );

        // Fill stdout completely
        entry.stdout_buffer = "A".repeat(120);
        // Add stderr
        entry.stderr_buffer = "B".repeat(50);

        entry.truncate_if_needed(100);

        // Total size should be within limit
        let total_size = entry.stdout_buffer.len() + entry.stderr_buffer.len();
        assert!(total_size <= 150); // Allow slack for newline boundary behavior
        assert_eq!(entry.calculate_size(), total_size);
    }

    #[test]
    fn test_remove_logs_debug() {
        let cache = TaskStreamCache::new(TaskStreamConfig::default());

        // Add entry
        let update = TaskStreamUpdate {
            agent_hash: "a".repeat(20),
            validator_hotkey: "val".to_string(),
            task_id: "task123".to_string(),
            task_name: Some("Test".to_string()),
            status: Some("running".to_string()),
            stdout_chunk: None,
            stderr_chunk: None,
            current_step: None,
        };
        cache.push_update(update);

        // Remove should work (debug log tested implicitly)
        cache.remove(&"a".repeat(20), "val", "task123");
        assert!(cache.get_task(&"a".repeat(20), "val", "task123").is_none());
    }

    #[test]
    fn test_truncate_clears_stdout_then_stderr() {
        let mut entry = TaskStreamEntry::new(
            "agent".to_string(),
            "val".to_string(),
            "task".to_string(),
            "Test".to_string(),
        );

        // Create scenario where stdout must be fully cleared
        entry.stdout_buffer = "A".repeat(60);
        entry.stderr_buffer = "B".repeat(80);

        // Total is 140, max is 50, so need to remove 90 bytes
        // stdout is 60 bytes, so it will be cleared, leaving 30 more to remove from stderr
        entry.truncate_if_needed(50);

        // Stdout should be cleared since it's smaller than excess
        assert!(entry.stdout_buffer.is_empty());

        // Stderr should be truncated
        assert!(entry.stderr_buffer.len() <= 50);
        assert!(!entry.stderr_buffer.is_empty());

        // Total size should be within limit
        assert!(entry.calculate_size() <= 50);
    }

    #[test]
    fn test_truncate_stderr_completely() {
        let mut entry = TaskStreamEntry::new(
            "agent".to_string(),
            "val".to_string(),
            "task".to_string(),
            "Test".to_string(),
        );

        // Both buffers exceed limit significantly
        entry.stdout_buffer = "A".repeat(100);
        entry.stderr_buffer = "B".repeat(100);

        // With max of 50, need to remove 150 bytes
        // stdout cleared (100), still need 50 more from stderr
        entry.truncate_if_needed(50);

        assert!(entry.stdout_buffer.is_empty());
        assert!(entry.stderr_buffer.len() <= 50);
    }

    #[test]
    #[serial_test::serial]
    fn test_config_from_env_with_custom_values() {
        // RAII guard to ensure cleanup even if assertions fail
        struct EnvGuard;
        impl Drop for EnvGuard {
            fn drop(&mut self) {
                std::env::remove_var("TASK_STREAM_MAX_SIZE");
                std::env::remove_var("TASK_STREAM_TTL_SECS");
                std::env::remove_var("TASK_STREAM_CLEANUP_INTERVAL");
                std::env::remove_var("TASK_STREAM_INTERVAL_MS");
                std::env::remove_var("TASK_STREAM_ENABLED");
            }
        }
        let _guard = EnvGuard;

        // Set custom environment variables
        std::env::set_var("TASK_STREAM_MAX_SIZE", "2097152");
        std::env::set_var("TASK_STREAM_TTL_SECS", "7200");
        std::env::set_var("TASK_STREAM_CLEANUP_INTERVAL", "600");
        std::env::set_var("TASK_STREAM_INTERVAL_MS", "5000");
        std::env::set_var("TASK_STREAM_ENABLED", "true");

        let config = TaskStreamConfig::from_env();
        assert_eq!(config.max_entry_size_bytes, 2097152);
        assert_eq!(config.ttl_secs, 7200);
        assert_eq!(config.cleanup_interval_secs, 600);
        assert_eq!(config.stream_interval_ms, 5000);
        assert!(config.enabled);

        // Test disabled
        std::env::set_var("TASK_STREAM_ENABLED", "false");
        let config = TaskStreamConfig::from_env();
        assert!(!config.enabled);

        // Test "0" means disabled
        std::env::set_var("TASK_STREAM_ENABLED", "0");
        let config = TaskStreamConfig::from_env();
        assert!(!config.enabled);

        // Cleanup happens automatically via _guard Drop
    }

    #[test]
    #[serial_test::serial]
    fn test_config_from_env_invalid_values() {
        // RAII guard to ensure cleanup even if assertions fail
        struct EnvGuard;
        impl Drop for EnvGuard {
            fn drop(&mut self) {
                std::env::remove_var("TASK_STREAM_MAX_SIZE");
                std::env::remove_var("TASK_STREAM_TTL_SECS");
            }
        }
        let _guard = EnvGuard;

        // Set invalid values that can't be parsed
        std::env::set_var("TASK_STREAM_MAX_SIZE", "invalid");
        std::env::set_var("TASK_STREAM_TTL_SECS", "not_a_number");

        let config = TaskStreamConfig::from_env();
        // Should fall back to defaults
        assert_eq!(config.max_entry_size_bytes, DEFAULT_MAX_ENTRY_SIZE);
        assert_eq!(config.ttl_secs, DEFAULT_TTL_SECS);

        // Cleanup happens automatically via _guard Drop
    }

    #[tokio::test]
    async fn test_spawn_cleanup_task() {
        use std::sync::Arc;

        let config = TaskStreamConfig {
            ttl_secs: 0,
            cleanup_interval_secs: 1, // 1 second for fast test
            ..Default::default()
        };
        let cache = Arc::new(TaskStreamCache::new(config));

        // Add an entry that will expire
        let update = TaskStreamUpdate {
            agent_hash: "agent".to_string(),
            validator_hotkey: "val".to_string(),
            task_id: "task".to_string(),
            task_name: Some("Test".to_string()),
            status: Some("running".to_string()),
            stdout_chunk: None,
            stderr_chunk: None,
            current_step: None,
        };
        cache.push_update(update);

        // Spawn cleanup task
        cache.clone().spawn_cleanup_task();

        // Wait for entry to expire
        tokio::time::sleep(tokio::time::Duration::from_millis(1100)).await;

        // Wait for cleanup to run
        tokio::time::sleep(tokio::time::Duration::from_millis(1100)).await;

        // Entry should be cleaned up
        let entry = cache.get_task("agent", "val", "task");
        assert!(entry.is_none());
    }

    #[test]
    fn test_live_task_progress_with_failed_status() {
        let mut entry = TaskStreamEntry::new(
            "agent".to_string(),
            "val".to_string(),
            "task".to_string(),
            "Test".to_string(),
        );
        entry.status = "failed".to_string();
        entry.stdout_buffer = "output".to_string();
        entry.stderr_buffer = "error occurred".to_string();
        entry.current_step = 5;

        let progress: LiveTaskProgress = entry.into();
        assert_eq!(progress.status, "failed");
        assert!(!progress.is_live);
        assert_eq!(progress.stdout, "output");
        assert_eq!(progress.stderr, "error occurred");
        assert_eq!(progress.current_step, 5);
    }

    #[test]
    fn test_task_stream_update_with_all_none() {
        let cache = TaskStreamCache::new(TaskStreamConfig::default());

        // First create an entry
        let update1 = TaskStreamUpdate {
            agent_hash: "agent".to_string(),
            validator_hotkey: "val".to_string(),
            task_id: "task".to_string(),
            task_name: Some("Test".to_string()),
            status: Some("running".to_string()),
            stdout_chunk: Some("initial".to_string()),
            stderr_chunk: None,
            current_step: Some(1),
        };
        cache.push_update(update1);

        // Update with all None values except required fields
        let update2 = TaskStreamUpdate {
            agent_hash: "agent".to_string(),
            validator_hotkey: "val".to_string(),
            task_id: "task".to_string(),
            task_name: None,
            status: None,
            stdout_chunk: None,
            stderr_chunk: None,
            current_step: None,
        };
        cache.push_update(update2);

        // Entry should still exist with original values
        let entry = cache.get_task("agent", "val", "task").unwrap();
        assert_eq!(entry.status, "running");
        assert_eq!(entry.stdout_buffer, "initial");
        assert_eq!(entry.current_step, 1);
    }

    #[test]
    fn test_size_bytes_updated_on_truncate() {
        let mut entry = TaskStreamEntry::new(
            "agent".to_string(),
            "val".to_string(),
            "task".to_string(),
            "Test".to_string(),
        );

        entry.stdout_buffer = "X".repeat(200);
        assert_eq!(entry.size_bytes, 0); // Not updated yet

        entry.truncate_if_needed(100);

        // size_bytes should be updated after truncation
        assert_eq!(entry.size_bytes, entry.calculate_size());
        assert!(entry.size_bytes <= 100);
    }

    #[test]
    fn test_new_entry_without_task_name() {
        let cache = TaskStreamCache::new(TaskStreamConfig::default());

        let update = TaskStreamUpdate {
            agent_hash: "agent".to_string(),
            validator_hotkey: "val".to_string(),
            task_id: "task".to_string(),
            task_name: None, // No task name
            status: Some("running".to_string()),
            stdout_chunk: Some("output".to_string()),
            stderr_chunk: None,
            current_step: None,
        };
        cache.push_update(update);

        let entry = cache.get_task("agent", "val", "task").unwrap();
        assert_eq!(entry.task_name, ""); // Should default to empty string
        assert_eq!(entry.stdout_buffer, "output");
    }
}
