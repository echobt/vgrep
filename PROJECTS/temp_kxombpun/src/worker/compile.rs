//! Agent Compilation Worker
//!
//! Background service that compiles pending agents using PyInstaller.
//! Runs only on term-server (not validators).
//!
//! Flow:
//! 1. Polls DB for agents with compile_status='pending'
//! 2. Compiles each with PyInstaller in isolated Docker container
//! 3. Stores binary in DB
//! 4. Marks as 'success' or 'failed'
//! 5. Clears and reassigns validators from platform-server
//! 6. Assigns evaluation tasks from active checkpoint
//! 7. Notifies assigned validators via WebSocket that binary is ready

use crate::bench::registry::RegistryClient;
use crate::client::websocket::platform::PlatformWsClient;
use crate::container::backend::create_backend;
use crate::container::compiler;
use crate::storage::pg::{PendingCompilation, PgStorage, TaskAssignment};
use serde::Deserialize;
use std::sync::Arc;
use std::time::Duration;
use tokio::sync::RwLock;
use tokio::time::interval;
use tracing::{debug, error, info, warn};

/// Number of tasks to assign per agent (from active checkpoint)
const TASKS_PER_AGENT: usize = 30;

/// Number of validators to assign per agent (30 tasks / 10 per validator = 3)
const VALIDATORS_PER_AGENT: usize = 3;

/// Maximum wait time for ready validators (15 minutes)
const MAX_VALIDATOR_WAIT_SECS: u64 = 15 * 60;

/// Default registry path (can be overridden by REGISTRY_PATH env var)
const DEFAULT_REGISTRY_PATH: &str = "./registry.json";

/// Get the registry path from environment or use default
fn get_registry_path() -> String {
    std::env::var("REGISTRY_PATH").unwrap_or_else(|_| DEFAULT_REGISTRY_PATH.to_string())
}

/// Configuration for the compile worker
pub struct CompileWorkerConfig {
    /// How often to poll for pending compilations
    pub poll_interval_secs: u64,
    /// Max agents to compile per poll
    pub batch_size: i32,
    /// Max concurrent compilations
    pub max_concurrent: usize,
}

impl Default for CompileWorkerConfig {
    fn default() -> Self {
        Self {
            poll_interval_secs: 10,
            batch_size: 5,
            max_concurrent: 2,
        }
    }
}

/// Background worker that compiles pending agents
pub struct CompileWorker {
    storage: Arc<PgStorage>,
    ws_client: Option<Arc<PlatformWsClient>>,
    config: CompileWorkerConfig,
    /// Platform server URL for fetching validators
    platform_url: String,
    /// Cached task list from terminal-bench@2.0 registry (first 30 tasks)
    task_list: Arc<RwLock<Vec<TaskAssignment>>>,
}

impl CompileWorker {
    pub fn new(
        storage: Arc<PgStorage>,
        ws_client: Option<Arc<PlatformWsClient>>,
        config: CompileWorkerConfig,
        platform_url: String,
    ) -> Self {
        Self {
            storage,
            ws_client,
            config,
            platform_url,
            task_list: Arc::new(RwLock::new(Vec::new())),
        }
    }

    /// Start the worker (runs forever)
    pub async fn run(&self) {
        info!(
            "Compile worker started (poll={}s, batch={}, concurrent={})",
            self.config.poll_interval_secs, self.config.batch_size, self.config.max_concurrent
        );

        // Load evaluation tasks from registry at startup
        if let Err(e) = self.load_evaluation_tasks().await {
            error!("Failed to load evaluation tasks: {}", e);
            error!("Compile worker will not be able to assign tasks to agents!");
        }

        // Cleanup orphan compiler containers from previous runs
        if let Err(e) = self.cleanup_orphan_compilers().await {
            warn!("Failed to cleanup orphan compiler containers: {}", e);
        }

        let mut ticker = interval(Duration::from_secs(self.config.poll_interval_secs));

        loop {
            ticker.tick().await;

            if let Err(e) = self.process_pending().await {
                error!("Error processing pending compilations: {}", e);
            }
        }
    }

    /// Load evaluation tasks from active checkpoint in registry
    async fn load_evaluation_tasks(&self) -> anyhow::Result<()> {
        let registry_path = get_registry_path();
        info!("Loading evaluation tasks from registry: {}", registry_path);

        // Load registry from checkpoint file
        let registry_client = RegistryClient::from_file(&registry_path).map_err(|e| {
            anyhow::anyhow!("Failed to load registry from {}: {}", registry_path, e)
        })?;

        // Get active checkpoint name for logging
        let active_checkpoint = RegistryClient::get_active_checkpoint(&registry_path)
            .unwrap_or_else(|_| "unknown".to_string());

        info!("Using active checkpoint: {}", active_checkpoint);

        // Get the dataset from the loaded registry (first dataset in checkpoint)
        let registry = registry_client
            .registry()
            .ok_or_else(|| anyhow::anyhow!("Registry not loaded"))?;

        let dataset = registry
            .datasets
            .first()
            .ok_or_else(|| anyhow::anyhow!("No datasets found in checkpoint"))?;

        // Get tasks, sorted by name for determinism
        let mut task_sources = dataset.tasks.clone();
        task_sources.sort_by(|a, b| a.name.cmp(&b.name));

        let tasks: Vec<TaskAssignment> = task_sources
            .into_iter()
            .take(TASKS_PER_AGENT)
            .map(|source| TaskAssignment {
                task_id: source.name.clone(),
                task_name: source.name,
            })
            .collect();

        info!(
            "Loaded {} evaluation tasks from checkpoint '{}': {:?}",
            tasks.len(),
            active_checkpoint,
            tasks.iter().map(|t| &t.task_id).collect::<Vec<_>>()
        );

        let mut guard = self.task_list.write().await;
        *guard = tasks;

        Ok(())
    }

    /// Cleanup orphan compiler containers from previous runs
    async fn cleanup_orphan_compilers(&self) -> anyhow::Result<()> {
        info!("Cleaning up orphan compiler containers...");
        let backend = create_backend().await?;
        // Use same challenge_id as the main challenge (from env var)
        let challenge_id =
            std::env::var("CHALLENGE_ID").unwrap_or_else(|_| "term-challenge".to_string());
        let removed = backend.cleanup(&challenge_id).await?;
        if removed > 0 {
            info!("Cleaned up {} orphan compiler containers", removed);
        } else {
            debug!("No orphan compiler containers found");
        }
        Ok(())
    }

    /// Process pending compilations
    async fn process_pending(&self) -> anyhow::Result<()> {
        // Get pending agents
        let pending = self
            .storage
            .get_pending_compilations(self.config.batch_size)
            .await?;

        if pending.is_empty() {
            debug!("No pending compilations");
            return Ok(());
        }

        info!("Found {} agents pending compilation", pending.len());

        // Process each agent (could be parallelized with semaphore)
        for compilation in pending {
            self.compile_agent(compilation).await;
        }

        Ok(())
    }

    /// Compile a single agent
    async fn compile_agent(&self, compilation: PendingCompilation) {
        let agent_hash = &compilation.agent_hash;
        let short_hash = &agent_hash[..16.min(agent_hash.len())];

        if compilation.is_package {
            info!("Compiling package agent {}...", short_hash);
            info!(
                "  Package format: {:?}, Entry point: {:?}",
                compilation.package_format, compilation.entry_point
            );
        } else {
            info!("Compiling single-file agent {}...", short_hash);
            info!(
                "Source code preview: {}...",
                &compilation.source_code[..200.min(compilation.source_code.len())]
                    .replace('\n', " ")
            );
        }

        // Mark as compiling
        if let Err(e) = self.storage.set_compiling(agent_hash).await {
            error!("Failed to mark agent {} as compiling: {}", short_hash, e);
            return;
        }

        // Log container backend being used
        info!("Starting compilation with container backend...");
        info!(
            "  CONTAINER_BROKER_WS_URL: {:?}",
            std::env::var("CONTAINER_BROKER_WS_URL").ok()
        );
        info!(
            "  CONTAINER_BROKER_JWT: {:?}",
            std::env::var("CONTAINER_BROKER_JWT")
                .ok()
                .map(|s| format!("{}...", &s[..20.min(s.len())]))
        );

        // Compile based on submission type
        let compile_result = if compilation.is_package {
            compiler::compile_package(
                compilation.package_data.as_deref().unwrap_or(&[]),
                compilation.package_format.as_deref().unwrap_or("zip"),
                compilation.entry_point.as_deref().unwrap_or("agent.py"),
                agent_hash,
            )
            .await
        } else {
            compiler::compile_agent(&compilation.source_code, agent_hash).await
        };

        match compile_result {
            Ok(result) => {
                info!(
                    "Agent {} compiled successfully: {} bytes in {}ms",
                    short_hash, result.size, result.compile_time_ms
                );

                // Log warnings
                for warning in &result.warnings {
                    warn!("Compile warning for {}: {}", short_hash, warning);
                }

                // Store binary
                if let Err(e) = self
                    .storage
                    .store_binary(agent_hash, &result.binary, result.compile_time_ms as i32)
                    .await
                {
                    error!("Failed to store binary for {}: {}", short_hash, e);
                    let _ = self
                        .storage
                        .set_compile_failed(agent_hash, &format!("Failed to store: {}", e))
                        .await;
                    return;
                }

                // Cleanup all previous evaluation data for this agent
                // This ensures a fresh start in case of recompilation
                if let Err(e) = self
                    .storage
                    .cleanup_agent_for_recompilation(agent_hash)
                    .await
                {
                    warn!(
                        "Failed to cleanup agent {} for recompilation: {}",
                        short_hash, e
                    );
                    // Continue anyway - cleanup is best effort
                }

                // Wait for ready validators and assign them (waits up to 15 min)
                if !self.assign_validators(agent_hash).await {
                    // Validators not available - agent already marked as failed
                    error!(
                        "No ready validators for agent {}, evaluation aborted",
                        short_hash
                    );
                    return;
                }

                // Get assigned validators and distribute tasks among them
                let assigned_validators =
                    match self.storage.get_assigned_validators(agent_hash).await {
                        Ok(v) => v,
                        Err(e) => {
                            error!(
                                "Failed to get assigned validators for {}: {}",
                                short_hash, e
                            );
                            return;
                        }
                    };

                // Create/update pending_evaluations entry with correct validator count
                // This ensures the entry exists even if it was deleted/expired
                if let Ok(Some(submission)) = self.storage.get_submission(agent_hash).await {
                    if let Err(e) = self
                        .storage
                        .queue_for_all_validators(
                            &submission.id,
                            agent_hash,
                            &submission.miner_hotkey,
                            assigned_validators.len() as i32,
                        )
                        .await
                    {
                        error!(
                            "Failed to create pending_evaluation for {}: {}",
                            short_hash, e
                        );
                    } else {
                        info!(
                            "Created/updated pending_evaluation for {} with {} validators",
                            short_hash,
                            assigned_validators.len()
                        );
                    }
                }

                // Assign tasks distributed across validators (10 tasks each)
                self.assign_evaluation_tasks_distributed(agent_hash, &assigned_validators)
                    .await;

                // Notify assigned validators that binary is ready
                self.notify_validators_binary_ready(agent_hash).await;
            }
            Err(e) => {
                error!("Compilation failed for {}: {}", short_hash, e);
                let _ = self
                    .storage
                    .set_compile_failed(agent_hash, &e.to_string())
                    .await;
            }
        }
    }

    /// Assign evaluation tasks distributed across validators
    /// Each validator gets a unique subset of the 30 tasks (10 each for 3 validators)
    async fn assign_evaluation_tasks_distributed(&self, agent_hash: &str, validators: &[String]) {
        let short_hash = &agent_hash[..16.min(agent_hash.len())];

        let tasks = self.task_list.read().await;
        if tasks.is_empty() {
            error!(
                "No evaluation tasks loaded! Cannot assign tasks to agent {}",
                short_hash
            );
            return;
        }

        if validators.is_empty() {
            error!(
                "No validators provided for task distribution for agent {}",
                short_hash
            );
            return;
        }

        // Distribute tasks across validators using pg_storage function
        match self
            .storage
            .assign_tasks_to_validators(agent_hash, validators, &tasks)
            .await
        {
            Ok(_) => {
                let tasks_per_validator = tasks.len() / validators.len();
                info!(
                    "Distributed {} tasks across {} validators ({} each) for agent {}",
                    tasks.len(),
                    validators.len(),
                    tasks_per_validator,
                    short_hash
                );
            }
            Err(e) => {
                error!(
                    "Failed to distribute tasks to validators for agent {}: {}",
                    short_hash, e
                );
            }
        }
    }

    /// Legacy: Assign evaluation tasks from terminal-bench@2.0 to the compiled agent
    /// Kept for backwards compatibility - use assign_evaluation_tasks_distributed instead
    #[allow(dead_code)]
    async fn assign_evaluation_tasks(&self, agent_hash: &str) {
        let short_hash = &agent_hash[..16.min(agent_hash.len())];

        // Clear existing task assignments
        if let Err(e) = self.storage.clear_evaluation_tasks(agent_hash).await {
            warn!(
                "Failed to clear existing task assignments for {}: {}",
                short_hash, e
            );
        }

        let tasks = self.task_list.read().await;
        if tasks.is_empty() {
            error!(
                "No evaluation tasks loaded! Cannot assign tasks to agent {}",
                short_hash
            );
            return;
        }

        match self.storage.assign_tasks_to_agent(agent_hash, &tasks).await {
            Ok(_) => {
                info!(
                    "Assigned {} evaluation tasks to agent {}",
                    tasks.len(),
                    short_hash
                );
            }
            Err(e) => {
                error!(
                    "Failed to assign evaluation tasks to agent {}: {}",
                    short_hash, e
                );
            }
        }
    }

    /// Select validators for an agent using deterministic hash-based selection
    fn select_validators(&self, agent_hash: &str, validators: &[String]) -> Vec<String> {
        if validators.is_empty() {
            return vec![];
        }

        let count = VALIDATORS_PER_AGENT.min(validators.len());

        // Sort validators for deterministic ordering
        let mut sorted_validators: Vec<&String> = validators.iter().collect();
        sorted_validators.sort();

        // Use agent_hash to deterministically select starting index
        let hash_bytes = hex::decode(agent_hash).unwrap_or_default();
        let start_idx = if hash_bytes.is_empty() {
            0
        } else {
            let mut idx_bytes = [0u8; 8];
            for (i, b) in hash_bytes.iter().take(8).enumerate() {
                idx_bytes[i] = *b;
            }
            u64::from_le_bytes(idx_bytes) as usize % sorted_validators.len()
        };

        // Select validators starting from start_idx (wrapping around)
        let mut selected = Vec::with_capacity(count);
        for i in 0..count {
            let idx = (start_idx + i) % sorted_validators.len();
            selected.push(sorted_validators[idx].clone());
        }

        selected
    }

    /// Assign validators to an agent after successful compilation
    /// Only uses validators that have reported ready status (broker connected)
    /// Waits up to 15 minutes for enough validators, then fails
    async fn assign_validators(&self, agent_hash: &str) -> bool {
        let short_hash = &agent_hash[..16.min(agent_hash.len())];

        // Clear existing validator assignments
        if let Err(e) = self.storage.clear_validator_assignments(agent_hash).await {
            warn!(
                "Failed to clear existing validator assignments for {}: {}",
                short_hash, e
            );
        }

        // Wait for ready validators (up to 15 minutes)
        let start_time = std::time::Instant::now();
        let required_validators = VALIDATORS_PER_AGENT;

        loop {
            // Check for ready validators from DB with stake verification (>= 10000 TAO)
            let ready_validators = match self
                .storage
                .get_ready_validators_with_stake(&self.platform_url, required_validators + 2)
                .await
            {
                Ok(v) => v,
                Err(e) => {
                    warn!("Failed to get ready validators with stake check: {}", e);
                    vec![]
                }
            };

            let ready_hotkeys: Vec<String> = ready_validators
                .iter()
                .map(|v| v.validator_hotkey.clone())
                .collect();

            if ready_hotkeys.len() >= required_validators {
                // Select validators deterministically from ready ones
                let selected = self.select_validators(agent_hash, &ready_hotkeys);

                if selected.len() >= required_validators {
                    // Assign selected validators
                    match self
                        .storage
                        .assign_validators_to_agent(agent_hash, &selected)
                        .await
                    {
                        Ok(count) => {
                            info!(
                                "Assigned {} ready validators to agent {}: {:?}",
                                count,
                                short_hash,
                                selected
                                    .iter()
                                    .map(|s| &s[..16.min(s.len())])
                                    .collect::<Vec<_>>()
                            );
                            return true;
                        }
                        Err(e) => {
                            error!("Failed to assign validators to agent {}: {}", short_hash, e);
                            return false;
                        }
                    }
                }
            }

            // Check timeout
            let elapsed = start_time.elapsed().as_secs();
            if elapsed >= MAX_VALIDATOR_WAIT_SECS {
                error!(
                    "TIMEOUT: No ready validators with sufficient stake (>= 10000 TAO) available for agent {} after {} seconds. \
                     Required: {}, Available: {}. Evaluation FAILED.",
                    short_hash,
                    elapsed,
                    required_validators,
                    ready_hotkeys.len()
                );
                // Mark agent as failed due to no validators
                if let Err(e) = self
                    .storage
                    .sudo_set_status(
                        agent_hash,
                        "failed",
                        Some(
                            "No ready validators with sufficient stake available after 15 minutes",
                        ),
                    )
                    .await
                {
                    error!("Failed to set agent status to failed: {}", e);
                }
                return false;
            }

            // Log progress every minute
            if elapsed > 0 && elapsed.is_multiple_of(60) {
                warn!(
                    "Waiting for validators for agent {}: {}/{} ready, {}s elapsed (max {}s)",
                    short_hash,
                    ready_hotkeys.len(),
                    required_validators,
                    elapsed,
                    MAX_VALIDATOR_WAIT_SECS
                );
            }

            // Wait 30 seconds before checking again
            tokio::time::sleep(std::time::Duration::from_secs(30)).await;
        }
    }

    /// Notify assigned validators that binary compilation is complete
    async fn notify_validators_binary_ready(&self, agent_hash: &str) {
        let short_hash = &agent_hash[..16.min(agent_hash.len())];

        // Get assigned validators for this agent
        let validators = match self.storage.get_assigned_validators(agent_hash).await {
            Ok(v) => v,
            Err(e) => {
                warn!(
                    "Failed to get assigned validators for {}: {}",
                    short_hash, e
                );
                return;
            }
        };

        if validators.is_empty() {
            warn!("No validators assigned to agent {}", short_hash);
            return;
        }

        // Send WebSocket notification
        if let Some(ws) = &self.ws_client {
            match ws.notify_binary_ready(&validators, agent_hash).await {
                Ok(_) => {
                    info!(
                        "Notified {} validators that binary is ready for {}",
                        validators.len(),
                        short_hash
                    );
                }
                Err(e) => {
                    warn!("Failed to notify validators for {}: {}", short_hash, e);
                }
            }
        } else {
            debug!(
                "No WebSocket client configured, skipping validator notification for {}",
                short_hash
            );
        }
    }
}

/// Start the compile worker in background
pub fn spawn_compile_worker(
    storage: Arc<PgStorage>,
    ws_client: Option<Arc<PlatformWsClient>>,
    config: CompileWorkerConfig,
    platform_url: String,
) {
    tokio::spawn(async move {
        let worker = CompileWorker::new(storage, ws_client, config, platform_url);
        worker.run().await;
    });
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_config_defaults() {
        let config = CompileWorkerConfig::default();
        assert_eq!(config.poll_interval_secs, 10);
        assert_eq!(config.batch_size, 5);
        assert_eq!(config.max_concurrent, 2);
    }
}
