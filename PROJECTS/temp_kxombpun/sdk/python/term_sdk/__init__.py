"""
Term Challenge SDK 2.0 - Build agents that solve terminal tasks.

SDK 2.0 uses an agent-controlled execution model where your agent:
- Receives the instruction once via the context
- Executes commands directly via subprocess (ctx.shell())
- Manages its own loop and LLM calls
- Signals completion with ctx.done()

Quick Start:
    ```python
    from term_sdk import Agent, AgentContext, run

    class MyAgent(Agent):
        def run(self, ctx: AgentContext):
            result = ctx.shell("ls -la")
            if result.has("file.txt"):
                ctx.shell("cat file.txt")
            ctx.done()

    if __name__ == "__main__":
        run(MyAgent())
    ```

With LLM:
    ```python
    from term_sdk import Agent, AgentContext, LLM, run

    class LLMAgent(Agent):
        def setup(self):
            self.llm = LLM(model="deepseek/deepseek-chat")

        def run(self, ctx: AgentContext):
            ctx.log(f"Task: {ctx.instruction[:100]}...")
            
            # Explore
            result = ctx.shell("ls -la")
            
            # Use LLM to decide next action
            response = self.llm.ask(
                f"Task: {ctx.instruction}\\n"
                f"Files: {result.stdout[:2000]}\\n"
                "What command should I run?"
            )
            
            # Execute LLM suggestion
            ctx.shell(response.text)
            ctx.done()

    if __name__ == "__main__":
        run(LLMAgent())
    ```

Agent Loop Pattern:
    ```python
    from term_sdk import Agent, AgentContext, LLM, run

    class LoopAgent(Agent):
        def setup(self):
            self.llm = LLM()

        def run(self, ctx: AgentContext):
            messages = [{"role": "user", "content": ctx.instruction}]
            
            while ctx.step < 100:  # Limit to 100 steps
                # Get LLM response
                response = self.llm.chat(messages)
                
                # Parse command from response
                cmd = self.parse_command(response.text)
                if not cmd:
                    ctx.done()
                    return
                
                # Execute and add to messages
                result = ctx.shell(cmd)
                messages.append({"role": "assistant", "content": response.text})
                messages.append({"role": "user", "content": f"Output: {result.stdout[-3000:]}"})
                
                if self.is_task_complete(result):
                    ctx.done()
                    return
            
            ctx.done()  # Ran out of steps

    if __name__ == "__main__":
        run(LoopAgent())
    ```
"""

__version__ = "2.0.0"

# Core agent classes
from .agent import Agent, AgentContext, ShellResult, HistoryEntry

# Runner
from .runner import run, log, log_error, log_step, set_logging

# LLM
from .llm import LLM, LLMResponse, LLMError, CostLimitExceeded

# Packager for multi-file submissions
from .packager import create_package, validate_project, package_to_base64

# Legacy types (for backwards compatibility if needed)
from .types import Request, Response, Tool, FunctionCall

__all__ = [
    # SDK 2.0 core
    "Agent",
    "AgentContext", 
    "ShellResult",
    "HistoryEntry",
    # Runner
    "run",
    "log",
    "log_error",
    "log_step",
    "set_logging",
    # LLM
    "LLM",
    "LLMResponse",
    "LLMError",
    "CostLimitExceeded",
    # Packager
    "create_package",
    "validate_project",
    "package_to_base64",
    # Legacy (SDK 1.x compatibility)
    "Request",
    "Response",
    "Tool",
    "FunctionCall",
]
