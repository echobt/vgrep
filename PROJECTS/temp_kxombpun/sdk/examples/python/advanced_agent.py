#!/usr/bin/env python3
"""
Advanced Term Challenge Agent Example (SDK 2.0)

Features:
- Multi-step planning with memory
- Streaming LLM responses
- Error recovery
- Cost tracking
"""

import json
import re
from dataclasses import dataclass, field

from term_sdk import Agent, AgentContext, LLM, LLMError, run


@dataclass
class Memory:
    """Agent memory for tracking state."""
    plan: list = field(default_factory=list)
    completed_steps: list = field(default_factory=list)
    errors: list = field(default_factory=list)
    files_created: list = field(default_factory=list)


class AdvancedAgent(Agent):
    """
    Advanced agent with planning, memory, streaming, and error recovery.
    """
    
    PLANNER_PROMPT = """You are a planning AI for terminal tasks.
Given a task, create a step-by-step plan.
Output a JSON array of steps, each step being a string description.

Example:
["List current directory", "Create file hello.py", "Write Python code", "Run the script", "Verify output"]

Task: {task}

Output ONLY the JSON array, nothing else."""

    EXECUTOR_PROMPT = """You are an expert Linux terminal user.
Execute the next step of the plan.

Task: {task}
Plan: {plan}
Completed: {completed}
Current step: {current_step}
Last output: 
```
{last_output}
```

Respond with a single shell command to execute this step.
Output ONLY the command, nothing else."""

    def setup(self):
        """Initialize agent."""
        self.llm = LLM()
        self.memory = Memory()
    
    def run(self, ctx: AgentContext):
        """Execute the task with planning and error recovery."""
        ctx.log(f"Task: {ctx.instruction[:100]}...")
        
        # Step 1: Create a plan
        self.memory.plan = self._create_plan(ctx)
        ctx.log(f"Created plan with {len(self.memory.plan)} steps")
        
        # Step 2: Explore the environment
        result = ctx.shell("ls -la")
        last_output = result.output
        
        # Step 3: Execute plan steps
        for i, step in enumerate(self.memory.plan):
            # Check resource limits
            if ctx.step > 95:  # Leave buffer before 100 step limit
                ctx.log("Low on steps, finishing up")
                break
            
            stats = self.llm.get_stats()
            if stats["total_cost"] > 1.0:
                ctx.log(f"Budget limit reached: ${stats['total_cost']:.2f}")
                break
            
            ctx.log(f"Step {i+1}/{len(self.memory.plan)}: {step}")
            
            # Get command for this step (with streaming feedback)
            cmd = self._get_command_for_step(ctx, step, last_output)
            if not cmd:
                ctx.log("No command returned, skipping step")
                continue
            
            # Execute command
            ctx.log(f"Executing: {cmd}")
            result = ctx.shell(cmd)
            last_output = result.output
            
            # Handle errors
            if result.failed:
                ctx.log(f"Command failed (exit {result.exit_code})")
                self.memory.errors.append(f"Step {i+1}: {cmd}")
                
                if len(self.memory.errors) > 3:
                    ctx.log("Too many errors, stopping")
                    break
                
                # Try to recover
                ctx.log("Attempting recovery...")
                continue
            
            # Track success
            self.memory.completed_steps.append(step)
            
            # Track file creation
            if '>' in cmd:
                match = re.search(r'>\s*(\S+)', cmd)
                if match:
                    self.memory.files_created.append(match.group(1))
        
        ctx.log(f"Completed {len(self.memory.completed_steps)}/{len(self.memory.plan)} steps")
        ctx.done()
    
    def _create_plan(self, ctx: AgentContext) -> list:
        """Create a plan for the task."""
        ctx.log("Creating plan...")
        
        try:
            response = self.llm.ask(
                self.PLANNER_PROMPT.format(task=ctx.instruction),
                temperature=0.3
            )
            
            # Parse JSON plan
            match = re.search(r'\[.*\]', response.text, re.DOTALL)
            if match:
                plan = json.loads(match.group())
                return plan
        except (json.JSONDecodeError, LLMError) as e:
            ctx.log(f"Planning error: {e}")
        
        # Fallback: simple plan
        return ["Explore directory", "Execute task", "Verify result"]
    
    def _get_command_for_step(self, ctx: AgentContext, step: str, last_output: str) -> str:
        """Get command for the current step using streaming."""
        prompt = self.EXECUTOR_PROMPT.format(
            task=ctx.instruction,
            plan=json.dumps(self.memory.plan),
            completed=json.dumps(self.memory.completed_steps),
            current_step=step,
            last_output=last_output[-1500:] if len(last_output) > 1500 else last_output
        )
        
        try:
            # Stream response with progress feedback
            full_text = ""
            for chunk in self.llm.stream(prompt):
                full_text += chunk
                if len(full_text) % 50 == 0:
                    ctx.log(f"  thinking... ({len(full_text)} chars)")
            
            # Extract just the command (first line, strip backticks)
            cmd = full_text.strip().split('\n')[0]
            cmd = cmd.strip('`').strip()
            return cmd
            
        except LLMError as e:
            ctx.log(f"LLM error: {e.code} - {e.message}")
            return None
    
    def cleanup(self):
        """Report stats."""
        stats = self.llm.get_stats()
        print("=== Agent Report ===")
        print(f"Steps: {len(self.memory.completed_steps)}/{len(self.memory.plan)}")
        print(f"Files created: {self.memory.files_created}")
        print(f"Errors: {len(self.memory.errors)}")
        print(f"Total cost: ${stats['total_cost']:.4f}")
        print(f"Total tokens: {stats['total_tokens']}")
        self.llm.close()


if __name__ == "__main__":
    run(AdvancedAgent())
