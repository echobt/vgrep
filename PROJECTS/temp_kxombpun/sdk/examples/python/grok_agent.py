#!/usr/bin/env python3
"""
Agent using Grok (or any model) via term_sdk LLM (SDK 2.0).
"""

import os
from term_sdk import Agent, AgentContext, LLM, LLMError, run


SYSTEM_PROMPT = """You are a terminal agent. Execute shell commands to complete tasks.

RULES:
- Return a single shell command to run
- Use standard Unix commands (ls, cat, echo, grep, find, etc.)
- When task is complete, return {"command": null, "task_complete": true}
- Be concise and efficient

Respond with JSON only: {"command": "your command here", "task_complete": false}"""


class GrokAgent(Agent):
    def setup(self):
        # Check for API key
        api_key = os.environ.get("LLM_API_KEY") or os.environ.get("OPENROUTER_API_KEY")
        if not api_key:
            print("[agent] WARNING: No API key found", flush=True)
        
        model = os.environ.get("LLM_MODEL", "x-ai/grok-2-latest")
        print(f"[agent] Using model: {model}", flush=True)
        self.llm = LLM(provider="openrouter", default_model=model, temperature=0.1)
        self.history = []
    
    def run(self, ctx: AgentContext):
        ctx.log(f"Task: {ctx.instruction[:100]}...")
        
        # Initial exploration
        result = ctx.shell("ls -la")
        last_output = result.output
        
        # Main execution loop
        while ctx.step < 100:  # Limit to 100 steps
            user_msg = f"""TASK: {ctx.instruction}

STEP: {ctx.step}
LAST OUTPUT:
{last_output[-2000:] if last_output else "(no output yet)"}

What command should I run next? (JSON only)"""

            self.history.append({"role": "user", "content": user_msg})
            
            messages = [{"role": "system", "content": SYSTEM_PROMPT}] + self.history[-10:]
            
            try:
                result = self.llm.chat(messages, max_tokens=256)
                self.history.append({"role": "assistant", "content": result.text})
                
                # Parse response
                data = result.json()
                if not data:
                    ctx.log("Failed to parse LLM response")
                    break
                
                if data.get("task_complete"):
                    ctx.log("Task marked complete by LLM")
                    break
                
                cmd = data.get("command")
                if cmd:
                    ctx.log(f"Executing: {cmd}")
                    shell_result = ctx.shell(cmd)
                    last_output = shell_result.output
                else:
                    ctx.log("No command in response")
                    break
                    
            except LLMError as e:
                ctx.log(f"LLM error: {e.code} - {e.message}")
                break
            except Exception as e:
                ctx.log(f"Error: {e}")
                break
        
        ctx.done()
    
    def cleanup(self):
        stats = self.llm.get_stats()
        print(f"[agent] Total cost: ${stats['total_cost']:.4f}", flush=True)
        self.llm.close()


if __name__ == "__main__":
    run(GrokAgent())
